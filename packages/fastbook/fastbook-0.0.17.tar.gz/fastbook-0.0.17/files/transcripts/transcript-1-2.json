{
  "00:01": "So, hello everybody, and welcome back to Practical Deep Learning for Coders.",
  "00:06": "This is lesson two, and in the last lesson we started training our first models.",
  "00:16": "We didn't really have any idea how that training was really working, but we were looking at",
  "00:20": "a higher level at what was going on.",
  "00:25": "And we learned about \u201cWhat is machine learning?\u201d and \u201cHow does that work?\u201d and we realized",
  "00:36": "that based on how machine learning worked that there are some fundamental limitations",
  "00:42": "on what it can do, and we've talked about some of those limitations.",
  "00:46": "And we also talked about how after you've trained a machine learning model, you end",
  "00:50": "up with a program which behaves much like a normal program or something: with inputs",
  "00:55": "and a thing in the middle and outputs.",
  "00:59": "So today we're gonna finish up talking about that and we're going to then look at how we",
  "01:05": "get those models into production and what some of the issues with doing that might be.",
  "01:13": "I wanted to remind you that there are two sets of books--sorry two sets of notebooks--available",
  "01:19": "to you.",
  "01:21": "One is the fastbook repo (the full actual notebooks containing all the text of the O'Reilly",
  "01:30": "book) and so this lets you see everything that I'm telling you in much more detail,",
  "01:37": "and then as well as that there's the course v4 repo which contains exactly the same notebooks",
  "01:43": "but with all the prose stripped away to help you study.",
  "01:48": "So that's where you really want to be doing your experiment and your practice and so maybe",
  "01:52": "as you listen to the video you can kind of switch back and forth between the video and",
  "01:57": "reading or do one and then the other, and then put it away and have a look at the course",
  "02:02": "v4 notebooks and try to remember like \u201cOkay, what was this section about?\u201d and run the",
  "02:07": "code, and see what happens and change it and so forth.",
  "02:12": "So we were looking at this line of code where we looked at how we created our data by passing",
  "02:24": "in information--perhaps most importantly some way to label the data--and we talked about",
  "02:30": "the importance of labeling.",
  "02:32": "And in this case, this particular dataset whether it's a cat or a dog, you can tell",
  "02:36": "by whether it's an uppercase or a lowercase letter in the first position.",
  "02:41": "That's just how this dataset (that they tell you when the readme) works.",
  "02:45": "And we also looked particularly at this idea of \u201cvalid percent equals 0.2,\u201d and like",
  "02:50": "\u201cWhat does that mean?",
  "02:51": "It creates a validation set.\u201d and that was something I wanted to talk more about.",
  "02:57": "The first thing I want to do though is point out that this particular labeling function",
  "03:06": "returns something that's either true or false.",
  "03:09": "And actually this data set as we'll see later also contains the actual breed of 37 different",
  "03:17": "cat and dog breeds, so you can also grab that from the filename.",
  "03:22": "In each of those two cases we're trying to predict a category \u201cIs it a cat, or is it",
  "03:29": "a dog?\u201d or \u201cIs it a German Shepherd, or a Beagle, or a Ragdoll cat, or whatever?\u201d",
  "03:36": "When you're trying to predict a category, so when the label is a category, we call that",
  "03:41": "a classification model.",
  "03:44": "On the other hand, you might try to predict how old is the animal, or how tall is it,",
  "03:52": "or something like that, which is like a continuous number that could be like 13.2 or 26.5 or",
  "03:59": "whatever.",
  "04:00": "Anytime you're trying to predict a number, your label is a number you call that regression.",
  "04:05": "Okay?",
  "04:06": "So those are the two main types of model classification and regressions.",
  "04:10": "This is very important jargon to know about.",
  "04:13": "So the regression model attempts to predict one or more numeric quantities such as temperature,",
  "04:19": "or location, or whatever.",
  "04:21": "This is a bit confusing, because sometimes people use the word regression as a shortcut",
  "04:26": "to a particular, for a\u2026",
  "04:27": "Like an abbreviation for a particular kind of model, called linear regression.",
  "04:32": "That's super confusing, because that's not what regression means.",
  "04:37": "Linear regression is just a particular kind of regression but I just wanted to warn you",
  "04:41": "of that.",
  "04:42": "When you start talking about regression a lot of people will assume you're talking about",
  "04:46": "linear regression even though that's not what the word means.",
  "04:50": "All right, so I wanted to talk about this valid percent zero point two thing.",
  "04:56": "So as we described valid percent grabs, in this case, twenty percent of the data, if",
  "05:01": "it's zero point two, and puts it aside like in a separate bucket and then when you train",
  "05:06": "your model, your model doesn't get to look at that data at all.",
  "05:11": "That data is only used to decide, to show you how accurate your model is.",
  "05:20": "So if you train for too long, and or with not enough data, and/or a model with too many",
  "05:27": "parameters, after a while the accuracy of your model will actually get worse, and this",
  "05:33": "is called overfitting.",
  "05:34": "Right?",
  "05:35": "So we use the validation set to ensure that we're not overfitting.",
  "05:42": "The next line of code that we looked at is this one, where we created something called",
  "05:47": "a learner.",
  "05:48": "We'll be learning a lot more about that, but a learner is basically, or is, something which",
  "05:52": "contains your data and your architecture that is the mathematical function that you're optimizing,",
  "06:02": "and so a learner is the thing that tries to figure out what are the parameters which best",
  "06:06": "cause this function to match the labels in this data.",
  "06:13": "So we\u2019ll be talking a lot more about that, but basically this particular function ResNet34",
  "06:18": "is the name of a particular architecture which is just very good for computer vision problems.",
  "06:24": "In fact the name really is ResNet and then 34 tells you how many layers there are.",
  "06:30": "So you can use ones with bigger numbers here to get more parameters that will take to train,",
  "06:36": "take more memory, more likely to overfit, but could also create more complex models.",
  "06:43": "Right now though I wanted to focus on this part here which is metrics equals error rate.",
  "06:48": "This is where you list the functions that you want to be the...",
  "06:52": "That you want to be called with your data.",
  "06:54": "With your validation data and print it out after each epoch, and epoch is what we call",
  "07:01": "it when you look at every single image in the data set once.",
  "07:06": "And so after you've looked at every image in the data set once we print out some information",
  "07:11": "about how you're doing and the most important thing we print out is the result of calling",
  "07:16": "these metrics so error rate is the name of a metric and it's a function that just prints",
  "07:21": "out what percent of the validation set are being incorrectly classified by your model.",
  "07:28": "So our metric is a function that measures the quality of the predictions using the validation",
  "07:35": "set so error rates one another common metric is accuracy which is just 1 minus error rate",
  "07:41": "so very important to remember from last week we talked about loss.",
  "07:47": "Arthur Samuel had this important idea in machine learning that we need some way to figure out",
  "07:53": "how good our how well our model is doing so that when we change the parameters we can",
  "08:00": "figure out which set of parameters make that performance measurement get better or worse,",
  "08:06": "that performance measurement is called the loss.",
  "08:09": "The loss is not necessarily the same as your metric.",
  "08:15": "The reason why is a bit subtle and we'll be seeing it in a lot of detail once we delve",
  "08:19": "into the math in the coming lessons but basically you need a function you need a loss function",
  "08:27": "where if you change the parameters by just a little bit up or just a little bit down",
  "08:32": "you can see if the loss gets a little bit better or a little bit worse and it turns",
  "08:36": "out that error rate and accuracy doesn't tell you that at all because you might change the",
  "08:42": "parameters by such a small amount that none of your dog's predictions start becoming cats",
  "08:47": "and none of your cat predictions start becoming dogs.",
  "08:50": "So like your predictions don't change so your error rate doesn't change.",
  "08:55": "Loss and metric are closely related but the metric is the thing that you care about the",
  "09:00": "loss is the thing which your computer is using as the measurement of performance to decide",
  "09:06": "how to update your parameters.",
  "09:09": "So we measure overfitting by looking at the metrics on the validation set.",
  "09:16": "So fast AI always uses the validation set to print out your metrics and overfitting",
  "09:23": "is like the key thing that machine learning is about it's all about how do we find a model",
  "09:31": "which fits the data not just for the data that we're training with but for data that",
  "09:36": "the training algorithm hasn't seen before.",
  "09:42": "So overfitting results when our model is basically \u201ccheating\u201d.",
  "09:48": "A model can cheat by saying oh I've seen this exact picture before and I remember that that's",
  "09:56": "a picture of a cat.",
  "09:57": "So it might not have learnt what cats look like in general it just remembers you know",
  "10:02": "that images one four and eight are cats and two and three and five are dogs and learns",
  "10:08": "nothing actually about what they really look like.",
  "10:11": "So that's the kind of cheating that we're trying to avoid we don't want it to memorize",
  "10:15": "our particular data set.",
  "10:18": "So we split off our validation data and what most of this are words you're seeing on the",
  "10:23": "screen are from the book okay so I just copied and pasted them.",
  "10:27": "So if we split off our validation data and make sure that our model never sees it during",
  "10:32": "training, it's completely untainted by it so we can't possibly cheat.",
  "10:37": "Not quite true!",
  "10:38": "We can cheat, the way we could cheat is we could run we could fit a model look at the",
  "10:44": "result and the validation set, change something a little bit fit another model look at the",
  "10:49": "validation set change something a little bit we could do that like a hundred times until",
  "10:54": "we find something with the validation set looks the best.",
  "10:57": "But now we might have fit the validation set, right?",
  "11:00": "So if you want to be really rigorous about this you should actually set aside a third",
  "11:06": "bit of data called the test set that is not used for training and it's not used for your",
  "11:11": "metrics.",
  "11:13": "It's actually, you don't look at it until the whole project has finished.",
  "11:16": "And this is what's used on competition platforms like Kaggle.",
  "11:20": "On Kaggle, after the competition finishes your performance will be measured against",
  "11:28": "a data set that you have never seen.",
  "11:31": "And so, that's a really helpful approach and it's actually a great idea to do that like",
  "11:38": "even if you're not doing the modeling yourself.",
  "11:41": "So if you're if you're looking at vendors and you're just trying to decide today go",
  "11:47": "with IBM or Google or Microsoft and they're all showing you how great their models are,",
  "11:53": "what you should do is you should say, \u201cOkay you go and build your models and I am going",
  "11:58": "to hang on to 10% of my data and I'm not going to let you see it at all and when you're all",
  "12:04": "finished, come back and then I'll run your model on the 10% of data you've never seen\u201d.",
  "12:10": "Now pulling out your validation and test sets is a bit subtle though.",
  "12:18": "Here's an example of a simple little data set and this comes from a fantastic blog post",
  "12:24": "that Rachel wrote that we will link to about creating effective validation sets.",
  "12:30": "And you can see basically you have some kind of seasonal data set.",
  "12:34": "Now if you just say, \u201cOkay, fas.ai, I want to model that I want to create a my dataloader",
  "12:42": "using a valid_percent of 0.2\u201d, it would do this.",
  "12:46": "It would delete randomly some of the dots, right?",
  "12:51": "Now, this isn't very helpful because it's we can still cheat because these dots are",
  "12:57": "right in the middle of other dots and this isn't what would happen in practice.",
  "13:01": "What would happen in practice is we would want to predict this is sales by date right",
  "13:05": "we want to predict the sales for next week.",
  "13:08": "Not the sales for 14 days ago 18 days ago and 29 days ago, okay?",
  "13:14": "So what you actually need to do to create an effective validation set here is not do",
  "13:17": "it randomly but instead chop off the end, right?",
  "13:23": "And so this is what happens in all Kaggle competitions pretty much that involve time,",
  "13:27": "for instance, is the thing that you have to predict is the next like two weeks or so after",
  "13:33": "the last data point that they give you and this is what you should do also for your test",
  "13:38": "set so again if you've got vendors that you're looking at you should say to them okay after",
  "13:44": "you're all done modeling we're going to check your model against data that is one week later",
  "13:49": "than you've ever seen before.",
  "13:52": "And you won't be able to retrain or anything because that's what happens in practice, right?",
  "13:56": "Okay.",
  "13:57": "There's a question, I've heard people describe overfitting as training error being below",
  "14:03": "validation error does this rule of thumb end up being roughly the same as yours?",
  "14:08": "Okay, so that's a great question.",
  "14:10": "So, I think what they mean there is training loss versus validation loss.",
  "14:16": "Because we don't print training error so we do print at the end of each epoch the value",
  "14:22": "of your loss function for the training set and the value of the loss function for the",
  "14:26": "validation set.",
  "14:29": "And if you train for long enough, that's so so if it's training mostly your training loss",
  "14:34": "will go down and your validation loss will go down.",
  "14:38": "Because by definition, loss function is defined such as a lower loss function is a better",
  "14:46": "model.",
  "14:47": "If you start overfitting, your training loss will keep going down, right?",
  "14:53": "Because like why wouldn't it?",
  "14:54": "You know, you're getting better and better parameters.",
  "14:58": "But your validation loss will start to go up because actually you started fitting to",
  "15:03": "the specific data points in the training set and so it's not going to actually get better.",
  "15:07": "It's going to get it's not going to get better for the validation set it'll start to get",
  "15:10": "worse.",
  "15:12": "However, that does not necessarily mean that you're overfitting or at least not overfitting",
  "15:18": "in a bad way as we'll see it's actually possible to be at a point where the validation loss",
  "15:25": "is getting worse but the validation accuracy or error or metric is still improving.",
  "15:32": "So I'm not going to describe how that would happen mathematically yet because we need",
  "15:36": "to learn more about loss functions but we will.",
  "15:38": "But for now just realize that the important thing to look at is your metric getting worse,",
  "15:46": "not your loss function getting worse.",
  "15:49": "Thank you for that fantastic question.",
  "15:56": "The next important thing we need to learn about is called transfer learning.",
  "16:00": "So the next line of code said learn.fine_tune.",
  "16:03": "Why does it say learn.fine_tune?",
  "16:05": "Fine tune is what we do when we are transfer learning so transfer learning is using a pre-trained",
  "16:13": "model for a task that is different to what it was originally trained for.",
  "16:17": "So more jargon to understand our jargon.",
  "16:20": "Let's look at that.",
  "16:21": "What's a pre-trained model?",
  "16:23": "So what happens is remember I told you the architecture we're using is called ResNet-34?",
  "16:28": "So when we take that ResNet-34 that's just a just a mathematical function okay with lots",
  "16:34": "of parameters that we're going to fit using machine learning.",
  "16:41": "There's a big data set called ImageNet, that contains 1.3 million pictures of a thousand",
  "16:45": "different types of thing, whether it be mushrooms or animals or airplanes or hammers or whatever.",
  "16:55": "There's a competition or there used to be a competition that runs every year to see",
  "16:58": "who could get the best accuracy on the ImageNet competition.",
  "17:02": "And the models that did really well, people would take those specific values of those",
  "17:08": "parameters and they would make them available on the internet for anybody to download.",
  "17:13": "So if you download that you don't just have an architecture now you have a trained model.",
  "17:18": "You have a model that can recognize a thousand categories of thing in images.",
  "17:26": "Which probably isn't very useful unless you happen to want something that recognizes those",
  "17:30": "exact thousand categories of thing.",
  "17:33": "But it turns out you can rather you can start with those weights in your model and then",
  "17:41": "train some more epochs on your data and you'll end up with a far far more accurate model",
  "17:48": "than you would if you didn't start with that pre- trained model and we'll see why in just",
  "17:53": "a moment, right?",
  "17:55": "But this idea of transfer learning, it's kind of, it makes intuitive sense, right?",
  "18:01": "ImageNet already has some cats and some dogs in it and it's you know it can say this is",
  "18:05": "a cat and this is a dog, but you want to maybe do something that recognizes lots of breeds",
  "18:10": "that aren't in ImageNet.",
  "18:11": "Well, for it to be able to recognize cats versus dogs versus airplanes versus hammers",
  "18:17": "it has to understand things like: what does metal look like?",
  "18:22": "What does fur look like?",
  "18:23": "What do ears look like?",
  "18:24": "You know, so it can say like oh this breed of animal, this breed of dog has pointy ears",
  "18:29": "and oh this thing is metal so it can't be a dog.",
  "18:33": "So all these kinds of concepts get implicitly learned by a pre-trained model.",
  "18:39": "So if you start with a pre-trained model then you don't have to learn all these features",
  "18:44": "from scratch, and so transfer learning is the single most important thing for being",
  "18:51": "able to use less data and less compute and get better accuracy.",
  "18:57": "So that's a key focus for the fastai library and a key focus for this course.",
  "19:03": "There's a question: I am a bit confused on the differences between loss, error, and metric.",
  "19:13": "Sure, so error is just one kind of metric so there's lots of different possible labels",
  "19:25": "you could have.",
  "19:26": "Let's say you were trying to create a model which could predict how old a cat or dog is.",
  "19:34": "So the metric you might use is: on average, how many years were you off by?",
  "19:42": "So that would be a metric.",
  "19:44": "On the other hand if you're trying to predict whether this is a cat or a dog your metric",
  "19:50": "would be: what percentage of the time am I wrong?",
  "19:54": "So that latter metric is called the error rate.",
  "19:57": "Okay so error is one particular metric.",
  "19:59": "It's a thing that measures how well you're doing and it's like it should be the thing",
  "20:05": "that you most care about.",
  "20:06": "So you write a function or use one of fastai's predefined ones which measures how well you're",
  "20:13": "doing.",
  "20:16": "Loss is the thing that we talked about in Lesson One so I'll give a quick summary but",
  "20:23": "go back to lesson one if you don't remember.",
  "20:25": "Arthur Samuel talked about how a machine learning model needs some measure of performance which",
  "20:32": "we can look at: when we adjust our parameters up or down does that measure of performance",
  "20:37": "get better or worse?",
  "20:40": "And as I mentioned earlier, some metrics possibly won't change at all if you move the parameters",
  "20:48": "up and down just a little bit.",
  "20:50": "So they can't be used for this purpose of adjusting the parameters to find a better",
  "20:55": "measure of performance.",
  "20:56": "So quite often we need to use a different function we call this the loss function and",
  "21:02": "the loss function is the measure of performance that the algorithm uses to try to make the",
  "21:06": "parameters better and it's something which should kind of track pretty closely to the",
  "21:12": "the metric you care about but it's something which, as you change the parameters a bit,",
  "21:17": "the loss should always change a bit.",
  "21:20": "And so there's a lot of hand waving there because we need to look at some of the math",
  "21:25": "of how that works and we'll be doing that in the next couple of lessons.",
  "21:29": "Thanks for their great questions.",
  "21:36": "Okay so fine tuning is a particular transfer learning technique where the -- oh and you're",
  "21:43": "still showing your picture and not the slides.",
  "21:52": "So fine-tuning is a transfer learning technique where the weights (this is not quite the right",
  "21:56": "word we should say the parameters) where the parameters of a pre-trained model are updated",
  "22:01": "by training for additional epochs using a different task to that used for pre-training.",
  "22:06": "So pre-training the task might have been ImageNet classification and then our different task",
  "22:12": "might be recognizing cats versus dogs.",
  "22:16": "So the way by default fastai does fine tuning is that we use one epoch, which, remember,",
  "22:24": "is one looking at every image in the data set once.",
  "22:28": "One epoch to fit just those parts of the model necessary to get the particular part of the",
  "22:36": "model that's especially for your data set working.",
  "22:41": "And then we use as many epochs as you asked for to fit the whole model.",
  "22:45": "And so this is more if you for those people who might be a bit more advanced we'll see",
  "22:49": "exactly how this works later on in the lessons.",
  "22:54": "So why does transfer learning work, and why does it work so well?",
  "22:58": "The best way in my opinion to look at this is to see this paper by Zeiler and Fergus,",
  "23:03": "who were actually 2012 ImageNet winners and interestingly their key insights came from",
  "23:12": "their ability to visualize what's going on inside a model.",
  "23:15": "And so visualization very often turns out to be super important to getting great results.",
  "23:21": "What they were able to do was they looked -- remember I told you like a resnet 34 has",
  "23:25": "34 layers?",
  "23:26": "They looked at something called AlexNet which was the previous winner of the competition,",
  "23:32": "which only had seven layers.",
  "23:34": "At the time that was considered huge and so they took the seven layer model and they said",
  "23:39": "what does the first layer of parameters look like?",
  "23:43": "And they figured it out how to draw a picture of them right?",
  "23:47": "And so the first layer had lots and lots of features but here are nine of them one two",
  "23:56": "three four five six seven eight nine.",
  "23:57": "And here's what nine of those pictures look like.",
  "24:01": "One of them was something that could recognize diagonal lines from top left to bottom right.",
  "24:05": "One of them could find diagonal lines from bottom left to top right.",
  "24:09": "One of them could find gradients that went from the top of orange to the bottom of blue.",
  "24:14": "Some of them were able you know, one of them was specifically for finding things that were",
  "24:19": "green, and so forth right.",
  "24:21": "So for each of these nine, they're called filters or features.",
  "24:29": "So then something really interesting they did was they looked at each one of these,",
  "24:32": "each one of these filters, each one of these features, and we'll learn kind of mathematically",
  "24:38": "about what these actually mean in the coming lessons but for now, let's just recognize",
  "24:43": "them and saying oh there's something that looks at diagonal lines and something that",
  "24:45": "looks at gradients and they found in the actual images in imagenet specific examples of parts",
  "24:54": "of photos that match that filter.",
  "24:57": "So for this top left filter here are nine actual patches of real photos that match that",
  "25:04": "filter and as you can see they're all diagonal lines.",
  "25:07": "And so here's the for the green one here's parts of actual photos that match the green",
  "25:11": "one.",
  "25:12": "So layer one is super super simple and one of the interesting things to note here is",
  "25:17": "that something that can recognize gradients and patches of color and lines is likely to",
  "25:22": "be useful for lots of other tasks as well not just imagenet.",
  "25:26": "So you can kind of see how something that can do this might also be good at many many",
  "25:32": "other computer vision tasks as well.",
  "25:36": "This is layer 2, layer 2 takes the features of layer 1 and combines them.",
  "25:43": "So it can not just find edges that can find corners or repeating curving patterns or semi",
  "25:53": "circles or full circles.",
  "25:56": "And so you can see for example here's a, it's kind of hard to exactly visualize these layers",
  "26:05": "after layer 1.",
  "26:07": "You kind of have to show examples of what the filters look like.",
  "26:10": "But here you can see examples of parts of photos that these, this layer 2 circular filter",
  "26:17": "has activated on.",
  "26:21": "And as you can see it's found things, with circles.",
  "26:24": "So interestingly this one which is this kind of blotchy gradient seems to be very good",
  "26:29": "at finding sunsets.",
  "26:31": "And this repeating vertical pattern is very good at finding, like curtains and wheat fields",
  "26:37": "and stuff.",
  "26:39": "So the further we get, layer three then gets to combine all the kinds of features in layer",
  "26:44": "two.",
  "26:46": "And remember we're only seeing so anything here are twelve of the features but actually",
  "26:50": "there's probably hundreds of them.",
  "26:51": "I don't remember exactly in alex net but there's lots.",
  "26:54": "But by the time we get to layer three by combining features from layer two it already has something",
  "27:00": "which is finding text.",
  "27:02": "So this is a feature which can find bits of image that contain text.",
  "27:08": "It's already got something which can find repeating geometric patterns.",
  "27:12": "And you see this is not just like a matching specific pixel patterns.",
  "27:18": "This is like a semantic concept.",
  "27:20": "It can find repeating circles or repeating squares or repeating hexagons.",
  "27:25": "Great.",
  "27:26": "So it's really like computing, it's not just matching a template.",
  "27:32": "And remember we know that neural networks can solve any possible computable function.",
  "27:36": "So it can certainly do that.",
  "27:39": "So layer four gets to combine all the filters from layer three anyway at once.",
  "27:45": "And so by layer four we have something that can find dog faces for instance.",
  "27:52": "So you can kind of see how each layer we get like more applicatively more sophisticated",
  "27:59": "features.",
  "28:00": "And so that's why these deep neural networks can be so incredibly powerful.",
  "28:06": "It's also why transfer learning can work so well.",
  "28:09": "Because like, if we wanted something that can find books.",
  "28:12": "And I don't think there's a book category in imagenet.",
  "28:16": "Well it's actually already got something that can find text as an earlier filter which I",
  "28:20": "guess it must be using to find maybe there's a category for library or something or a bookshelf.",
  "28:27": "So when you use transfer learning you can take advantage of all of these pre-learnt",
  "28:34": "features to find things that are as combinations of these or existing features.",
  "28:39": "That's why transfer learning can be done so much more quickly and so much less data than",
  "28:44": "traditional approaches.",
  "28:48": "One important thing to realize then is that these techniques for computer vision are not",
  "28:52": "just good at recognizing photos; there's all kinds of things you can turn into pictures,",
  "28:59": "for example these are sounds that have been turned into pictures by representing their",
  "29:07": "frequencies over time and it turns out that if you convert a sound into these kinds of",
  "29:14": "pictures you can get basically state-of-the-art results at sound detection just by using the",
  "29:21": "exact same resnet learner that we've already seen.",
  "29:25": "We need to highlight that it's 945 so if you want to take a break soon?",
  "29:32": "A really cool example from I think our very first year of running fastai; one of our students",
  "29:39": "created pictures, they worked at Splunk in anti-fraud, and they created pictures of users",
  "29:45": "moving their mouse and, if I remember correctly as they moved their mouse he basically drew",
  "29:50": "a picture of where the mouse moved and the color depended on how fast they moved and",
  "29:55": "these circular blobs is where they clicked the left or the right mouse button.",
  "30:01": "At Splunk what he did actually for the course, as a project for the course, is he tried to",
  "30:08": "see whether he could use this these pictures with exactly the same approach we saw in lesson",
  "30:14": "1 to create an anti-fraud model, and it worked so well that Splunk ended up patenting a new",
  "30:21": "product based on this technique and you can actually check it out there's a blog post",
  "30:25": "about it on the internet where they describe this breakthrough anti-fraud approach which",
  "30:30": "literally came from one of our really amazing and brilliant and creative students after",
  "30:36": "lesson one of the course.",
  "30:40": "Another cool example of this is looking at different viruses and again turning them into",
  "30:47": "pictures and you can kind of see how they've got here this is from a paper, check out the",
  "30:52": "book for the citation, they've got three examples of a particular virus called VB.AT and another",
  "30:59": "example of a particular virus called Fakerean and you can see in each case the pictures",
  "31:04": "all look kind of similar and that's why again they can get state-of-the-art results in virus",
  "31:10": "detection; by turning the program signatures into pictures and putting it through image",
  "31:17": "recognition.",
  "31:20": "So in the book you'll find a list of all of the terms, all of the most important terms,",
  "31:26": "we've seen so far and what they mean I'm not going to read through them but I want you",
  "31:30": "to please because these are the terms that we're going to be using from now on and you've",
  "31:35": "got to know what they mean because if you don't you're going to be really confused because",
  "31:41": "I'll be talking about labels and architectures and models and parameters and they have very",
  "31:45": "specific exact meanings and I'll be using those exact meanings, so please review this.",
  "31:52": "So to remind you this is where we got to; we ended up with Arthur Samuels overall approach",
  "32:01": "and we replaced his terms with our terms so we have an architecture which contains parameters",
  "32:08": "as inputs, well parameters and the data as inputs so that the architecture plus the parameters",
  "32:16": "are the model, with the inputs they used to calculate predictions, they are compared to",
  "32:22": "the labels with a loss function and that loss function is used to update the parameters",
  "32:28": "many many times to make them better and better until the loss gets nice and super low.",
  "32:35": "So this is the end of chapter 1 of the book.",
  "32:38": "It's really important to look at the questionnaire because the questionnaire is the thing where",
  "32:43": "you can check whether you have taken away from this book, this chapter the stuff that",
  "32:49": "we hope you have.",
  "32:51": "So go through it and anything that you're not sure about, the answer is in the text",
  "32:58": "so just go back to earlier in the book and in the chapter you will find the answers.",
  "33:04": "There's also a further research section after each questionnaire, for the first couple of",
  "33:09": "chapters they're actually pretty simple hopefully they're pretty fun and interesting; they're",
  "33:13": "things where to answer the question it's not enough to just look in the chapter, you actually",
  "33:18": "have to go and do your own thinking and experimenting and googling and so forth.",
  "33:24": "In later chapters some of these further research things are pretty significant projects that",
  "33:29": "might take a few days or even weeks and so check them out because hopefully they'll be",
  "33:35": "a great way to expand your understanding of the material.",
  "33:42": "So something that Sylvain points out in the book is that if you really want to make the",
  "33:45": "most of this then after each chapter please take the time to experiment with your own",
  "33:50": "project and within the books we provide and then see if you can redo the notebooks on",
  "33:57": "a new dataset.",
  "33:59": "Perhaps for chapter one that might be a bit hard because we haven't really shown how to",
  "34:02": "change things but for chapter two, which we're going to start next, you'll absolutely be",
  "34:07": "able to do that.",
  "34:09": "Okay so let's take a 5 minute break and we'll come back at 9:55 San Francisco time.",
  "34:19": "Okay so welcome back everybody and I think we've got a couple of questions to start with",
  "34:24": "so Rachel please take it away.",
  "34:26": "Sure, are filters independent by that I mean if filters are pre-trained might they become",
  "34:32": "less good and detecting features of previous images when fine-tuned?",
  "34:35": "Oh that is a great question, so assuming I understand the question correctly, if you",
  "34:43": "start with say an imagenet model and then you fine-tune it on dogs versus cats for a",
  "34:50": "few epochs and you get something that's very good at recognizing dogs versus cats it's",
  "34:56": "going to be much less good as an imagenet model after that, so it's not going to be",
  "35:00": "very good at recognizing aeroplanes or hammers or whatever.",
  "35:06": "This is called catastrophic forgetting in the literature, the idea that as you see more",
  "35:12": "images about different things to what you saw earlier that you start to forget what",
  "35:16": "the things you saw earlier are.",
  "35:19": "So if you want to fine-tune something which is good at a new task but also continues to",
  "35:26": "be good at the previous task you need to keep putting in examples of the previous task as",
  "35:31": "well.",
  "35:35": "What are the differences between parameters and hyper parameters?",
  "35:39": "If I am feeding an image of a dog as an input and then changing the hyper parameters of",
  "35:45": "batch size in the model what would be an example of a parameter?",
  "35:50": "So the parameters are the things that are described in lesson one that Arthur Samuel",
  "35:57": "described as being the things which change what the model does, what the architecture",
  "36:06": "does.",
  "36:07": "So we start with this infinitely flexible function, the thing called a neural network,",
  "36:10": "that can do anything at all and the way you get it to do one thing versus another thing",
  "36:19": "is by changing its parameters.",
  "36:21": "They are the numbers that you pass into that function so there's two types of numbers you",
  "36:26": "pass into the function: there's the numbers that represent your input, like the pixels",
  "36:31": "of your dog, and there's the numbers that represent their learnt parameters.",
  "36:39": "So in the example of something that's not a neural net, but like a checkers playing",
  "36:42": "program like Arthur Samuel might have used back in the early 60s and late 50s, those",
  "36:48": "parameters may have been things like: if there is a opportunity to take a piece versus an",
  "36:55": "opportunity to get to the end of a board how much more value should I consider one versus",
  "37:01": "the other.",
  "37:02": "You know it's twice as important or it's three times as important -- that two versus three",
  "37:06": "-- that would be an example of a parameter.",
  "37:10": "In a neural network, parameters are a much more abstract concept and so a detailed understanding",
  "37:16": "of what they are will come in the next lesson or two, but it's the same basic idea: they\u2019re",
  "37:22": "the numbers which change what the model does to be something that recognizes malignant",
  "37:30": "tumors, versus cats versus dogs versus colorizes black and white pictures.",
  "37:37": "Whereas the hyperparameter is the choices about what numbers do you pass to the function,",
  "37:46": "to the actual fitting function to decide how that fitting process happens.",
  "37:50": "There's a question, \u201cI'm curious about the pacing of this course.",
  "37:55": "I'm concerned that all the material may not be covered.\u201d",
  "37:59": "Depends what you mean by all the material.",
  "38:01": "We certainly won't cover everything in the world, so yeah we'll cover what we can.",
  "38:09": "We\u2019ll cover what we can in seven lessons; we're certainly not covering the whole book",
  "38:14": "if that's what you're wondering.",
  "38:15": "The whole book will be covered in either two or three courses.",
  "38:20": "In the past it's generally been two courses to cover about the amount of stuff in the",
  "38:23": "book but we'll see how it goes, because the book\u2019s pretty big -- 500 pages.",
  "38:29": "So when you say two courses, you mean fourteen lesson?",
  "38:32": "Fourteen, yes it would be like 14 or 21 lessons to get through the whole book.",
  "38:37": "Although having said that, by the end of the first lesson hopefully there'll be kind of",
  "38:41": "like enough momentum and understanding that reading the book independently will be more",
  "38:46": "useful and you'll have also kind of gained a community of folks on the forums that you",
  "38:52": "can hang out with and ask questions of and so forth.",
  "38:57": "So in in the second part of the course we're going to be talking about putting stuff in",
  "39:02": "production and so to do that, we need to understand like what are the capabilities and limitations",
  "39:10": "of deep learning?",
  "39:12": "What are the kinds of projects that even make sense to try to put in production?",
  "39:18": "And you know one of the key things I should mention in the book and in this course is",
  "39:21": "that the first two or three lessons and chapters, there's a lot of stuff which is designed not",
  "39:27": "just for the coders but for, for everybody.",
  "39:32": "There's lots of information about, what are the practical things you need to know to make",
  "39:36": "deep learning work.",
  "39:37": "And so one of them, things you need to know is, \u201cwell what's deep learning actually",
  "39:41": "good at at the moment?\u201d",
  "39:44": "So I'll summarize what the book says about this, but there are the kind of four key areas",
  "39:50": "that we have as applications in Fastai: computer vision, text, tabular, and what I've called",
  "39:57": "here \u201cRecsys\u201d, for recommendation systems and specifically a technique called collaborative",
  "40:01": "filtering which we briefly saw...",
  "40:03": "Sorry another question, are there any pre-trained weights available other than the ones from",
  "40:09": "Imagenet that we can use?",
  "40:11": "If yes, when should we use others and when Imagenet?",
  "40:13": "Oh that's a really great question.",
  "40:16": "So yes there are a lot of pre-trained models, and one way to find them..",
  "40:23": "And also you're currently just showing us..",
  "40:26": "Ok great.",
  "40:28": "One great way to find them is you can look up models zoo which is a common name for places",
  "40:36": "that have lots of different models.",
  "40:40": "And so here's lots of models zoos.",
  "40:43": "Or you can look for pre-trained models.",
  "40:51": "And so yeah, there's quite a few, unfortunately not as wide a variety as I would like that",
  "40:59": "most is still on Imagenet or similar kinds of general photos.",
  "41:05": "For example medical imaging there's hardly any.",
  "41:08": "There's a lot of opportunities for people to create domain-specific pre-trained models",
  "41:13": "it's it's still an area that's really underdone because not enough people are working on transfer",
  "41:17": "learning.",
  "41:19": "Okay, so as I was mentioning we've kind of got these four applications that we've talked",
  "41:27": "about a bit and deep learning is pretty, you know, pretty good at all of those tabular",
  "41:37": "data like spreadsheets and database tables is an area where deep learning is not always",
  "41:43": "the best choice but it's particularly good for things involving high cardinality variables,",
  "41:48": "that means variables that have like lots and lots of discrete levels like zip code or product",
  "41:54": "ID or something like that.",
  "41:56": "Deep learning is really pretty great for those in particular.",
  "42:02": "For text it's pretty great at things like classification and translation.",
  "42:09": "It's actually terrible for conversation and so that's that's been something that's been",
  "42:12": "a huge disappointment for a lot of companies I tried to create these like conversation",
  "42:16": "bots, but actually deep learning isn't good at providing accurate information it's good",
  "42:23": "at providing things that sound accurate and sound compelling but that we don't really",
  "42:27": "have great ways yet of actually making sure it's correct.",
  "42:34": "One big issue for recommendation systems collaborative filtering is that deep learning is focused",
  "42:40": "on making predictions which don't necessarily actually mean creating useful recommendations.",
  "42:47": "We'll see what that means in a moment.",
  "42:50": "Deep learning is also good at multimodal that means things where you've got multiple different",
  "42:57": "types of data so you might have some tabular data including a text column and an image,",
  "43:03": "then some collaborative filtering data and combining that all together is something that",
  "43:09": "deep learning is really good at.",
  "43:11": "So for example putting captions on photos is something which deep learning is pretty",
  "43:18": "good at, although again, it's not very good at being accurate.",
  "43:21": "So what you know might say this is a picture of two birds when it's actually a picture",
  "43:26": "of three birds and then this other category there's lots and lots of things that you can",
  "43:34": "do with deep learning by being creative about the use of these kinds of other application",
  "43:40": "based approaches, for example an approach that we developed for natural language processing",
  "43:45": "called ULMFit that we will be learning in the course.",
  "43:49": "It turns out that it's also fantastic you're doing protein analysis.",
  "43:52": "If you think of the different proteins as being different words and they're in a sequence",
  "43:58": "which has some kind of state and meaning it turns out that ULMFit works really well for",
  "44:03": "protein analysis.",
  "44:05": "So often it's about kind of being being creative.",
  "44:09": "So to decide like for the product that you're trying to build is deep learning gonna work",
  "44:15": "well for it, in the end you kind of just have to try it and see but if you if you do a search",
  "44:23": "you know hopefully you can find examples about the people that have tried something similar",
  "44:27": "even if you can't that doesn't mean it's not going to work.",
  "44:32": "So for example I mentioned the collaborative filtering issue where a recommendation and",
  "44:37": "a prediction are not necessarily the same thing.",
  "44:40": "You can see this on Amazon for example quite often.",
  "44:43": "So I bought a Terry Pratchett book and then Amazon tried for months to get me to buy more",
  "44:50": "Terry Pratchett books.",
  "44:51": "Now that must be because their predictive model said that people who bought one particular",
  "44:56": "Terry Pratchett book are likely to also buy a other Terry Pratchett books.",
  "45:00": "But from the point of view of like well is this going to change my buying behavior: probably",
  "45:06": "not, right, like if I liked that book I already know I like that author and I already know",
  "45:10": "that like they probably wrote other things so I'll go and buy it anyway.",
  "45:14": "So this would be an example of like Amazon probably not being very smart, up here they're",
  "45:19": "actually showing me collaborative filtering predictions rather than actually figuring",
  "45:24": "out how to optimize a recommendation.",
  "45:27": "So an optimized recommendation would be something more like your local human bookseller might",
  "45:32": "do, where they might say, \u201cOh! you like Terry Pratchett, well let me tell you about",
  "45:37": "other kind of comedy fantasy sci-fi writers on the similar vein who you might not have",
  "45:42": "heard about before\u201d.",
  "45:45": "So the difference between recommendations and predictions is super important.",
  "45:51": "So I wanted to talk about a really important issue around interpreting models and for a",
  "45:57": "case study for this I thought we let's pick something that's actually super important",
  "46:01": "right now which is a model in this paper.",
  "46:04": "One of the things we're going to try and do in this course is learn how to read papers.",
  "46:08": "So here is a paper which you I would love for everybody to read called high temperature",
  "46:14": "and high humidity reduce the transmission of COVID-19.",
  "46:16": "Now this is a very important issue because if the claim of this paper is true then that",
  "46:22": "would mean that this is going to be a seasonal disease and if this is a seasonal disease",
  "46:27": "and it's going to have massive policy implications.",
  "46:31": "So let's try and find out how this was modeled and understand how to interpret this model.",
  "46:39": "So this is a key picture from the paper and what they've done here is they've taken a",
  "46:47": "hundred cities in China and they've plotted the temperature on one axis, in Celsius, and",
  "46:53": "R on the other axis, where R is a measure of transmissibility.",
  "46:57": "It says for each person that has this disease how many people on average will they infect.",
  "47:05": "So if R is under 1, then the disease will not spread.",
  "47:08": "If R is higher than like 2 it's going to spread incredibly quickly.",
  "47:16": "Basically R is going to, you know, any high R is going to create an exponential transmission",
  "47:20": "impact.",
  "47:22": "And you can see in this case they have plotted a best fit line through here.",
  "47:29": "Then they've made a claim that there's some particular relationship in terms of a formula",
  "47:34": "that R is 1.99 minus 0.023 times temperature.",
  "47:40": "So very obvious concern I would have looking at this picture is that this might just be",
  "47:49": "random, maybe there's no relationship at all but just if you picked a hundred cities at",
  "47:55": "random perhaps they were sometimes show this level of relationship.",
  "48:01": "So one simple way to kind of see that would be to actually do it in a spreadsheet.",
  "48:08": "So here is a spreadsheet.",
  "48:11": "What I did was I kind of eyeballed this data and I guessed what is the mean degrees centigrade.",
  "48:18": "I think it's about 5.",
  "48:20": "What about the standard deviation of centigrade.",
  "48:22": "I think it's probably about 5 as well.",
  "48:26": "And then I did the same thing for R. I think the mean R looks like it's about 1.9 to me.",
  "48:31": "And it looks like the standard deviation of R is probably about 0.5.",
  "48:36": "So what I then did was I just jumped over here and I created a random normal value,",
  "48:45": "so a random value from a normal distribution, so a bell curve, with that particular mean",
  "48:51": "and standard deviation of temperature and that particular mean and standard deviation",
  "48:57": "of R. And so this would be an example of a city that might be in this data set of a hundred",
  "49:04": "cities.",
  "49:05": "Something with 9 degrees Celsius and R of 1.1; so that would be 9 degrees Celsius and",
  "49:10": "R of 1.1, something about here.",
  "49:17": "So then I just copied that formula down 100 times.",
  "49:23": "So here are a hundred cities that could be in China right, where this is assuming that",
  "49:30": "there is no relationship between temperature and R right.",
  "49:34": "They are just random numbers and so each time I recalculate that so if I hit control equals",
  "49:42": "it will just recalculate it right.",
  "49:44": "I get different numbers okay because they're random.",
  "49:49": "And so you can see at the top here I've then got the average of all of the temperatures",
  "49:56": "and the average of all of the R and the average of all the temperatures varies and the average",
  "50:03": "of all of the R varies as well.",
  "50:06": "So then what I did was I copied those random numbers over here.",
  "50:16": "let's actually do it.",
  "50:19": "So I'll go copy these 100 random numbers and paste them here here here here.",
  "50:33": "And so now I've got 1 2 3 4 5 6 I've got 6 kind of groups of 100 cities.",
  "50:42": "All right and so let's stop those from randomly changing any more by just fixing them in stone",
  "50:51": "there.",
  "50:55": "Okay, so now that I've pasted them in, I've got 6 examples of what a hundred cities might",
  "51:04": "look like if there was no relationship at all between temperature and R. I've got their",
  "51:10": "mean temperature and R in each of those six examples.",
  "51:15": "What I've done, is you can see here, at least for the first one, is I've plotted it, right?",
  "51:21": "You can see, in this case, there's actually a slight positive slope.",
  "51:27": "I've actually calculated the slope for each, just by using the slope function in Microsoft",
  "51:37": "Excel.",
  "51:38": "You can see that actually, in this particular case, is just random - five times it's been",
  "51:45": "negative, and it's even more negative than their 0.023.",
  "51:52": "So you can like, it's kind of matching our intuition here, which is that the slope of",
  "51:57": "the line that we have here, is something that absolutely can often happen totally by chance.",
  "52:04": "It doesn't seem to be indicating any kind of real relationship at all.",
  "52:09": "If we wanted that slope to be more confident, we would need to look at more cities.",
  "52:18": "Here I've got 3,000 randomly generated numbers.",
  "52:25": "You can see here the slope is 0.00002, right?",
  "52:30": "It's almost exactly zero, which is what we'd expect, when there's actually no relationship",
  "52:35": "between C and R, and in this case there isn't - they're all random . Then if we look at",
  "52:40": "lots and lots of randomly generated cities, then we can say, oh yeah, there's no slope.",
  "52:45": "But when you only look at a hundred, as we did here, you're going to see relationships",
  "52:51": "totally coincidentally, very, very often.",
  "52:55": "So that's something that we need to be able to measure.",
  "52:59": "One way to measure that is we use something called a p-value.",
  "53:02": "A p-value, here's how a p-value works: we start out with something called a null hypothesis.",
  "53:08": "The null hypothesis is basically what's our starting point assumption.",
  "53:15": "Our starting point assumption might be, oh there's no relationship between temperature",
  "53:19": "and R. And then we gather some data and (Rachel: have you explained what R is?)",
  "53:23": "I have, yes.",
  "53:24": "R is the transmissibility of the virus.",
  "53:29": "So then we gather data of independent and dependent variables - in this case the independent",
  "53:33": "variable is the thing that we think might cause the dependent variable.",
  "53:38": "Here the independent variable would be temperature, the dependent variable would be R. So here",
  "53:42": "we've gathered data - there's the data that was gathered in this example, and then we",
  "53:48": "say what percentage of the time would we see this amount of relationship, which is a slope",
  "53:53": "of 0.023 by chance?",
  "53:57": "And as we've seen, one way to do that is by, what we would call, a simulation, which is",
  "54:01": "by generating random numbers - a 100 set pairs of random numbers, a bunch of times, and seeing",
  "54:07": "how often you see this relationship.",
  "54:12": "We don't actually have to do it though.",
  "54:13": "There's actually a simple equation we can use to jump straight to this number, which",
  "54:19": "is, what percent of the time would we see that relationship by chance?",
  "54:27": "And this is basically what that looks like.",
  "54:30": "We have the most likely observation, which in this case would be if there is no relationship",
  "54:37": "between temperature.",
  "54:38": "Then the most likely slope would be zero, and sometimes you get positive slopes by chance,",
  "54:46": "and sometimes you get pretty small slopes, and sometimes you get large negative slopes",
  "54:53": "by chance.",
  "54:54": "And so, the larger the number, the less likely it is to happen, whether it be on the positive",
  "54:59": "side or the negative side.",
  "55:01": "In our case, our question was - how often are we going to get less than negative 0.023?",
  "55:08": "It would actually be somewhere down here.",
  "55:11": "I actually copy this from Wikipedia, where they were looking for positive numbers, and",
  "55:15": "so they've colored in this area above the number.",
  "55:19": "This is the p-value, and we don't care about the math but there's a simple little equation",
  "55:24": "you can use to directly figure out this number - the p-value - from the data.",
  "55:35": "This is kind of how nearly all kind of medical research results tend to be shown, and folks",
  "55:43": "really focus on this idea of p-values.",
  "55:46": "And indeed, in this particular study as we\u2019ll see in a moment, they reported p-values.",
  "55:51": "Probably a lot of you have seen p-values in your previous lives.",
  "55:56": "They come up in a lot of different domains.",
  "55:59": "Here's the thing - they are terrible.",
  "56:03": "You almost always shouldn't be using them.",
  "56:06": "Don't just trust me.",
  "56:08": "Trust the American Statistical Association.",
  "56:11": "They point out six things about p-values, and those include: p-values do not measure",
  "56:17": "the probability that the hypothesis is true, or, the probability that the data were produced",
  "56:23": "by random choice alone.",
  "56:25": "Now we know this because we just saw that, if we use more data, if we sample three thousand",
  "56:33": "random cities rather than a hundred, we get a much smaller value.",
  "56:40": "So p-values don't just tell you about how big a relationship is, but they actually tell",
  "56:44": "you about a combination of that, and, how much data did you collect.",
  "56:48": "So they don't measure the probability that the hypothesis is true.",
  "56:53": "So therefore, conclusions and policy decisions should not be based on whether a p-value passes",
  "56:59": "some threshold.",
  "57:01": "P-value does not measure the importance of a result, because, again, it could just tell",
  "57:09": "you that you collected lots of data, which doesn't tell you that the results are actually",
  "57:13": "of any practical import.",
  "57:15": "By itself, it does not provide a good measure of evidence.",
  "57:21": "Frank Harrell, who is somebody whom I read his book, and it's a really important part",
  "57:27": "of my learning.",
  "57:28": "He's a professor of biostatistics, has a number of great articles about this.",
  "57:34": "He says null hypothesis testing and p-values have done significant harm to science.",
  "57:39": "He wrote another piece called \u201cnull hypothesis significance testing never worked\u201d.",
  "57:48": "I've shown you what p-values are so that you know why they don't work, not so that you",
  "57:53": "can use them.",
  "57:54": "But they're a super important part of machine learning because they come up all the time.",
  "58:00": "When people are saying, this is how we decide whether your drug worked, or whether there",
  "58:07": "is an epidemiological relationship, or whatever.",
  "58:11": "And indeed, p-values appear in this paper.",
  "58:16": "In the paper, they show the results of a multiple linear regression.",
  "58:22": "They put three stars next to any relationship which has a p-value of 0.01 or less.",
  "58:35": "There is something useful to say about a small p-value, like 0.01 or less.",
  "58:41": "Which is the thing that we're looking at did not, probably did not happen by chance, right?",
  "58:45": "The biggest statistical error people make all the time is that they see that a p-value",
  "58:51": "is not less than 0.05 and then they make the erroneous conclusion that no relationship",
  "58:59": "exists, right?",
  "59:02": "Which doesn't make any sense because like let's say you only had like three data points",
  "59:06": "then you almost certainly won't have enough data to have a p-value of less than 0.05 for",
  "59:12": "any hypothesis.",
  "59:14": "So like the way to check, is to go back and say, what if I picked the exact opposite null",
  "59:19": "hypothesis?",
  "59:20": "What if my null hypothesis was there is a relationship between temperature and R?",
  "59:25": "Then do I have enough data to reject that null hypothesis, alright?",
  "59:31": "And if the answer is no, then you just don't have enough data to make any conclusions at",
  "59:37": "all, alright?",
  "59:39": "So in this case they do have enough data to be confident that there is a relationship",
  "59:45": "between temperature and R. Now that's weird because we just looked at the graph, and we",
  "59:52": "did a little back of a bit of a back-of-the-envelope in Excel and we thought this is, could it,",
  "59:57": "could well be random.",
  "60:00": "So here's where the issue is.",
  "60:03": "The graph shows what we call a univariate relationship.",
  "60:06": "A univariate relationship shows the relationship between one independent variable and one dependent",
  "60:12": "variable, and that's what you can normally show on a graph.",
  "60:15": "But in this case they did a multivariate model in which they looked at temperature, and humidity,",
  "60:21": "and GDP per capita, and population density, and when you put all of those things into",
  "60:28": "the model then you end up with statistically significant results for temperature and humidity.",
  "60:34": "Why does that happen?",
  "60:35": "Well the reason that happens is because all these variations in the blue dots, is not",
  "60:42": "random.",
  "60:44": "There's a reason they're different, right?",
  "60:46": "And the reasons include, denser cities are going to have higher transmission, for instance,",
  "60:52": "and probably more humid will have less transmission.",
  "60:56": "So when you do a multivariate model, it actually allows you to be more confident of your results,",
  "61:08": "right?",
  "61:10": "But the p-value as noted by the American Statistical Association does not tell us whether this",
  "61:15": "is of practical importance.",
  "61:18": "The thing that tells us if this is of practical as importance, is the actual slope that's",
  "61:23": "found.",
  "61:24": "And so in this case the equation they come up with is that R = three point nine six eight",
  "61:32": "minus three point O point O three eight by temperature minus point zero two four by relative",
  "61:38": "humidity this is this equation is this practically important.",
  "61:42": "Well we can again do a little back of the envelope here, by just putting that into Excel.",
  "61:52": "Let's say there was one place it had a temperature of ten centigrade and a humidity of forty,",
  "61:57": "then if this equation is correct R would be about two point seven somewhere with the temperature",
  "62:03": "of 35 centigrade and a humidity of eighty will be about point eight.",
  "62:09": "So is this practically important?",
  "62:11": "Oh my god yes, right?",
  "62:14": "Two different cities, with different climates can be, if they're the same in every other",
  "62:19": "way, and this model is correct then one city would have no spread of disease (because R",
  "62:25": "is less than 1), one would have massive exponential explosion.",
  "62:30": "So we can see from this model that if the modeling is correct, then this is a highly",
  "62:37": "practically significant result.",
  "62:39": "So this is how you determine practical significance of your models is not with p-values but with",
  "62:46": "looking at kind of actual outcomes.",
  "62:49": "So how do you think about the practical importance of a model and how do you turn a predictive",
  "62:58": "model into something useful in production.",
  "63:01": "So I spent many many years thinking about this, and I actually created a with some other",
  "63:09": "great folks actually created a paper about it.",
  "63:13": "\"Designing Great Data Products\" And this is largely based on ten years of work I did at",
  "63:24": "a company I founded called Optimal Decisions Group.",
  "63:27": "And Optimal Decisions Group was focused on the question of helping insurance companies",
  "63:32": "figure out what prices to set.",
  "63:34": "And insurance companies up until that point had focused on predictive modeling.",
  "63:40": "Actuaries, in particular, spent their time trying to figure out how likely is it that",
  "63:47": "you're going to crash your car and if you do how much damage might you have and then",
  "63:52": "based on that try to figure out what price they should set for your policy.",
  "63:57": "So for this company, what we did was we decided to use a different approach which I ended",
  "64:03": "up calling the drivetrain approach which is described here to set insurance prices and",
  "64:10": "indeed to do all kinds of other things.",
  "64:12": "And so, for the Insurance example, the objective would be for an insurance company would be",
  "64:19": "how do I maximize my, let's say, five-year profit.",
  "64:24": "And then, what inputs can we control can we control which what I call levers - so in this",
  "64:30": "case it would be what price can I set.",
  "64:33": "And then data is data which can tell you as you change your levers how does that change",
  "64:39": "your objective.",
  "64:40": "So if I start increasing my price to people who are likely to crash their car, then we",
  "64:45": "will get less of them which means we have less costs, but at the same time, we'll also",
  "64:50": "have less revenue coming in, for example.",
  "64:53": "So to link up there kind of the levers to the objective via the data we collect, we",
  "64:58": "build models that described how the levers influence the objective.",
  "65:02": "And this is all like it seems pretty obvious when you say it like this but when we started",
  "65:08": "work with Optimal Decisions in 1999, nobody was doing this in insurance, Everybody in",
  "65:14": "insurance was simply doing a predictive model to guess how likely people were to crash their",
  "65:20": "car, and then pricing was set by like adding 20% or whatever.",
  "65:26": "It was just done in a very kind of naive way.",
  "65:30": "So what I did is I, you know, over many years took this basic process and tried to help",
  "65:37": "lots of companies figure out how to use it to turn predictive models into actions.",
  "65:44": "So the starting point in like actually getting value in a particular model is thinking about",
  "65:50": "what is it you're trying to do, and you know what are the sources of value in that thing",
  "65:53": "you're trying to do.",
  "65:55": "The levers - what are the things you can change?",
  "65:57": "Like what's the point of a predictive model if you can't do anything about it, right?",
  "66:03": "Figuring out ways to find what data you, you don't have, which ones suitable, what's available,",
  "66:06": "then thinking about what approaches to analytics you can then take.",
  "66:11": "And then super important, like well, can you actually implement, you know, those changes.",
  "66:18": "And super super important how do you actually change things as the environment changes.",
  "66:23": "And, you know, interestingly a lot of these things are areas where there's not very much",
  "66:26": "academic research.",
  "66:28": "There's a little bit.",
  "66:32": "And some of the papers that have been particularly around \u201cmaintenance\u201d of like; How do you",
  "66:35": "decide when your machine learning model is kind of still okay?",
  "66:40": "How do you update it over time?",
  "66:41": "Have had like many many many many citations, but they don't pop up very often because a",
  "66:48": "lot of folks are so focused on the math.",
  "66:50": "You know.",
  "66:52": "And then there's the whole question of like \u201cWhat constraints are in place across this",
  "66:55": "whole thing?\u201d",
  "66:56": "So what you'll find in the book, is there is a whole appendix which actually goes through",
  "67:00": "every one of these six things.",
  "67:03": "And has a whole list of examples.",
  "67:07": "So this is an example of how to like think about value.",
  "67:13": "And lots of questions that companies and organizations can use to try and think about, you know,",
  "67:21": "all of these different pieces of the actual puzzle of getting stuff into production and",
  "67:26": "actually into an effective product.",
  "67:28": "We have a question.",
  "67:29": "Sure, just a moment.",
  "67:31": "So I was going to say, so do check out this appendix because it actually originally appeared",
  "67:35": "as a blog post and I think, except for my covid-19 posts that I did with Rachel, it's",
  "67:41": "actually the most popular blog post I've ever written.",
  "67:44": "It\u2019s had hundreds of thousands of views.",
  "67:45": "And it kind of represents like 20 years of hard won insights about like how you actually",
  "67:53": "get value from machine learning and practice and what you actually have to ask.",
  "67:57": "So please check it out because hopefully you'll find it helpful.",
  "68:00": "So when we think about like think about this for the question of how should people think",
  "68:06": "about the relationship between seasonality and transmissibility of covid-19, you kind",
  "68:14": "of need to dig really deeply into the questions about like oh not just what what's that what",
  "68:20": "are those numbers in the data, but what does it really look like right.",
  "68:23": "So one of the things in the paper that they show is actual maps, right of temperature",
  "68:29": "and humidity and R right.",
  "68:34": "And you can see like, not surprisingly, that humidity and temperature in China are what",
  "68:41": "we would call auto-correlated.",
  "68:43": "Which is to say that places that are close to each other, in this case geographically,",
  "68:47": "have similar temperatures and similar humidities.",
  "68:52": "And so like this actually puts into the question a lot the p values that they have right.",
  "69:00": "Because you can't really think of these as a hundred totally separate cities.",
  "69:04": "Because the ones that are close to each other probably have very close behavior so maybe",
  "69:08": "you should think of them as like a small number of sets of cities, you know of kind of larger",
  "69:14": "geographies.",
  "69:17": "So these are the kinds of things that when you look actually into a model you need to",
  "69:21": "like think about what are, what are the limitations?",
  "69:24": "But then to decide like well, what does that mean?",
  "69:26": "What do I what do about that?",
  "69:30": "You need to think of it from this kind of utility point of view, this kind of end to",
  "69:37": "end, what are the actions I can take?",
  "69:39": "What are the order the results point of view?",
  "69:40": "Not just null hypothesis testing.",
  "69:43": "So in this case for example there are basically four possible key ways this could end up.",
  "69:52": "It could end up that there really is a relationship between temperature and R, or so that's but",
  "70:01": "the right hand side is.",
  "70:02": "Or there is no real relationship between temperature and R. And we might act on the assumption",
  "70:09": "that there is a relationship.",
  "70:10": "Or we might act on the assumption that there isn't a relationship.",
  "70:14": "And so you kind of want to look at each of these four possibilities and say like well",
  "70:18": "what would be the economic and societal consequences?",
  "70:23": "And you know there's gonna be a huge difference in lives lost and you know economies crashing",
  "70:29": "and whatever else - you know for each of these four.",
  "70:36": "The paper actually you know has shown, if their model is correct, what's the likely",
  "70:42": "R value in March for like every city in the world.",
  "70:47": "And the likely R value in July for every city in the world.",
  "70:51": "And so for example if you look at kind of New England and New York, the prediction here",
  "70:56": "is and also West, the other the very coast of the west coast is that in July the disease",
  "71:02": "will stop spreading.",
  "71:04": "Now you know if that happens, if they're right then, that's gonna be a disaster because I",
  "71:10": "think it's very likely in America and also the UK, that people will say \u201cOh turns out",
  "71:17": "this disease is not a problem you know.",
  "71:19": "It didn't really take off at all.",
  "71:21": "The scientists were wrong.\u201d",
  "71:23": "People will go back to their previous day-to-day life and we could see what happened in 1918",
  "71:28": "flu virus of like the second go around.",
  "71:32": "When winter hits could be much worse than the start right.",
  "71:38": "So like there's these kind of like huge potential policy impacts depending on whether this is",
  "71:45": "true or false.",
  "71:47": "And so to think about it.",
  "71:49": "Yes?",
  "71:50": "I also just wanted to say that it would be it would be very irresponsible to think \u201coh",
  "71:55": "summer\u2019s gonna solve it.",
  "71:57": "We don't need to act now.\u201d",
  "71:58": "Just in that this is something growing exponentially and could do a huge huge amount of damage.",
  "72:04": "Yeah yes okay.",
  "72:05": "It already has done by the way.",
  "72:08": "If you assume that there will be seasonality and that summer will fix things then it could",
  "72:14": "lead you to be apathetic now.",
  "72:16": "If you assume there's no seasonality and then there is, then you could end up kind of creating",
  "72:23": "a larger level of expectation of destruction that actually happens and end up with your",
  "72:28": "population being even more apathetic you know so that they're you know.",
  "72:32": "Being wrong in any direction could be a problem.",
  "72:35": "So one of the ways we tend to deal with this, with with this kind of modeling is we try",
  "72:40": "to think about priors.",
  "72:42": "So our priors are basically things where we, you know rather than just having a null hypothesis,",
  "72:47": "we try and start with a guess as to like well what's what's more likely?",
  "72:51": "Right so in this case if memory serves correctly I think we know that like flu viruses become",
  "72:58": "inactive at 27 centigrade we know that like cold, the cold coronaviruses are seasonal.",
  "73:08": "The 1918 flu pandemic was seasonal.",
  "73:13": "In every country and city that\u2019s been studied so far, there's been quite a few studies like",
  "73:18": "this.",
  "73:19": "They've always found climate relationships so far.",
  "73:21": "So maybe we'd say: \u201cWell prior belief is that this thing is probably seasonal.\u201d",
  "73:27": "And so then we\u2019d say: \u201cWell this particular paper adds some evidence to that.\u201d",
  "73:32": "So it shows how incredibly complex it is to use a model in practice for in this case policy",
  "73:43": "discussions but also for organizational decisions.",
  "73:47": "Because, you know, there's always complexities, there's always uncertainties.",
  "73:52": "And so you actually have to think about the utilities, you know.",
  "73:57": "And your best guesses and try to combine everything together as best as you can.",
  "74:01": "Okay.",
  "74:02": "So with all that said.",
  "74:08": "It's still nice to be able to get our models up and running even if, you know - even just",
  "74:15": "a predictive model is sometimes useful on its own.",
  "74:19": "Sometimes it's useful to prototype something, and sometimes it's got to be part of some",
  "74:24": "bigger picture.",
  "74:26": "So rather than try to create some huge end-to-end model here.",
  "74:29": "We thought we would just show you how to get your Pytorch FastAI model up-and-running.",
  "74:39": "In as raw a form as possible.",
  "74:42": "So that from there, you can kind of build on top of it, as you like.",
  "74:46": "So to do that; we are going to download and curate our own dataset.",
  "74:53": "And you're going to do the same thing.",
  "74:54": "You're going to train your own model, on that dataset, and then you're going to create an",
  "75:00": "application, and then you're going to host it.",
  "75:04": "Right?",
  "75:05": "Now, there're lots of ways to curate an image dataset; you might have some photos on your",
  "75:10": "own computer, there might be stuff at work you can use.",
  "75:16": "One of the easiest though, is just to download stuff off the internet.",
  "75:18": "There\u2019s lots of services for downloading stuff off the internet.",
  "75:22": "We're going to be using Bing Image Search here.",
  "75:26": "Because they're super easy to use.",
  "75:27": "A lot of the other kind of easy to use things require breaking the Terms of Service of websites.",
  "75:34": "So we're not going to show you how to do that.",
  "75:37": "But there\u2019s lots of examples that do show you how to do that.",
  "75:41": "So you can check them out as well, if you want to.",
  "75:44": "Bing Image Search is actually pretty great at least at the moment.",
  "75:47": "These things change a lot, so keep an eye on our website to see if we've changed our",
  "75:53": "recommendation.",
  "75:54": "The biggest problem with Bing Image Search is that the signup process is a nightmare,",
  "76:01": "at least at the moment.",
  "76:03": "One of the hardest parts of this book is just signing up to their damn API.",
  "76:08": "Which requires going through Azure.",
  "76:09": "It's called Cognitive Services - Azure Cognitive Services.",
  "76:12": "So we'll make sure that all that information is on the website for you to follow through",
  "76:16": "just how to sign up.",
  "76:18": "So we're going to start from the assumption that you've already signed up.",
  "76:25": "But you can find it, just go: Bing, Bing Image Search API.",
  "76:33": "And at the moment they give you seven days with a pretty high quota for free.",
  "76:40": "And then after that, you can keep using it as long as you like but they kind of limit",
  "76:48": "it to like three transactions per second or something.",
  "76:51": "Which is still plenty.",
  "76:52": "You can still do thousands for free so it's at the moment it's pretty great even for free.",
  "76:59": "So what will happen is when you sign up for Bing Image Search, or any of these kind of",
  "77:05": "services, they'll give you an API key.",
  "77:07": "So just replace the \u2018XXX\u2019 here with the API key that they give you.",
  "77:12": "Okay, so that's now going to be called \u201ckey\u201d.",
  "77:15": "In fact, let's do it over here.",
  "77:19": "Okay, so you'll put in your key and then there's a function we've created called search_images_bing",
  "77:28": "which is just a super tiny little function.",
  "77:32": "As you can see, it's just two lines of code -- I was just trying to save a little bit",
  "77:37": "of time, which will take some take your API key and some search term and return a list",
  "77:43": "of URLs that match that search term.",
  "77:47": "As you can see for using this particular service you have to install a particular package,",
  "77:57": "so we show you how to do that on the site as well.",
  "78:01": "So once you've done so you'll be able to run this and that will return by default I think",
  "78:06": "150 URLs.",
  "78:09": "Okay, so fast.ai comes with a download_url function, so let's just download one of those",
  "78:15": "images just to check and open it up.",
  "78:18": "And so what I did was I searched for \u201cgrizzly bear\u201d and here I have a grizzly bear.",
  "78:25": "So then what I did was I said, okay, let's try and create a model that can recognize",
  "78:30": "grizzly bears versus black bears versus teddy bears, so that way I can find out.",
  "78:35": "I could set up some video recognition system near our campsite when we're out camping that",
  "78:43": "gives me bear warnings, but if it's a teddy bear coming then it doesn't warn me and wake",
  "78:47": "me up, because that would not be scary at all.",
  "78:49": "So then I just go through each of those three bear types, create a directory with the name",
  "78:56": "of grizzly or black or teddy bear searched Bing for that particular search term along",
  "79:04": "with bear and download.",
  "79:06": "And so download_images is a fast.ai function as well.",
  "79:11": "So after that I can call get_image_files which is a fast.ai function that will just return",
  "79:17": "recursively all of the image files inside this path.",
  "79:21": "And you can see it's given me bears/black/ and then lots of numbers.",
  "79:28": "So one of the things you have to be careful of is that a lot of the stuff you download",
  "79:32": "will turn out to be like not images at all and will break.",
  "79:36": "So you can call verify_images to check that all of these file names are actual images.",
  "79:44": "And in this case I didn't have any failed, so there's it's empty.",
  "79:48": "But if you did have some, then you would call Path.unlink to unlink.",
  "79:55": "Path.unlink is part of the Python standard library and it deletes a file.",
  "79:59": "And map is something that will call this function for every element of this collection.",
  "80:07": "This is part of a special fast.ai class called \u201cL\u201d.",
  "80:13": "It\u2019s basically it's kind of a mix between the Python standard library list class and",
  "80:19": "a numpy array class, Then we'll be learning more about it later in this course, but it",
  "80:24": "basically tries to make it super easy to do kind of more functional-style programming",
  "80:29": "in Python.",
  "80:31": "So in this case it's going to unlink everything that's in the failed list, which is probably",
  "80:37": "what we want now, because there are all the images that fail to verify.",
  "80:41": "All right, so we've now got a path that contains a whole bunch of images and they're classified",
  "80:49": "according to black, grizzly, or teddy, based on what folder they're in. and so to create",
  "80:56": "so we're going to create a model.",
  "80:57": "and so to create a model the first thing we need to do is to tell fast.ai what kind of",
  "81:05": "data we have and how it\u2019s structured.",
  "81:09": "Now in part in Lesson 1 of the course we did that by using what we call a factory method",
  "81:16": "which is we just said image_data_loader start from name, and it did it all for us.",
  "81:23": "Those factory methods are fine for beginners, but now we're into Lesson 2.",
  "81:29": "We're not quite beginners anymore, so we're going to show you the super super flexible",
  "81:32": "way to use data in whatever format you like, and it's called the DataBlock API.",
  "81:39": "And so the DataBlock API  looks like this.",
  "81:46": "Here's the DataBlock API.",
  "81:50": "You tell fast.ai what your independent variable is and what your dependent variable is.",
  "81:56": "So what your labels are and what your input data is.",
  "81:59": "So in this case our input data are images and our labels are categories.",
  "82:05": "So category is going to be either grizzly, or black, or teddy.",
  "82:12": "So that's the first thing you tell it.",
  "82:13": "Now that's the block's parameter.",
  "82:15": "And then you tell it - how do you get a list of all of the, in this case file names, right.",
  "82:20": "And we just saw how to do that because we just called the function ourselves.",
  "82:23": "The function is called get_image_files.",
  "82:25": "So we tell it what function to use to get that list of items and then you tell it - how",
  "82:31": "do you split the data into a validation set and a training set.",
  "82:35": "And so we're going to use something called a RandomSplitter which just splits it randomly.",
  "82:40": "And we're going to point 30% of it into the validation set.",
  "82:42": "We're also going to set the random seed which ensures that every time we run this, the validation",
  "82:47": "set will be the same.",
  "82:50": "And then you say, okay, how do you label the data.",
  "82:53": "And this is the name of a function called parent_label.",
  "82:56": "And so that's going to look for each item at the name of the parent.",
  "83:02": "So this, this particular one would become a black bear.",
  "83:05": "Now this is like the most common way for image datasets to be represented, is that they get",
  "83:12": "put the different images get the files get put into folder according to their label.",
  "83:19": "And then finally here we've got something called item_tfms.",
  "83:22": "We'll be learning a lot more about transforms in a moment.",
  "83:25": "That these are basically functions that get applied to each image.",
  "83:28": "And so each image is going to be resized to 128 by 128 square.",
  "83:36": "So we're going to be learning more about DataBlock API soon.",
  "83:40": "But basically the process is going to be -- it's going to call whatever is get_items, which",
  "83:43": "is a list of image files.",
  "83:44": "And then it\u2019s going to call get_x, get_y so in this case there's no get_x but there",
  "83:50": "is a get_y so it's just parent label.",
  "83:53": "And then it's going to call the create method for each of these two things - it's going",
  "83:56": "to create an image and it's going to create a category.",
  "83:58": "And so I'm going to call the item_tfms, which is resize.",
  "84:03": "And then the next thing it does is it puts it into something called a data loader.",
  "84:07": "A data loader is something that grabs a few images at a time (I think by default it\u2019s",
  "84:13": "64) and puts them all into a single, it's called a batch.",
  "84:16": "It just grabs 64 images and sticks them all together.",
  "84:20": "And the reason it does that is it then puts them all onto the GPU at once so it can pass",
  "84:26": "them all to the model through the GPU in one go.",
  "84:30": "And that's going to let the GPU go much faster, as we'll be learning about.",
  "84:34": "And then finally (we don't use any here), we can have something called batch transforms,",
  "84:40": "which we will talk about later.",
  "84:42": "And then somewhere in the mineral about here conceptually is the splitter which is the",
  "84:47": "thing that splits into the training set and the validation set.",
  "84:52": "So this is a super flexible way to tell fast.ai how to work with your data.",
  "84:59": "And so at the end of that it returns an object of type DataLoaders.",
  "85:06": "That's why we always call these things DLs, right.",
  "85:09": "So, DataLoaders has a validation and a training DataLoader.",
  "85:14": "And a DataLoader as I just mentioned is something that grabs a batch of a few items at a time",
  "85:20": "and puts it on the GPU for you.",
  "85:23": "So this is basically the entire code of DataLoaders.",
  "85:28": "So the details don't matter, I just wanted to point out that like a lot of these concepts",
  "85:32": "in fast.ai, when you actually look at what they are, they\u2019re incredibly simple little",
  "85:37": "things.",
  "85:38": "It's literally something that you just pass in a few data loaders to and it stores them",
  "85:41": "in an attribute.",
  "85:42": "And pass and gives you the first one back as .train and second one back as .valid.",
  "85:50": "So we can create our DataLoaders by first of all creating the DataBlock ,and then we",
  "85:58": "call the DataLoaders, passing in our path to create DLs.",
  "86:03": "And then you can call show_batch on that.",
  "86:05": "You can call show_batch pretty much anything in fast.ai to see your data.",
  "86:08": "And look, we've got some grizzlies, we've got a teddy, we've got a grizzly.",
  "86:15": "So you get the idea right.",
  "86:18": "I'm going to look at these different, I'm going to look at data augmentation next week",
  "86:23": "so, I'm going to skip over data augmentation and let's just jump straight into trading",
  "86:27": "your model.",
  "86:32": "So once we've got DLs, we can just like in Lesson 1, call cnn_learner to create a ResNet.",
  "86:39": "We\u2019're going to create a smaller ResNet this time, a ResNet18.",
  "86:43": "Again, asking for error rate, we can then call .fine_tune again.",
  "86:47": "So you see it's all the same lines of code we've already seen.",
  "86:51": "And you can see our error rate goes down from nine to one, so we've got 1% error and after",
  "86:57": "training for about 25 seconds.",
  "87:00": "So you can see you know we've only got 450 images we've trained for well less than a",
  "87:05": "minute and we only have let's look at the confusion matrix so we can say, \u201cI want",
  "87:12": "to create a classification interpretation class; I want to look at the confusion matrix\u201d",
  "87:16": "and the confusion matrix, as you can see, it's something that says \u201cfor things that",
  "87:21": "are actually black bears, how many are predicted to be black bears versus grizzly bears versus",
  "87:29": "teddy bears?\u201d",
  "87:30": "So, the diagonal are the ones that are all correct and so it looks like we've got two",
  "87:34": "errors.",
  "87:35": "We've got one grizzly that was predicted to be black and one black that was predicted",
  "87:39": "to be grizzly.",
  "87:40": "A super, super useful method is \u201cplot top losses\u201d and that'll actually show me what",
  "87:49": "my errors actually look like.",
  "87:51": "So, this one here was predicted to be a grizzly bear but the label was \u201cblack bear\u201d.",
  "87:57": "This one was the one that's predicted to be a black bear and the label was \u201cgrizzly",
  "88:01": "bear\u201d.",
  "88:02": "These ones here are not actually wrong.",
  "88:05": "This is predicted to be \u201cblack\u201d and it's actually black.",
  "88:07": "But, the reason they appear in this is because these are the ones that the model was the",
  "88:14": "least confident about.",
  "88:15": "Okay, so we're going to look at the image classifier cleaner next week.",
  "88:21": "Let's focus on how we then get this into production.",
  "88:25": "So, to get it into production, we need to export the model.",
  "88:32": "So, what exporting the model does is that it creates a new file, which by default is",
  "88:37": "called \u201cexport.pkl\u201d, which contains the architecture and all of the parameters of",
  "88:44": "the model.",
  "88:45": "So, that is now something that you can copy over to a server somewhere and treat it as",
  "88:52": "a predefined program, right?",
  "88:55": "So, then the process of using your trained model on new data kind of in production is",
  "89:04": "called \u201cinference\u201d.",
  "89:05": "So, here I've created an inference learner by loading that learner back again, all right,",
  "89:12": "and so obviously it doesn't make sense to do it right next to after I've saved it in",
  "89:17": "a notebook.",
  "89:18": "But, I'm just showing you how it would work right.",
  "89:20": "So, this is something that you would do on your server- inference.",
  "89:25": "Remember that once you have trained a model, you can just treat it as a program- you can",
  "89:30": "pass inputs to it.",
  "89:32": "So, this is now our program.",
  "89:34": "This is our bear predictor.",
  "89:35": "So, I can now call \u201cpredict\u201d on it and I can pass it an image and it will tell me-",
  "89:44": "here it is 99.999% sure- that this is a \u201cgrizzly\u201d.",
  "89:49": "So, I think what we're going to do here is we're going to wrap it up here and next week",
  "89:56": "we'll finish off by creating an actual GUI for our bear classifier.",
  "90:05": "We will show how to run it for free on a service called \u201cBinder\u201d and, yeah, and then I",
  "90:18": "think we'll be ready to dive into some of the details of what's going on behind the",
  "90:23": "scenes.",
  "90:25": "Any questions or anything else before we wrap up, Rachel?",
  "90:29": "No.",
  "90:30": "Okay, great.",
  "90:31": "All right, thanks everybody.",
  "90:34": "So, we hopefully, yeah, I think from here on we've covered, you know, most of the key",
  "90:45": "kind of underlying foundational stuff from a machine-learning point of view that we're",
  "90:49": "going to need to cover.",
  "90:50": "So, we'll be able to, ready to dive into lower-level details of how deep learning works behind",
  "90:58": "the scenes and I think that'll be starting from next week.",
  "91:03": "So, see you then."
}