{
  "00:02": "Hi everybody and welcome to Lesson 6, where we're going to continue looking at training",
  "00:08": "convolutional neural networks for computer vision, and so we last looked at this the",
  "00:14": "lesson before last, and specifically we were looking at how to train an image classifier",
  "00:19": "to pick out breeds of pet, one of 37 breeds of pet, and we've gotten as far as training",
  "00:27": "a model. We also had to look and figure out what loss function was actually being used",
  "00:33": "in this model. And so we talked about Cross-entropy loss, which is actually a really important",
  "00:38": "concept and some of the things we'll talk about today depend a bit on you understanding",
  "00:42": "this concept. So if you were at all unsure about where we got to with that, go back and",
  "00:48": "have another look. Have a look at the questionnaire particular, and make sure that you're comfortable",
  "00:54": "with Cross-entropy loss, if you're not you may want to go back to the 04_mnist_basics",
  "00:59": "notebook, and remind yourself about MNIST loss, because it's very, very similar. That's",
  "01:05": "what we have built on, to build-up Cross-entropy loss. So having trained our model, the next",
  "01:12": "thing we're going to do is look at model interpretation. There's not much point having a model if you",
  "01:17": "don't see what it's doing and one thing we can do is use a confusion matrix, which in",
  "01:25": "this case is not terribly helpful. There's a kind of a few too many, and it's not too",
  "01:29": "bad, we can kind of see some colored areas, and so this diagonal here all the ones that",
  "01:34": "are classified correctly. So for Persians there were 31 classified as Persians, but",
  "01:40": "we can see there's some bigger numbers here, like a Siamese, 6 were misclassified they",
  "01:45": "actually continued, considered a Birman, but for when you've got a lot of classes like",
  "01:52": "this it might be better, instead, to use the \ufffdmost_confused\ufffd method and that tells",
  "01:59": "you the combinations which it got wrong the most often. In other words, which numbers",
  "02:06": "are the biggest. So actually here's the biggest one, 10, and that's confusing, an American",
  "02:11": "Pitbull Terrier or a Staffordshire Bull Terrier. That's happened 10 times and a Ragdoll is",
  "02:18": "getting confused with a Birman 8 times. And so I'm not a dog or cat expert, and so I don't",
  "02:26": "know what this stuff means, so I looked it up on the internet, and I found that American",
  "02:31": "Pit Bull Terriers and Staffordshire Bull Terriers are almost identical, that, I think, they",
  "02:35": "sometimes have a slightly different colored nose, if I remember correctly, and Ragdolls",
  "02:40": "and Birman's are types of cat that are so similar to each other that there's whole long",
  "02:45": "threads on cat lover forums about \ufffdIs this a Ragdoll?\ufffd or \ufffdIs this Birman?\ufffd, and",
  "02:49": "experts disagreeing with each other. So, no surprise that these things are getting confused.",
  "02:55": "So when you see your model making sensible mistakes, the kind of mistakes that humans",
  "03:01": "make, that's a pretty good sign, that it's picking up the right kind of stuff, and that",
  "03:05": "the kinds of errors you're getting also might be pretty tricky to fix, but, you know, let's",
  "03:12": "see if we can make it better. And one way to try and make it better is to improve our",
  "03:19": "learning rate. Why would we want to improve the learning rate? Well, one thing we'd like",
  "03:23": "to do is to try to train it faster. Get more done in less epochs, and so one way to do",
  "03:30": "that would be to call our fine-tuned method with a higher learning rate. So last time",
  "03:38": "we used the default, which, I think, is 1e neg 2 (0.002),, and so if we pump that up",
  "03:51": "to 0.1, it's going to jump further each time. So remember the learning rate, if you've forgotten",
  "03:57": "this, have a look again at Notebook 4, that's the thing we multiply the gradients by, to",
  "04:02": "decide how far to step, and unfortunately when we use this higher learning rate, the",
  "04:09": "error rate goes from 0.08 in three epochs, to 0.082, so we're getting the vast majority",
  "04:18": "of them wrong now. So that's not a good sign. So, why did that happen? Well, what happened",
  "04:26": "it's rather than this gradual move towards the minimum, we had this thing where we step",
  "04:31": "too far, and we get further further away. So when do you see this happening. which locks",
  "04:40": "in practice like this, your error rate getting worse right from the start, that's a sign",
  "04:45": "your learning rate is too high. So we need to find something just right, not too small",
  "04:50": "that we take tiny jumps and it takes forever, and not too big that we, you know, either",
  "04:56": "get worse and worse, or we just jump backwards and forwards quite slowly.",
  "05:00": "So to find a good learning rate we can use something that the researcher Leslie Smith",
  "05:06": "came up with called \ufffdThe Learning Rate Finder\ufffd, and \ufffdThe Learning Rate Finder\ufffd is pretty",
  "05:11": "simple. All we do... Remember, when we do Stochastic Gradient Descent, we look at one",
  "05:17": "mini batch at a time, there are a few images, in this case, at a time, find the gradient",
  "05:22": "for that set of images for the mini-batch, and jump, step our weights based on the learning",
  "05:28": "rate and the gradient. Well what Leslie Smith said was \ufffdOK let's do the very first mini",
  "05:35": "batch at a really really low learning rate, like 10 to the minus 7, and then let's increase",
  "05:43": "by a little bit there like maybe 25% higher and do another step, and then 25 percent higher",
  "05:50": "and to another step\ufffd. So these are not epochs, these are just a single, a similar mini batch,",
  "05:56": "and then we can plot on this chart here. \ufffdOK, at 10 to the minus 7, what was the loss?\ufffd,",
  "06:01": "and, \ufffdAt 25% higher than that what was the loss?\ufffd, and \ufffdAt 25% higher than that what",
  "06:05": "was the loss?\ufffd. And so, not surprisingly, if you do that at the low learning rates,",
  "06:10": "the loss doesn't really come down, because the learning rate is so small that these steps",
  "06:15": "are tiny, tiny, tiny, and then gradually we get to the point where they're big enough",
  "06:22": "to make a difference and the loss starts coming down, because we've plotted here the learning",
  "06:26": "rate against the loss. All right? So here the loss is coming down as we continue to",
  "06:32": "increase the learning rate. The loss comes down until we get to a point where, our learning",
  "06:37": "rates too high and so it flattens out and then oop it's getting worse again. So here's",
  "06:41": "the point above like 0.1, where we're in this territory. So what we really want is somewhere",
  "06:52": "around here, where it's kind of nice and steep. So you can actually ask it, the learning rate",
  "06:59": "finder. So were used \ufffdlr_find\ufffd to get this plot. We can we can get back from it,",
  "07:04": "the minimum and steep. And so steep is where was it steepest, but the steepest point was",
  "07:10": "5e neg 3 (5e-03), and the minimum point divided by ten, that's quite a good rule of thumb,",
  "07:17": "is 1e neg 2 (1e-02). Somewhere around this range might be pretty good. So each time you",
  "07:26": "run it you'll get different values. A different time we ran it, we thought that maybe 3e neg",
  "07:29": "3 (3e-3) would be good, so we picked that. And you'll notice the learning rate finder",
  "07:34": "is a logarithmic scale. Be careful of interpreting that. So we can now rerun the learning rate",
  "07:41": "finder, setting the learning rate to a number we picked from the learning rate finder, which",
  "07:45": "in this case was 3e neg 3 (3e-3), and we can see now that's looking good. Right? We've",
  "07:50": "got an 8.3% error rate after three epochs. So this idea of the learning rate finder is",
  "07:59": "very straightforward. I can describe it to you in a couple of sentences. It doesn't require",
  "08:03": "any complex math, and yet it was only invented in 2015, which is super interesting. Right?",
  "08:10": "It, it just shows that there's so many interesting things first to all, to learn and discover.",
  "08:17": "I think part of the reason perhaps for this it took a while is that, you know, engineers",
  "08:22": "kind of love using lots and lots of computers. So before the learning rate finder came along,",
  "08:28": "people would like run lots of experiments on big clusters to find out which learning",
  "08:31": "rate was the best, rather than just doing a batch at a time, and I think partly also",
  "08:37": "the idea of having a thing where a human is in the loop where we look at something, and",
  "08:41": "make a decision is also kind of unfashionable. A lot of folks in research and industry love",
  "08:46": "things which are fully automated, but anyway it's great we now have this tool, because",
  "08:50": "it makes our life easier and fast AI certainly the first library to have this, and I don't",
  "08:57": "know if it's still the only one to have it built in, at least to the basic, the base",
  "09:01": "library. So, now we've got a good learning rate. How do we fine-tune the weights? So,",
  "09:08": "so far we've just been running this fine-tuned method without thinking much about what it's",
  "09:13": "actually doing, but we did mention in Chapter 1, Lesson 1 briefly basically what's happening",
  "09:23": "with a fine tune, what is transfer learning doing, and before we look at that let's take",
  "09:30": "a question. \ufffdIs the learning rate plot in \ufffdlr_find\ufffd plotted against one single mini",
  "09:39": "batch?\ufffd. No, it's not it's just... It's actually just the standard, kind of, walking",
  "09:50": "through the, walking through the data loader, so just getting the usual mini batches of",
  "09:57": "the shuffled data, and so it's kind of just normal training, and the only thing that's",
  "10:02": "being different is that we're increasing the learning rate a little bit after each mini",
  "10:07": "batch, and, and keeping track of it. along with that is is the network reset to",
  "10:18": "the initial status after each trial. No certainly not we actually want to see how it our learns.",
  "10:26": "We want to see it improving so we don't reset it to its initial state state until we're",
  "10:32": "done. So at the end of it we go back to the random weights we started with or whatever",
  "10:37": "the weights were at the time we ran this. So what we're seeing here is, is something",
  "10:44": "that's actually the, the actual learning that's happening as we at the same time increase",
  "10:50": "the learning rate. Why would an ideal learning rate found with a single mini-batch at the",
  "10:57": "start of training keep being a good learning rate even after several epochs and further",
  "11:01": "loss reductions? Okay question. It absolutely wouldn't so let's look at that too shall we.",
  "11:09": "And, ya go on. Can i ask one more?. Of course it is an important point so ask us. It is,",
  "11:16": "it is very important. For the learning rate finder why use the steepest and not the minimum?",
  "11:22": "We certainly don't want the minimum because the minimum is the point at which it's not",
  "11:27": "learning anymore. Right so so the first flat section at the bottom here means in this mini",
  "11:33": "batch didn't get better. So we want the steepest because that's the mini-batch where it got",
  "11:37": "the most improved. And that's what we want. We want the weights to be moving as fast as",
  "11:41": "possible. As a rule of thumb though we do find that the minimum divided by ten works",
  "11:48": "pretty well. That's Sylvian\ufffds favorite approach. And he's generally pretty spot-on with that.",
  "11:54": "so that's why we actually print out those two things. LR mean is actually the minimum",
  "11:59": "divided by 10 and steepest point is suggest the steepest point. Great,good questions all.",
  "12:11": "So remind ourselves what transfer learning does. but with transfer learning remember",
  "12:17": "what our neural network is. it's a bunch of linear models basically with activation functions",
  "12:27": "between them. And our activation functions are generally ReLU\ufffds - rectified linear",
  "12:32": "units. If any of this is fuzzy have a look at the 04 notebook again to remind yourself.",
  "12:42": "And so each of those linear layers has a bunch of parameters to the whole neural network",
  "12:47": "has a bunch of parameters. And so after we train a neural network on something like imagenet",
  "12:56": "we have a whole bunch of parameters that aren't random anymore. They're actually useful for",
  "13:00": "something and we've also seen that the early layers seem to learn about fairly general",
  "13:07": "ideas like gradients and edges and the later layers learn about more sophisticated ideas",
  "13:12": "like what our eyes look like or what does fur look like or what does text look like.",
  "13:17": "So with transfer learning we take a model. so in other words a set of parameters which",
  "13:23": "has already been trained on something like imagenet. We throw away the very last layer",
  "13:28": "because the very last layer is the bit that specifically says which one of those in the",
  "13:33": "case of imagenet 1000 categories is this an image in. So we throw that away and we replace",
  "13:39": "it with random weights. Sometimes with more than one layer of random weights and then",
  "13:44": "we train that. Now, yes. Oh I just wanted to make a comment and that's that I think",
  "13:55": "the learning rate finder. And I think after you learn about it the idea almost seems kind",
  "14:02": "of so simple or approximate that it's like wait this shouldn't work like or you know",
  "14:07": "shouldn't you have to do something more more complicated or more precise that it's like",
  "14:12": "I just want to highlight that this is a very surprising result. That some kind of the such",
  "14:17": "as simple approximate method would be so helpful. Yeah, I would particularly say it's surprising",
  "14:23": "to people who are not practitioners or who have not been practitioners for long. I've",
  "14:32": "noticed that a lot of my students at USF have a tendency to kind of jump in to try to doing",
  "14:38": "something very complex where they account for every possible imperfection from the start.",
  "14:44": "And it's very rare that that's necessary. So one of the cool things about this is a",
  "14:47": "good example of trying the easiest thing first and seeing how well it works. And this was",
  "14:53": "a very big innovation when it came out that I think it's kind of easy to take for granted",
  "14:58": "now but this was super super helpful when it was. It was super helpful and it was also",
  "15:05": "nearly entirely ignored. None of the research community cared about it and it wasn't until",
  "15:09": "fast.ai, I think in our first course talked about it that people started noticing. And",
  "15:15": "we had quite a few years in fact is still a bit the case where super fancy researchers",
  "15:20": "still don't know about the learning rate finder. And you know, get, get beaten by you know",
  "15:27": "first lesson fast.ai students on practical problems because they can pick learning rates",
  "15:32": "better. And they can do it without a cluster of thousands of Buddhas",
  "15:38": "okay, so transfer loading. So we've got our pre-trained Network and so it's really important",
  "15:45": "every time you hear the word pre-trained network you're thinking a bunch of parameters which",
  "15:49": "have particular numeric values and go with a particular architecture like ResNet 34.",
  "15:55": "We have thrown away the, the final layer and replace them with random numbers. And so now",
  "16:03": "we want to train, to fine tune this set of parameters for a new set of images in this",
  "16:09": "case pets. So fine-tune is the method we call to do that and to see what it does we can",
  "16:19": "go learn.fine-tune?? and we can see the source code and here is the signature of the function.",
  "16:28": "And so the first thing that happens is we call freeze. So freeze is actually the method",
  "16:37": "which makes it so only the last layer\ufffds weights will get stepped by the optimizer.",
  "16:46": "So the gradients are calculated just for those last layers of parameters and the step is",
  "16:50": "done just for those last layer of parameters. So then we call fit and we fit for some number",
  "16:58": "of epochs which by default is one we don't change that very often. And what that fit",
  "17:06": "is doing is it's just fitting those randomly added weights. Which makes sense right. they're",
  "17:12": "the ones that are going to need the most work. because at the time in which we add them they're",
  "17:17": "doing nothing at all they're just random. So that's why we spend one epoch trying to",
  "17:24": "make them better. After you've done that you now have a model which is much better than",
  "17:30": "we started with. it's not random anymore. All the layers except the last are the same",
  "17:35": "as the pretrained network. The last layer has been tuned for this new data set. The",
  "17:41": "closer you get to the right answer, as you can kind of see in this picture, the smaller",
  "17:46": "the steps you want to create as this sorry, the smaller steps you want to take, generally",
  "17:50": "speaking. So the next thing we do is we divide our learning rate by 2 and then we unfreeze.",
  "17:56": "So that means we make it so that all the parameters can now be stepped and all of them will have",
  "18:01": "gradients calculated. And then we fit for some more epochs and this is something we",
  "18:06": "have to the pass to the method. And so that\ufffds now got to train the whole network. So if",
  "18:15": "we want to we can kind of do this by hand, right. And actually cnn_learner, we have by",
  "18:22": "default freeze the model for us, freeze the parameters for us. So we actually don't have",
  "18:29": "to call freeze. So if we just create a learner and then fit for a while. This is three epochs",
  "18:37": "of training just the last layer. And so then we can just manually do it ourselves unfreeze.",
  "18:44": "And so now at this point as the question earlier suggested maybe this is not the right learning",
  "18:50": "rate anymore so we can run LR find again. And this time you don't see the same shape.",
  "18:57": "You don't see this rapid drop because it's much harder to train a model that's already",
  "19:01": "pretty good. So instead you just see a very gentle little gradient. So generally here",
  "19:09": "what we do, is we kind of try to find the bit where it starts to get worse again. And",
  "19:12": "go about which is about here and go about ten let you know a multiple of ten less than",
  "19:17": "that. So about 1e-5 I would guess which yeah that's what we picked. So then after unfreezing,",
  "19:24": "finding our new learning rate and then we can do a bunch more. And so here we are, we",
  "19:29": "are getting down to 5.9 percent error. Which is okay but there's, there's better we can",
  "19:36": "do. And the reason we can do better is that at this point here we're training the whole",
  "19:43": "model at a 1e-5 so ten to the minus five learning rate which doesn't really make sense. because",
  "19:50": "we know that the last layer is still not that great it's only had three epochs of training",
  "19:55": "from random. so it probably needs more work. We know that the second last layer was probably",
  "20:00": "pretty specialized to imagenet and less specialized to pet breeds so that probably needs a lot",
  "20:06": "of work. Whereas the early layers but kind of gradients and edges probably don't need",
  "20:11": "to be changed much at all. But what would really like is to have a small learning rate",
  "20:15": "for the early layers and a bigger learning rate for the later layers and this is something",
  "20:21": "that we developed at fast.ai and we call it discriminative learning rates. And Jason Jasinski",
  "20:29": "actually is a guy who wrote a great paper that some of these ideas are based on. He",
  "20:34": "actually showed that different layers of the network really want to be trained at different",
  "20:39": "rates. Although he didn't kind of go as far as trying that out and seeing how it goes,",
  "20:44": "it's more of a theoretical thing. So in fast.ai, if we want to do that we can pass to our learning",
  "20:51": "rate, rather than just passing a single number, we can pass a slice. Now a slice is a special",
  "20:59": "built-in feature of Python, it's just an object which basically can have a few different numbers",
  "21:05": "in it. In this case, we\ufffdre passing it two numbers. And the way we read those, basically",
  "21:11": "what this means in fast.ai is our learning rate is the very first layer. We'll have this",
  "21:17": "learning rate, 10 to the -6, the very last layer will be 10 to the -4, and the layers",
  "21:23": "between the two will be kind of equal multiples. So they'll kind of be equally spaced learning",
  "21:29": "rates from the start to the end. So here we can see, basically doing our kind of own version",
  "21:39": "of fine-tune. We create the learner, we fit with that automatically frozen version, we",
  "21:46": "unfreeze when we fit some more. And so when we do that you can see this works a lot better.",
  "21:52": "We're getting down to 5.3, 5.1, 5.4, and error. Well, that's pretty great. One thing we'll",
  "22:00": "notice here is that we did kind of overshoot a bit, and it seemed like more like an epoch",
  "22:05": "number 8 was better. So kind of back before, you know, well actually, let me explain something",
  "22:12": "about fit_one_cycle. So fit_one_cycle is a bit different to just fit. So what fiit_one_cycle",
  "22:20": "does is it actually starts at a low learning rate, it increases it gradually for the first",
  "22:29": "one-third or so of the batches until it gets to a high learning rate. The, the highest",
  "22:34": "were the, this is why they're called lr_max; it's the highest learning rate we get to.",
  "22:39": "And then for the remaining two-thirds or so of the batches it gradually decreases the",
  "22:44": "learning rate. And the reason for that is just that, well largely it's kind of like",
  "22:49": "empirically, researchers have found that works the best. In fact, this was developed again",
  "22:53": "by Leslie Smith, the same guy that did the learning rate finder. Again it was a huge",
  "22:58": "step, you know, it really dramatically accelerated the speed at which we can train your networks,",
  "23:04": "and also made them much more accurate. And again the academic community basically ignored",
  "23:09": "it. In fact, the key publication that developed this idea was not even, not even past peer",
  "23:16": "review. And so the reason I mentioned this now is to say that we can't,we don't really",
  "23:23": "just want to go back and pick the model that was trained back here because we could probably",
  "23:29": "do better, because we really want to pick a model that's got a low learning rate. But",
  "23:34": "what I would generally do here is I\ufffdd change this 12 to an 8, because this is, this is",
  "23:39": "looking good. And then I would retrain it from scratch. Normally you\ufffdd find a better",
  "23:44": "result. You can plot the loss and you can see how the training and validation loss moved",
  "23:51": "along. And you can see here that, you know the, the error rate was starting to get worse",
  "24:01": "here. And what you'll often see is, often the validation loss will get worse a bit before",
  "24:11": "the error rate gets worse. We're not really seeing it so much in this case, but the error",
  "24:15": "rate and the validation losts don't always, they're not always kind of in lockstep. So",
  "24:22": "what we're plotting here is the loss but you actually kind of want to look to see mainly",
  "24:25": "what's happening with the error rate, because that's actually the thing we care about. Remember",
  "24:28": "the loss is just like an approximation of what we care about that just happens to have",
  "24:35": "a gradient that works out nicely. So how do you make it better now? We're, we're already",
  "24:45": "down to just 5.4 or if we'd stopped bit earlier maybe we could get down to 5.1 or less error.",
  "24:52": "On 37 categories that's pretty remarkable, that's a very very good pet breed predictor.",
  "25:01": "If you want to do something even better, you could try creating a deeper architecture.",
  "25:05": "So a deeper architecture is just literally putting more pairs of nonlinear activation",
  "25:13": "function also known as a non-linearity, followed by these little linear models. Put more pairs",
  "25:17": "on to the end and they're basically... the number of these",
  "25:22": "sets of layers you have is the number that you'll see at the end of an architecture so",
  "25:27": "there's resnet18, resnet34, resnet50, so forth. Having said that, you can't really pick resnet19",
  "25:37": "or resnet38--I mean you could make one--but nobody's created a pre-trained version of",
  "25:45": "that for you, so you won't be able to do any fine-tuning. So like you can theoretically",
  "25:50": "create any number of layers you like, but in practice (most of the time) you'll want",
  "25:57": "to pick a model that has a pre-trained version so you kind of have to select from the sizes",
  "26:03": "people have pre-trained and there's nothing special about these sizes: they're just ones",
  "26:07": "that people happen to have picked out. For the bigger models, there's more parameters",
  "26:14": "and more gradients that are going to be stored on your GPU and you will get used to the idea",
  "26:20": "of seeing this error, unfortunately. \ufffdOut of memory.\ufffd So that's not out of memory",
  "26:26": "in your RAM, that's out of memory in your GPU. CUDA is referring to the language and",
  "26:32": "the system used for your GPU so if that happens, unfortunately you actually have to restart",
  "26:37": "your notebook, so that's a kernel > restart and try again. That's a really annoying thing,",
  "26:45": "but such is life. One thing you can do if you get an out of memory error is: after your",
  "26:52": "cnn_learner call, add this magic incantation to_fp16(). What that does is it uses for most",
  "27:00": "of the operations, numbers that use half as many bits as usual. So they're less accurate,",
  "27:06": "this half-precision floating point or FP16. That will use less memory and on pretty much",
  "27:16": "any Nvidia card created in 2020 (or later), and some more expensive cards even created",
  "27:25": "in 2019, that's often got a result in a 2 to 3 times speed up in terms of how long it",
  "27:32": "takes as well. So here, if I add in to_fp16() then I will be seeing often much faster training.",
  "27:41": "And in this case what I actually did is I switched to a resnet50 which would normally",
  "27:45": "take about twice as long, and my per epoch time has gone from 25 seconds to 26 seconds.",
  "27:53": "So the fact that we used a much bigger network, and it was no slower, is thanks to to_fp16().",
  "27:59": "But you'll see our error rate hasn't improved. It's pretty similar to what it was, and so",
  "28:06": "it's important to realize that just because we increase the number of layers, it doesn't",
  "28:11": "always get better! So it tends to require a bit of experimentation to find what's going",
  "28:17": "to work for you. And of course, don't forget the trick is: use small models for as long",
  "28:24": "as possible to do all of your cleaning up and testing and so forth. And wait until you're",
  "28:29": "all done to try some bigger models and because they're going to take a lot longer. Ok, questions.",
  "28:36": "How do you know or suspect when you can \ufffddo better?\ufffd You have to always assume you can",
  "28:46": "do better... Because you never know! So you just have to... I mean... Part of it though",
  "28:53": "is: do you need to do better? Or do you already have a good enough result to handle the actual",
  "28:58": "task you're trying to do? Often people do spend too much time fiddling around with their",
  "29:04": "models rather than actually trying to see whether it's already going to be super helpful.",
  "29:08": "As soon as you can actually try to use your model to do something practical, the better.",
  "29:14": "Yeah, how much can you improve it? Who knows! You know, go through the techniques that we're",
  "29:22": "teaching in this course and try them, and see which ones help. Unless it's a problem",
  "29:28": "that somebody has already tried before and written down their results, in a paper or",
  "29:34": "a Kaggle competition or something, there's no way to know how good it can get. So don't",
  "29:39": "forget after you do the questionnaire to check out the further research section. One of the",
  "29:48": "things we've asked you to do here is to read a paper. So find the learning rate finder",
  "29:53": "paper and read it, and see if you can kind of connect what you read up to the things",
  "30:00": "that we've learned in this lesson. See if you can maybe even implement your own learning",
  "30:05": "rate finder. You know, as manually as you need to and see if you can get something--that",
  "30:12": "you know, based on reading the paper--to work yourself. You can even look at the source",
  "30:19": "code of fastai\ufffds learning rate finder, of course. And then can you make this classifier",
  "30:25": "better? So this is further research, right? So maybe you can start doing some reading",
  "30:29": "to see what else could you do? Have a look on the forum and see what people are trying.",
  "30:35": "Have a look on the book website, course website, to see what other people have achieved, and",
  "30:40": "what they did, and play around. So we've got some tools in our toolbox now for you to experiment",
  "30:45": "with. so that is that is PET Breeds that is as you",
  "30:54": "know a pretty tricky computer vision classification problem and we kind of have seen most of the",
  "31:02": "pieces of what goes into the training of it, we haven't seen how to build the actual",
  "31:05": "architecture but other than that we've kind of worked our way up to understanding what's",
  "31:10": "going on. So let's build from there into another kind of Dataset: one that involves multi-label",
  "31:20": "classification. So what's multi-label classification? or maybe... so maybe let's look at an example.",
  "31:29": "Here is a multi label dataset where you can see that it's not just one label on each image",
  "31:36": "but sometimes there's three bicycle, car perso,, I don't actually see the car here maybe it",
  "31:42": "has been cropped out, so a multi-label dataset is one where you still got one image per row",
  "31:48": "but you can have 0 1 2 or more labels per row so we're going to have a think about and",
  "31:56": "look at how we handle that but first of all let's take another question.",
  "32:01": "R: is dropping floating-point number precision switching from FP 32 to FP 16 have an impact",
  "32:11": "on final loss. J: yes it does, often it makes it better,",
  "32:19": "believe it or not, it seems like you know they're kind o, it's doing a little bit of",
  "32:26": "rounding off, is one way to give it, drop some of that precision and so that creates",
  "32:30": "a bit more bumpiness, a bit more uncertainty it was you know of a stochastic nature and",
  "32:37": "you know when you introduce more lightly random stuff into training it very often makes it",
  "32:43": "a bit better and so yeah FP 16 training often gives us a slightly better result but I you",
  "32:50": "know I wouldn't say it's generally a big deal either way and that me it's not always better.",
  "32:55": "R: would you say this is a bit of a pattern in deep learning less us exact stochastic",
  "33:04": "way \ufffd\ufffd.? J: for sure not just in deep learning but",
  "33:09": "machine learning more generally, you know there's been some interesting research looking",
  "33:14": "at like matrix factorization techniques which if you want them to go super fast you can",
  "33:18": "use a lots of machines, you can use randomization and you often, when you then use the results",
  "33:24": "you often find you actually get better, better outcomes.",
  "33:27": "R: just a brief blog for the fast day I computational linear algebra course which talks a little",
  "33:32": "bit about \ufffd.. J: that's it really well that sounds like",
  "33:38": "a fascinating course, and look at that it's number-one hit here on Google's, so easy to",
  "33:44": "find but by somebody called Rachel Thomas hey that's persons got the same name as you,",
  "33:53": "Rachel Thomas. All right so how we going to do multi-label",
  "33:58": "classification so let's look at a data set called Pascal which is a pretty famous dataset,",
  "34:02": "we look at the version that goes back to 2007 been around for a long time and it comes with",
  "34:08": "a CSV file which we will read in CSV as comma separated values and let's take a look each",
  "34:15": "row has a file name one or more labels and something telling you whether it's in the",
  "34:21": "validation set or not so the list of categories in each image is a space delimited string",
  "34:28": "but doesn't have a horse person it has a horse and a person. pd here stands for Pandas. Pandas",
  "34:36": "is really important library for any kind of data processing and you'll use it all the",
  "34:44": "time in machine learning and deep learning so let's have a quick chat about it. not a",
  "34:48": "real panda, it's the name of a library and it creates things called data frames that's",
  "34:53": "what the DF here stands for and a dataframe is a table containing rows and columns. pandas",
  "34:59": "can also do some slightly more sophisticated things than that but we'll treat it that way",
  "35:02": "for now so you can read in a data frame by saying pd for pandas. Pandas read CSV give",
  "35:08": "it a file name you've now got a dataframe you can call head to see the first few rows",
  "35:12": "of it for instance a data frame as a iloc integer location property which you can index",
  "35:22": "into as if it was an array vector it looks just like numpy so column means every row,",
  "35:30": "remembers row comma column and zero means zeros column and so here is the first column",
  "35:36": "of the data frame. now you can do the exact opposite so the zeroth row and every column",
  "35:43": "it's going to give us the first row and you can see the row has column headers and values",
  "35:49": "so it's a little bit different to Numpy and remember if there's a comma column or a bunch",
  "35:54": "of comma column at the end of indexing in Numpy or PyTorch or Pandas whatever you can",
  "36:01": "get rid of it. And these two are exactly the same , and you can do the same this here by",
  "36:08": "grabbing the column by name, the first column as Fname, say df.fname you get that first",
  "36:13": "column you can create new columns so here's a tiny little data frame I've created from",
  "36:18": "a dictionary and I could create a new column by for example adding two columns and you",
  "36:25": "can see there it is. So it's like a lot like NUmpy or Pytorch, except that you have this",
  "36:31": "idea of kind of rows and and column named columns and so it's all about and tabular",
  "36:38": "data. I find this API pretty unintuitive a lot of people do but it's fast and powerful",
  "36:46": "so it takes a while to get familiar with it but it's worth taking a while and the creator",
  "36:50": "of pandas wrote a fantastic book called \ufffdPython for data analysis\ufffd which I've read both",
  "36:57": "versions and I found it fantastic it doesn't just cover pandas it covers other stuff as",
  "37:01": "well like iPython and Numpy and matplotlib so highly recommend this book this is our",
  "37:12": "table so what we want to do now is construct data loaders that we can train with and we've",
  "37:22": "talked about the data block API as being a great way to create data loaders but let's",
  "37:26": "use this as an opportunity to create a data data loaders or a data processor create a",
  "37:30": "data block and data loaders for this and let's try to do it like right from square one so",
  "37:38": "let's see exactly what's going on with datablock so first of all let's remind ourselves about",
  "37:45": "what a dataset and the dataloader is. A dataset is an abstract idea of a class you can create",
  "37:53": "a data set data set is anything which you can index into it like so or and you can take",
  "37:59": "the length of it like so so for example the list of the lowercase letters along with a",
  "38:06": "number saying which lowercase letter it is, I can index into it to get 0 comma \ufffda\ufffd.",
  "38:12": "I can get the length of it, to get 26 and so therefore this qualifies as a dataset and",
  "38:19": "in particular dataset normally you would expect that when you index into it you would get",
  "38:23": "back at tuple because you've got the independent and dependent variables, not necessarily always",
  "38:31": "just two things it could be more that could be less but 2 is the most common so once we",
  "38:38": "have a dataset we can pass it to a dataloader we can repress we can request a particular",
  "38:45": "batch size we can shuffle or not and so there's our data loader from \ufffda\ufffd we could grab",
  "38:52": "the first value from that iterator and here is the shuffled, seven is H four is E twenty",
  "38:58": "is U and so forth and so I remember a mini-batch has a bunch of a mini-batch of the independent",
  "39:06": "variable and a mini-batch of the dependent variable if you want to see how the two correspond",
  "39:11": "to each other you can use zip so for zip passing in this list and then this list so B0 and",
  "39:20": "B 1 you can see what zip does in Python is it grabs one element from each of those in",
  "39:25": "turn and gives you back the tuples of the corresponding elements since we're just passing",
  "39:33": "in all of the elements of B to this function, Python has a convenient shortcut for that",
  "39:40": "which is just say *B and so * means insert into this parameter lists each element of",
  "39:48": "B just like we did here, so these are the same thing so this is a very handy idiom that",
  "39:55": "we use a lot in Python zip * something is kind of a way of like transposing something",
  "40:01": "from one orientation to another. Allright so we've got a dataset we've got a dataloader",
  "40:10": "and then what about datasets our datasets is an object which has a training data set",
  "40:16": "and a validation set dataset so let's look at one now normally you don't start with kind",
  "40:24": "of an enumeration like this like with with an independent variable and a dependent variable",
  "40:29": "normally you start with like a file name for example and then you, you kind of calculate",
  "40:38": "or compute or transform your file name into an image by opening it and a label by for",
  "40:45": "example looking at the file name and grabbing something out of it so for example we could",
  "40:49": "do something similar here this is what data sets does so we could",
  "40:52": "start with just the lowercase letters so this is still a dataset right because we can index",
  "40:58": "into it and we can get the length of it although it's not giving us tuples yet so if we now",
  "41:05": "pass that list to the datasets plus and index into it we get back the tuple and it's actually",
  "41:14": "a tuple with just one item this is how Python shows tuple with one item as it puts it in",
  "41:18": "parenthesis and a comma and then nothing okay so in practice what we'd really want to do",
  "41:23": "is to say like okay we'll take this and do something to compute an independent variable",
  "41:28": "and do something to compute the dependent variable so here's a function we could use",
  "41:32": "to compute an independent variable which is to stick an A on the end and our dependent",
  "41:37": "variable might just be the same thing with a B on the end but here's two functions so",
  "41:42": "for example now we can call datasets passing an A and then we can pass in a list of transformations",
  "41:51": "to do and so in this case I've just got one which is this function at an a on the end",
  "41:56": "so now for index into it I don't get A anymore I get AA if you pass multiple functions then",
  "42:04": "it's going to do multiple things I've got F 1 then F 2 a a B that's this one that's",
  "42:13": "this one and you'll see this is a list of lists and the reason for that is that you",
  "42:17": "can also pass something. like this: a list containing \ufffdf1\ufffd, a list",
  "42:22": "containing \ufffdf2\ufffd, and this will actually take each element of \ufffda\ufffd, pass it through",
  "42:28": "this list of functions, and there's just one of them, to give you \ufffdaa\ufffd, and then start",
  "42:34": "again, and separately pass it through this list of functions, there's just one, to get",
  "42:38": "\ufffdab\ufffd. And so this is actually kind of the main way we build up independent variables",
  "42:46": "and dependent variables in Fastai, is we start with something like a filename, and we pass",
  "42:50": "it through two lists of functions: one of them will generally kind of, open up the image",
  "42:54": "for example, and the other one will kind of parse the filename, for example and give you",
  "42:59": "a independent variable and a dependent variable. So you can then create a DataLoaders object",
  "43:06": "from datasets by passing in the datasets, and a batch size, and so here you can see",
  "43:13": "I've got shuffled \ufffdoa\ufffd, \ufffdia\ufffd etc. \ufffdob\ufffd, \ufffdib\ufffd etc. So, this is worth",
  "43:20": "studying to make sure you understand what Datasets and DataLoaders are. We don't often",
  "43:25": "have to create them from scratch, we can create a DataBlock to do it for us. But now we can",
  "43:31": "see what the DataBlock has to do. So let's see how it does it. We can start by creating",
  "43:36": "an empty DataBlock. So an empty DataBlock is going to take our DataFrame, so we're going",
  "43:42": "to go back to looking at our DataFrame, which remember, was this guy. And so if we pass",
  "43:54": "in our DataFrame, we can now, we will now find that this Datablock has created Datasets,",
  "44:03": "a training and a validation Dataset for us, and if we look at the training set, it'll",
  "44:10": "give his back an independent variable in the dependent variable and we'll see that they",
  "44:14": "are, the same thing. So this is the first row of the table what's actually shuffled,",
  "44:21": "so it's a random row of the table, repeated twice. And the reason for that is by default",
  "44:27": "the DataBlock assumes that we have two things, the independent variable and the dependent",
  "44:31": "or the input in the target, and by default it just copies, it just keeps exactly whatever",
  "44:37": "you gave it. To create the training set in the validation set by default it just randomly",
  "44:43": "splits the data with the 20% validation set. So that's what's happened here. So this is",
  "44:50": "not much use. What we what we actually want to do if we look at X for example is grab",
  "44:56": "the \ufffdfname\ufffd, the filename field, because we want to open this image. That's going to",
  "45:01": "be our independent variable. And then for the label, we're going to want this here \ufffdperson",
  "45:11": "cat\ufffd. So we can actually pass these as parameters \ufffdget_x\ufffd and \ufffdget_y\ufffd, are functions",
  "45:19": "that return the the bit of data that we want. And so you can create an user function in",
  "45:25": "the same line of code in Python by saying lambda. so lambda \ufffdr\ufffd means create a function,",
  "45:33": "doesn't have a name, that's going to take a parameter called \ufffdr\ufffd. We don't even",
  "45:37": "have to say return it's got to return the \ufffdfname\ufffd column, in this case. And \ufffdget_y\ufffd",
  "45:45": "is something, which is a function that takes an \ufffdr\ufffd and returns the labels column.",
  "45:51": "So now we can do the same thing called \ufffddblock dot datasets\ufffd. We can grab a row from that,",
  "45:57": "from the training set, and you can see look here it is there is, there is the image filename",
  "46:02": "and there is the space delimited list of labels. So here's exactly the same thing again, but",
  "46:10": "done with functions. Okay so now the one line of code above has become three lines of code,",
  "46:17": "but it does exactly the same thing. Okay we don't get back the same result because the",
  "46:25": "training set... well wait why don't we get the same result?",
  "46:28": "Oh, I know why. Because it randomly shuffles, it's randomly picking a different validation",
  "46:37": "set. Because the random spit is done differently each time, so that's why we don't get the",
  "46:42": "same result. One thing to note, be careful of lambdas. If you want to save this DataBlock",
  "46:50": "for use later, you won't be able to. Python doesn't like saving things that contain lambdas,",
  "46:55": "so most of the time in the book and the course we normally use, avoid lambdas for that reason",
  "47:01": "because this is often very convenient to be able to save things. We use the word here",
  "47:06": "serialization, that just means, basically it means saving something. This is not enough",
  "47:13": "to open an image because we don't have the path. So to turn this into, so rather than",
  "47:20": "just using this function to grab the \ufffdfname\ufffd column, we should actually use pathlib to",
  "47:26": "go, a \ufffdpath/train\ufffd and then column. And then for the \ufffdy\ufffd, again the labels it\ufffds",
  "47:34": "not quite enough, we actually have a split on space. But this is Python, we can use any",
  "47:38": "function we like, and so then we won't use the same three lines of code as here, and",
  "47:43": "now we've got a path, and a list of labels. So that's looking good. So we want this path",
  "47:52": "to be opened as an image, so the DataBlock API, lets you pass a \ufffdblocks\ufffd argument,",
  "47:59": "where you tell it, for each of the things in your tuple, so there's two of them, what",
  "48:05": "kind of block do you need. So we need an ImageBlock to open an image, and then, in the past we've",
  "48:11": "used a CategoryBlock, for categorical variables, but this time we don't have a single category,",
  "48:17": "we've got multiple categories, where we have to use a MultiCategoryBlock. So once we do",
  "48:22": "that, and have a look, we now have an 500 by 375 image as our independent variable,",
  "48:29": "and as a dependent variable we have a long list of zeros and ones. The long list of zeros",
  "48:39": "and ones, is the labels as a one hot encoded vector, a rank one tensor, and specifically",
  "48:53": "there will be a zero in every location where, in the vocab, where there is not that kind",
  "49:00": "of object in this image, and a one in every location where there is. Sso for this one",
  "49:05": "there's just a person so this must be the location in the vocab where there's a person.",
  "49:11": "We have any questions? The one hot encoding is a very important concept, and we didn't",
  "49:19": "have to use it before, right? We could just have a single integer saying which one thing",
  "49:27": "is it, but when we've got lots of things, lots of potential labels, it's convenient",
  "49:33": "to use this one hot encoding. And it's kind of what, it's actually what's going to happen",
  "49:37": "with, with the, with the actual matrices anyway. When we actually compare the activations of",
  "49:49": "our neural network to the target, it's actually going to be comparing each one of these.",
  "49:57": "Okay so the categories, as I mentioned, is based on the vocab, where we can grab the",
  "50:03": "vocab from our Datasets object, and then we can say okay, let's look at the first row,",
  "50:10": "and let's look at the dependent variable, and let's look for where the dependent variable",
  "50:17": "is 1. Okay and, and we can have a look, parse those indexes, there's a vocab and get back",
  "50:26": "a list of what it actually was there. And again each time I run this, I'm going to get",
  "50:30": "different results. So each time we run this we're going to get different results because",
  "50:36": "I called \ufffddot datasets\ufffd again here, so it's going to give me a different train-test",
  "50:40": "split, and so this time it turns out that this actually, a chair, and we have a question.",
  "50:48": "Shouldn't the tensor be of integers? Why is it a tensor of floats? Yeah, conceptually",
  "50:56": "this is a tensor of integers, they can only be 0 or 1, but we, we\ufffdre going to be",
  "51:07": "using a cross entropy style loss function, so we're going to actually need to do floating-point",
  "51:14": "calculations on them. That's going to be faster to just store them as float in the first place",
  "51:20": "rather than converting backwards and forwards, even though they're conceptually an \ufffdint\ufffd",
  "51:23": "we're not going to be doing kind of \ufffdint style calculations\ufffd with them. Good question.",
  "51:32": "I mentioned that by default, the DataBlock uses a random split, you might\ufffdve noticed,",
  "51:43": "in the DataFrame though, it said here's a column saying what validation set to use,",
  "51:50": "and if the data set you're given, tells you what validations had to use, you should generally",
  "51:55": "use it because that way you can compare your validation set results to somebody else's.",
  "52:01": "So you can pass a splitter argument, which again is a function, and so we're going to",
  "52:06": "pass it a function, that's also called splitter, and the function is going to return the indexes",
  "52:11": "where it's not valid and that's going to be the training set, and the indexes where it",
  "52:19": "is valid, that's going to be the validation set. And so the splitter argument is expected",
  "52:23": "to return two lists of integers, and so if we do that we get again the same thing, but",
  "52:30": "now we're using the correct train and validation sets. Another question? Sure. Any particular",
  "52:40": "reason we don't use floating point eight? Is it just that the precision is too low?",
  "52:46": "Yeah, trying to train with 8-bit precision is super difficult it's, it's so flat and",
  "52:57": "bumpy, it's pretty difficult to get decent gradients. But you know it's an area of research,",
  "53:03": "the main thing people do with 8-bit or even one bit data types, is they take a model that's",
  "53:10": "already been trained with 16-bit or 32-bit floating-point and then they kind of round",
  "53:15": "it off. It's called discretizing, to create a kind of purely integer or even binary network",
  "53:23": "which can do inference much faster. Figuring out how to train with such low precision data",
  "53:31": "is an area of active research. I suspect it's possible, and I suspect, I mean people have",
  "53:42": "fiddled had some success I think you know it could turn out to be super interesting",
  "53:47": "particularly for stuff that's been done on low-powered devices that might not even have",
  "53:51": "a floating-point unit. Right, so the last thing we need to do is to add our item transforms",
  "54:01": "RandomResizedCrop, we've talked about that enough, so I won't go into it, but basically",
  "54:04": "that means we now are going to ensure that everything has the same shape so that we can",
  "54:09": "collate it into a DataLoader so now rather than going \ufffddatasets\ufffd we go DataLoaders,",
  "54:13": "and display our data. And remember, if something goes wrong, as we saw last week you can call",
  "54:21": "\ufffdsummary\ufffd, to find out exactly what's happening in your DataBlock. So now you know",
  "54:27": "this is something really worth studying this section because data blocks are super handy",
  "54:30": "and if you haven't used Fastai 2 before, they won't be familiar to you because no other",
  "54:37": "library uses them, and so like this has really shown you how to go right back to the start",
  "54:42": "and gradually build them up, so hopefully that'll make a whole lot of sense. Now we're",
  "54:49": "going to need a loss function again, and to do that let's start by just creating a learner.",
  "54:56": "Let's create a Resnet18 from the DataLoaders object we just created, and let's grab one",
  "55:04": "batch of data and then let's put that into our mini-batch of independent and dependent",
  "55:11": "variables and then \ufffdlearn dot model\ufffd is the thing that actually contains the, the",
  "55:18": "the model itself, in this case it\ufffds CNN, and you can treat it as a function, and so",
  "55:23": "therefore we can just pass something to it. And so if we pass a mini-batch of the independent",
  "55:29": "variable to \ufffdlearn dot model\ufffd it will return the activations from the final layer.",
  "55:36": "And that is, shape 64 by 20. So anytime you get a tensor back, look at its shape, and",
  "55:44": "in fact before you look, at its shape, predict what the shape should be. And then make sure",
  "55:48": "that you're right. If you're not, either you guessed wrong, so try to understand where",
  "55:53": "you made a mistake, or there's a problem with your code, and this place, 64 by 20, makes",
  "56:01": "sense because we have a mini-batch size of 64, and for each of those, we're going to",
  "56:06": "make predictions about what probability is each of these 20 possible categories, and",
  "56:13": "we have a question. Two questions. Two questions, all right! Is the DataBlock API compatible",
  "56:19": "with out of core data sets like Dask. Yeah, the DataBlock API can do anything you wanted",
  "56:26": "to do, so you're passing it, if we go back to the start. So, you can create an empty",
  "56:38": "one, and then you can pass it anything that is indexable, and yeah so that can be anything",
  "56:49": "you like, and pretty much anything can be made indexable in Python and that's something",
  "56:55": "like Dask is certainly indexable. So that works perfectly fine. If it's not indexable,",
  "57:04": "like it's a, it's a network stream or something like that, then you can\ufffdt use the DataLoaders",
  "57:10": "Datasets API directly which we'll learn about either in this course or the next one. But",
  "57:16": "yeah, anything that you can index into, which certainly includes Dask, you can use with",
  "57:21": "DataBlocks. Next question, where do you put images for multi-label with that CSV table?",
  "57:26": "Should they be in the same directory? They can be any way you like, so in this case we",
  "57:34": "used a pathlib object like so. And in this case, by default it's going to be using\ufffd",
  "57:51": "Let me think about this. What's happening here is the path is.. Oh it's saying \ufffddot\ufffd",
  "58:03": "okay the reason for that is that path.BASE_PATH is currently set to path, and so that displays",
  "58:08": "things relative. Well let's get rid of that. Okay so the path we set is here, right? And",
  "58:17": "so then when we said get_x, it's saying path slash train whatever, right? So this is an",
  "58:23": "absolute path, and so here is the exact path. So you can put them anywhere you like, you",
  "58:30": "just have to say what the \ufffdpath\ufffd is. And then if you want to not get confused by having",
  "58:37": "this big long prefix that we can, don't want to see all the time, just set BASE_PATH to",
  "58:42": "the path you want everything to be relative to, and then it'll just print things out in",
  "58:47": "this more convenient manner. All right, so um this is really important that you can do",
  "58:56": "this, that you can create a learner, you can grab a batch of data that, you can pass it",
  "59:01": "to the model, this is just plain PyTorch, this line here right no Fastai. You can see",
  "59:07": "the shape, right? You can recognize why it has this shape, and so now if you have a look,",
  "59:14": "here are the 20 activations. Now this is not a trained model, it's a pre trained model",
  "59:22": "with a random set of final layer weights, so these specific numbers don't mean anything,",
  "59:27": "but it's just worth remembering this is what activations look like, and most importantly",
  "59:33": "they're not between 0 & 1. And, if you remember from the MNIST Notebook,",
  "59:38": "we know how to scale things between zero and one, we can pop them into the sigmoid function.",
  "59:43": "So the sigmoid function is something that scales everything to be between zero and one.",
  "59:50": "So let's use that. You'll also hopefully remember from the MNIST Notebook that the MNIST loss,",
  "59:59": "the MNIST loss function, first did sigmoid, and then it did \ufffdtorch.where\ufffd, so and",
  "60:07": "then it did \ufffd.mean\ufffd. We're going to use exactly the same thing as the MNIST loss function,",
  "60:12": "and we're just going to do one thing, which is going to add \ufffd.log\ufffd, for the same reason",
  "60:16": "that we talked about when we were looking at softmax, we talked about why log is a good",
  "60:26": "idea as a transformation. We saw in the MNIST Notebook, we didn't need it but we're gonna",
  "60:33": "train faster and more accurately, if we use it, because it's just more, it's going to",
  "60:37": "be better behaved, as we've seen. So this particular function, which is identical to",
  "60:42": "MNIST loss plus \ufffd.log\ufffd jhas a specific name and it's called binary cross entropy,",
  "60:50": "and we used it for the threes vs. sevens problem, to, to decide whether that column is it a",
  "60:58": "three or not, but because we can use broadcasting in PyTorch and element-wise arithmetic, this",
  "61:08": "function when we pass it a whole matrix is going to be applied to every column. So is",
  "61:15": "the first column, you know, what... So it'll basically do a \ufffdtorch.where\ufffd on, on every",
  "61:21": "column separately and every item separately. So that's great, it basically means that this",
  "61:29": "binary cross-entropy function is going to be just like MNIST loss, rather than just",
  "61:34": "being \ufffdIs this the number three?\ufffd it'll be \ufffdIs this a dog?\ufffd, \ufffdIs this a cat?\ufffd,",
  "61:39": "\ufffdIs this a car?\ufffd, \ufffdIs this a person?\ufffd, \ufffdIs this a bicycle?\ufffd, and so forth. So",
  "61:43": "this is where it's so cool in PyTorch, we can kind of run, write, one thing and then",
  "61:48": "kind of have it expand to handle higher dimensional tensors, without doing any extra work. We",
  "61:56": "don't have to write this ourselves, of course, because PyTorch has one and it's called \ufffdF.binary_cross_entropy\ufffd.",
  "62:06": "We can just use PyTorch\ufffds. As we've talked about there's always a equivalent module version",
  "62:11": "so this is exactly the same thing as a module \ufffdnn.BCELoss\ufffd, and these ones don't include",
  "62:22": "the initial sigmoid, actually. If you want to include this initial sigmoid you need F.binary_cross_entropy_with_logits",
  "62:30": "or the equivalent nn.BCEWithLogitsLoss. So BCE is binary cross-entropy. And so those",
  "62:38": "are two functions, plus two equivalent classes for multi-label or binary problems, and then",
  "62:47": "the equivalent for single label like MNIST and pets is \ufffdnll_loss\ufffd and \ufffdcross_entropy\ufffd.",
  "62:54": "That's the equivalent of \ufffdbinary_cross_entropy\ufffd and \ufffdbinary_cross_entropy_with_logits\ufffd.",
  "62:58": "So these are pretty awful names, I think we can all agree, but it is what it is. So in",
  "63:05": "our case we have a one hot encoded target, and we want the one with the sigmoid in, so",
  "63:12": "the equivalent built-in is called \ufffdBCEWithLogitsLoss. That we can make that our loss function, we",
  "63:19": "can compare the activations to our targets, and we can get back a loss, and then that's",
  "63:26": "what we can use to train, and then finally, before we take our break, we also need a metric.",
  "63:34": "Now previously we've been using as a metric accuracy or actually error rate. Error rate",
  "63:38": "is 1 - accuracy. Accuracy only works for single label datasets, like MNIST and pets, because",
  "63:50": "what it does is it takes the input, which is the final layer of activations, and it",
  "63:56": "does our \ufffdargmax\ufffd, what \ufffdargmax\ufffd does is it says: \ufffdWhat is the index of the largest",
  "64:01": "number in those activations?\ufffd. So, for example, for MNIST, you know, maybe",
  "64:05": "the largest, the highest probability is seven, so this \ufffdargmax\ufffd would return seven. And",
  "64:10": "then it says, \ufffdOK there those are my predictions.\ufffd, and then it says, \ufffdOK is the prediction",
  "64:16": "equal to the target or not, and then take the floating-point mean\ufffd. That's what accuracy",
  "64:22": "is. So \ufffdargmax\ufffd only makes sense when there's a single maximum thing you're looking",
  "64:29": "for. In this case we've got multi-label. So instead we have to compare each activation",
  "64:37": "to some threshold. Our default is 0.5, and so we basically say, \ufffdIf the sigmoid of",
  "64:45": "the activation is greater than 0.5, let's assume that means that category is there and",
  "64:52": "if it's not let's assume it means it's not there\ufffd, and so this is going to give us",
  "64:56": "a list of trues and falses, for the ones that the based on the activations it thinks are",
  "65:02": "there, and we can compare that to the target, and then again take the floating point mean.",
  "65:09": "So we can use the default threshold of 0.5, but we don't necessarily want to use 0.5,",
  "65:16": "we might want to use a different threshold, and remember we have to pass, when we create",
  "65:21": "our learner, we have to pass to the metric, the metrics argument, a function. So what",
  "65:27": "if we want to use a threshold other than 0.5. Well we'd like to create a special function,",
  "65:32": "which is \ufffdaccuracy_multi\ufffd, with some different threshold, and the way we do that is we use",
  "65:38": "a special, built-in in Python called partial. Let me show you how partial works. Here\ufffds",
  "65:47": "a function called \ufffdsay_hello\ufffd, \ufffdsay_hello\ufffd somebody with something. So \ufffdsay_hello\ufffd",
  "65:55": "Jeremy, where the default is \ufffdHello\ufffd, that says \ufffdHello Jeremy\ufffd. \ufffdsay_hello\ufffd",
  "66:00": "Jeremy, comma \ufffdAhoy\ufffd, gonna be \ufffdAhoy! Jeremy\ufffd. Let's create a special version",
  "66:05": "of this function that will be more suitable for Sylvain. It's going to use French. So",
  "66:11": "we can say partial, create a new function, that's based on the \ufffdsay_hello\ufffd function,",
  "66:17": "but it's always going to set say_what to \ufffdBonjour\ufffd and we'll call that \ufffdf\ufffd. So now f(\ufffdJeremy\ufffd)",
  "66:23": "is \ufffdBonjour Jeremy and f(\ufffdSylvain\ufffd) is \ufffdBonjour Sylvain\ufffd. So, you see, we've",
  "66:29": "created a new function, from an existing function, by fixing one of its parameters. So we can",
  "66:36": "do the same thing for \ufffdaccuracy_multi\ufffd. Hey, let's use a threshold of 0.2, and we",
  "66:42": "can pass that to metrics, and so let's create a \ufffdcnn_learner\ufffd and you'll notice here",
  "66:48": "we don't actually pass a loss function, and that's because fast AI is smart enough to",
  "66:53": "realize. \ufffdHey, you're doing a classification model, with a, a multi-label dependent variable.",
  "67:02": "So I know what loss function you probably want\ufffd. So it does it for us. We can call",
  "67:06": "\ufffdfine_tune\ufffd and here we have an accuracy of 94.5 after the first few, and eventually",
  "67:12": "95.1. That's pretty good. We've got an accuracy of over 95%, was 0.2 a good threshold to pick.",
  "67:20": "Who knows? Let's try 0.1. Oh, l that's a worse accuracy. So, I guess, in this case we could",
  "67:28": "try a higher threshold. 94. Hmm, also not good. What's the best threshold? Well what",
  "67:34": "we could do is call, \ufffdget_preds\ufffd, to get all of the predictions, and all of the targets,",
  "67:40": "and then we could calculate the accuracy, at some threshold, then we could say, \ufffdOK,",
  "67:47": "let's grab lots of numbers between 0.05 and 0.95, and with a list comprehension calculate",
  "67:54": "the accuracy for all of those different thresholds, and plot them. Ah, looks like we want a threshold",
  "68:03": "somewhere a bit about 0.5. So, cool, we can just use that, and it's going to give us 96",
  "68:09": "in a bit, which is going to give us a better accuracy. This is",
  "68:15": "a, you know, something that a lot of theoreticians would be uncomfortable about - I've used the",
  "68:21": "validation set to pick a hyper parameter, a threshold, right. And so people might be",
  "68:27": "like, \ufffdOh, you're overfitting, using the validation set to pick a hyper parameter.\ufffd",
  "68:32": "But if you think about it, this is a very smooth curve, right. It's not some bumpy thing",
  "68:36": "where we've accidentally kind of randomly grabbed some unexpectedly good value. When",
  "68:42": "you're picking a single number from a smooth curve \ufffd you know, this is where the theory",
  "68:47": "of like don't use a validation set for for how parameter tuning doesn't really apply.",
  "68:52": "So it's always good to be practical, right. Don't treat these things as rules, but as",
  "68:58": "rules of thumb. Okay, so let's take a break for five minutes and I'll see you back here",
  "69:06": "in five minutes time. Hey,welcome back oh I want to show you something",
  "69:12": "really cool - image regression. So we are not going to learn how to use a fast.ai image",
  "69:21": "regression application because we don't need one. Now that we know how to build stuff up",
  "69:29": "with loss functions and the DataBlock API ourselves, we can invent our own applications.",
  "69:36": "So there is no image regression application, per se. But we can do image regression really",
  "69:45": "easily. What do we mean by image regression? Well, remember back to a lesson, I think is",
  "69:50": "lesson 1, we talked about the two basic types of machine learning, or supervised machine",
  "69:58": "learning - regression and classification. Classification is when our dependent variable",
  "70:03": "is a discrete category or set of categories. And regression is when our dependent variable",
  "70:12": "is a continuous number, like age or XY coordinate, or something like that. So image regression",
  "70:20": "means our independent variable is an image and our dependent variable is a continuum",
  "70:26": "or one or more continuous values. And so here's what that can look like which is biwi head",
  "70:36": "pose dataset. It has a number of things in it, but one of the things we can do is find",
  "70:40": "the midpoint of a person's face, see. So the biwi head pose dataset, so the biwi head poste",
  "70:59": "dataset comes from this paper, \ufffdRandom Forest for Real Time 3D Face Analysis.\ufffd So thank",
  "71:07": "you to those authors. And we can grab it in the usual way, untar_data. And we can have",
  "71:15": "a look at what's in there, and we can see there's 24 directories numbered from 0, from",
  "71:20": "1 to 24. 1,2,3, and each one also has a .obj file. We're not going to be using the .obj",
  "71:26": "file, I'm just the directories. So let's look at one of the directories and as you can see",
  "71:30": "there's a thousand things in the first directory. So each one of these 24 directories is one",
  "71:35": "different person that they photographed. And you can see, for each person there's frame",
  "71:42": "3 pose, frame 3 RGB, frame 4 pose, frame 4 RGB, and so forth. So in each case we've got",
  "71:51": "the image, which is the RGB, and we've got the pose, which is pose.txt. So as we've seen,",
  "71:58": "we can grab our use get_image_files to get a list of all of the files image files recursively",
  "72:03": "in a path. So once we have an image filename, like this one, sorry like this one, we can",
  "72:13": "turn it into a pose file name by removing the last 1,2,3,4,5,6,7 letters and adding",
  "72:20": "back on pose.txt. And so here is a function that does that. And so you can see, I can",
  "72:28": "pass in an image file to img2pose, and get back a pose file, right. So PILImage.create",
  "72:37": "is the fastai way to create an image, at least a PIL image. It has a shape (in computer",
  "72:45": "vision, they're normally backwards, they normally do columns by rows but that's why it's this",
  "72:51": "way around) whereas PyTorch and Numpy tensors and arrays are rows by columns. So that's",
  "72:57": "confusing, but that's just how things are I'm afraid. So here's an example of an image.",
  "73:03": "When you look at the ReadMe from the dataset website, they tell you how to get the center",
  "73:11": "point from, from one of the text files, and it's just this function (the details don\ufffdt",
  "73:16": "matter, it is what it is). They call it get_ctr and it will return the XY coordinate of the",
  "73:23": "center of the person's head, or face. So we can pass this as get_y, because get_y, remember",
  "73:30": "is a thing that gives us back the label, okay. So, so, here's the thing, right. We can create",
  "73:40": "a DataBlock and we can pass in as the independent variables block, ImageBlock as usual. And",
  "73:47": "then the dependent variables block we can say PointBlock, which is a tensor with two",
  "73:51": "values in. And now by combining these two things, this says we want to do image regression",
  "73:58": "with the dependent variable with two continuous values. To get the items, you call get_image_files,",
  "74:05": "to get the y, we'll call the get_ctr function to split it. So this is important, we should",
  "74:13": "make sure that the validation set contains one or more people that don't appear in the",
  "74:22": "training set. So I'm just going to grab person number 13, just grabbed it randomly, and I'll",
  "74:28": "use all of those images as the validation set. Because I think they did this with a",
  "74:34": "Xbox Kinect, you know, video thing, so there's a lot of images that look almost identical.",
  "74:40": "So if you randomly assigned them then you would be massively overestimating how effective",
  "74:46": "you are. You want to make sure that you're actually doing a good job with a random, with",
  "74:51": "a new set of people, not just a new set of frames. That's why we use this and so funcSplitter",
  "74:57": "is a splitter that takes a function. And in this case we're using lambda to create the",
  "75:03": "function. We will use data augmentation and we will also normalize (so this is actually",
  "75:11": "done automatically), now this case we're doing it manually. So this is going to subtract",
  "75:19": "the mean and divide by the standard deviation of the original data set that the pre-trained",
  "75:25": "model used, which is ImageNet. So that's our data block, and so we can call dataloaders",
  "75:34": "to get our data loaders, passing in the path. And show_batch, and we can see that looks",
  "75:39": "good, right. Here's our faces and the points. And so let's like, particularly for as a student",
  "75:46": ",don't just look at the pictures, look at the actual data. So grab a batch, put it into",
  "75:52": "an xb and a yb (x batch and y batch), and have a look at the shapes. And make sure they",
  "75:57": "make sense. So why is this 64 by 1 by 2? So it's 64 in the mini batch (64 rows), and then",
  "76:08": "the coordinates is a 1 by 2 tensor. So there's a single point with two things in it. It's",
  "76:21": "like you could have like hands, face, and armpits, or whatever \ufffd or nose and ears",
  "76:26": "and mouth. So in this case we're just using one point and the point is represented by",
  "76:31": "two values, the x and the y. And then why is this 64 by 3 by 240 by 320? Well there's",
  "76:39": "240 rows by 320 columns (that\ufffds the pixels it's the size of the images that we're using),",
  "76:45": "mini-batches 64 items now what's the 3? The 3 is the number of channels, which in this",
  "76:52": "case means the number of colors. If we open up some random grizzly bear image and then",
  "77:00": "we go through each of the elements of the first axis, and do a show_image you can see",
  "77:13": "that it's got the red the green and the blue as the three channels, so",
  "77:20": "that's how we store a three channel image. It is stored as a three by number of rows",
  "77:27": "by number of columns rank three tensor and so a mini batch of those is a rank four tensor.",
  "77:34": "Tat's why this is that shape. So here's a row from the dependent variable okay there's",
  "77:42": "that XY location we talked about. So we can now go ahead and create a learner passing",
  "77:50": "in our dataloaders as usual, passing in our pretrained architecture as usual, and if you",
  "77:55": "think back, you may just remember in Lesson one we learn about y_range. Y_range is where",
  "78:04": "we tell Fastai what range of data we expect to see in the dependent variable. So we want",
  "78:11": "to use this generally when we're doing regression though the range of our coordinates is between",
  "78:18": "minus 1 and 1, that's how Fastai and Pytorch treats coordinates the left hand side is minus",
  "78:25": "1 or the top is minus 1 and the bottom in the right 1. No point predicting something",
  "78:32": "that's more than minus 1 or bigger than 1 as that is not in the area that we use for",
  "78:37": "our coordinates. [Rachel] I have a question. [Jeremy] sure just a moment. So how does Y_range",
  "78:44": "work? Well it actually uses this function called sigmoid_range which takes the sigmoid",
  "78:49": "of X multiplies by hi minus lo and adds lo and here is what sigmoid_range looks like",
  "78:58": "or minus 1 to 1. It's just a sigmoid where the bottom is the lo and the top is the hi",
  "79:06": "and so that way all of our activations are going to be mapped to the range from minus",
  "79:11": "1 or 1. Yes Rachel. [Rachel] can you provide images with an arbitrary number of channels",
  "79:19": "as inputs specifically more than three channels? [Jeremy] yeah you can have as many channels",
  "79:24": "as you like. We\ufffdve certainly seen images with less than three because we've been grayscale.",
  "79:32": "More than three is common as well you could have like an infrared band or like satellite",
  "79:36": "images often have multispectral. There's some kinds of medical images where there are bands",
  "79:41": "that are kind of outside the visible range. Your pre-trained model will generally have",
  "79:49": "three channels. Fastai does some tricks to use three channel pre-trained models for non",
  "79:57": "three channel data but that's the only tricky bit other than that it's just just a you know",
  "80:05": "it's just an axis that happens to have four things or two things or one thing instead",
  "80:09": "of three things. There's nothing special about it. Okay we didn't specify a loss function",
  "80:18": "here so we get whatever you gave us which is a MSE loss. So MSE loss is mean squared",
  "80:24": "error and that makes perfect sense right you would expect mean squared error to be a reasonable",
  "80:30": "thing to use for regression we're just testing how close we are to the target and then taking",
  "80:36": "the square picking the mean. We didn't specify any metrics and that's because mean squared",
  "80:43": "error is already a good metric like it's not \ufffd it has nice gradient so behaves well but",
  "80:52": "it's also the thing that we care about so we don't need a separate metric to track.",
  "80:57": "Let's go ahead and use lr_find() and we can pick her learning rate so maybe about n to",
  "81:05": "the minus 2 we can call fine_tune and we get a valid loss of 0.0001. So that's the mean",
  "81:13": "squared error so we should take the square root but on average we're about 0.01 off in",
  "81:18": "a coordinate space that goes between minus 1 and 1. Well that sounds super accurate,",
  "81:22": "took about 3 and a bit minutes to run. So we can always call in Fastai, and we always",
  "81:29": "should, our results and see what our results look like",
  "81:32": "and as you can see Fastai has automatically figured out how to display the combination",
  "81:37": "of an image independent variable and a point dependent variable on the left is the target",
  "81:44": "and on the right is the prediction and as you can see it is pretty close to perfect.",
  "81:51": "One of the really interesting things here is that we used fine_tune even though think",
  "81:57": "about it the thing we're fine-tuning imagenet isn't even an image regression model. So we're",
  "82:03": "actually fine-tuning an image classification model that becomes something totally different;",
  "82:10": "an image regression model. Why does that work so well? Well because an imagenet classification",
  "82:21": "model must have learnt a lot about kind of how images look like, what things look like",
  "82:27": "and where the pieces of them are they kind of know how to figure out what breed of animals",
  "82:32": "something is even if it's partly obscured by borscht shorts, in the shade, or it's turned",
  "82:38": "in different angles. You know these are pre-trained image models are incredibly powerful computers,",
  "82:45": "you know computing algorithms. So built into every imagenet pre-trained model is all this",
  "82:52": "capability that it had to learn for itself. So asking it to use that capability to figure",
  "82:58": "out where something is, it's just actually not that hard for it and so that's why we",
  "83:04": "can actually fine tune an imagenet classification model to create something completely different",
  "83:10": "which is a point image regression model. So I find that incredibly cool I gotta say. So",
  "83:24": "again look at the further research after you've done the questionnaire and particularly if",
  "83:28": "you haven't used dataframes before please play with them because we're going to be using",
  "83:31": "them more and more. [Rachel] I\ufffdve a question. [Jeremy] I'll just do the last one and also",
  "83:40": "go back and look at the bear classifier from notebook 2 or whatever; hopefully you created",
  "83:46": "some other classifier for your own data. Because remember we talked about how it would be better",
  "83:52": "if the bear classifier could also recognize that there's no bear at all or maybe there's",
  "83:59": "both a grizzly bear and a black bear or a grizzly bear and a teddy bear so if you retrain",
  "84:04": "using multilabel classification see what happens see how well it works when there's no bears",
  "84:10": "and see whether it changes the accuracy of the single label model when you turn it into",
  "84:17": "a multilabel problem. So have a fiddle around and tell us on the forum what you find. You've",
  "84:22": "got a question rachel [Rachel] is there a tutorial showing how to use pretrained models",
  "84:27": "on 4-channel images; also how can you add a channel to a normal image; [Jeremy] well",
  "84:35": "the last one is how do you add a channel to an image? I don\ufffdt know what that means.",
  "84:41": "Okay I don't know; Like an image is an image. You can\ufffdt add a channel to an image. it",
  "84:49": "is what it is. I don't know if there's a tutorial but we can certainly make sure somebody on",
  "84:59": "the forum has learned how to do it. it's super straightforward; pretty much automatic. Okay",
  "85:10": "we're going to talk about collaborative filtering. What is Collaborative filtering? Think about",
  "85:23": "on Netflix or whatever, you might have watched a lot of movies that are sci-fi and have a",
  "85:32": "lot of action and were made in the 70s. Netflix might not know anything about the properties",
  "85:41": "of movies you watched. They might just know that they are movies with titles and IDs.",
  "85:48": "But what it could absolutely see without any manual work is find other people that watched",
  "85:55": "the same movies that you watched. And it could",
  "86:00": "see what other movies those people watched that you haven't, and it would probably find",
  "86:05": "they were also, we would probably find, they're also science fiction, and full of action,",
  "86:09": "and made in the 70s. So we can use an approach where we recommend things, even if we don't",
  "86:20": "know anything about what those things, are as long as we know who else has used or recommended",
  "86:30": "things that are similar, you know, the same kind, you know, many of the same things that",
  "86:33": "that you've liked or, or used. This doesn\ufffdt necessarily mean users and products. In fact",
  "86:43": "in collaborative filtering instead of saying products we normally say items, and items",
  "86:47": "could be links you click on, diagnosis for a patient, and so forth. So there's a key",
  "86:57": "idea here, which is that in the underlying items and we going to be using movies in this",
  "87:02": "example, there are some, there are some features, they may not be labeled, but there's some",
  "87:09": "underlying concept of features, of, of those movies, like the fact that there's a action",
  "87:17": "concept, and a sci-fi concept, and a 1970s concept. Now you never actually told Netflix",
  "87:23": "you like these kinds of movies, and maybe Netflix never actually added columns to their",
  "87:27": "movies saying what movies are those types, but as long as like, you know, in the real",
  "87:33": "world there's this concept of sci-fi, and action, and movie age, and that those concepts",
  "87:39": "are relevant for at least some people's movie watching decisions, as long as this is true,",
  "87:47": "then we can actually uncover these they're called latent factors, these things that,",
  "87:54": "kind of, decide what kind of movies you want to watch, and they\ufffdre latent, because nobody",
  "88:00": "necessarily ever wrote them down or labeled them or or communicated them in any way. So",
  "88:07": "let me show you what this looks like. So there's a great dataset we can use, called MovieLens,",
  "88:14": "which contains tens of millions of movie rankings, and so a movie ranking looks like this. It",
  "88:21": "has a user number, a movie number, a rating and a timestamp. So we don't know anything",
  "88:32": "about who user number 196 is. I don't know if that is Rachel, or Sylvain, or somebody",
  "88:37": "else. I don't know what movie number 242 is. I don't know if that's Casablanca or Lord",
  "88:44": "of the Rings or The Mask. And then rating is a number between, I think, it was 1 and",
  "88:52": "5. A question. Sure. \ufffdIn traditional machine learning we perform cross validations and",
  "88:58": "k-fold training to check for variance and bias trade-off. Is this common in training",
  "89:04": "deep learning models as well?\ufffd So cross-validation is a technique where you don't just let your",
  "89:14": "data set into one training set and one validation set, but you basically do it five or so times,",
  "89:21": "like five training sets, and like five validation sets representing different overlapping subsets,",
  "89:29": "and basically this was this used to be done a lot because people often used to have not",
  "89:34": "enough data to get a good result, and so this way, rather than, kind of, having 20% that",
  "89:43": "you would leave out each time you could just leave out like, 10% each time. Nowadays it's",
  "89:49": "less common that we have so little data that we need to worry about the complexity and",
  "89:54": "extra time of lots of models. It's done on Kaggle a lot. As on Kegel every little fraction",
  "90:02": "of a percent matters, but it's not, yeah, it's not a deep learning thing, or a machine",
  "90:07": "learning thing, or whatever. It's just a, you know, lots of data or not very much data",
  "90:13": "thing, and do you care about the last decimal place",
  "90:16": "of\ufffd Or not. It's not something we're going to talk about, certainly, in this part of",
  "90:22": "the course, if ever, because it's not something that comes up in practice that often as being",
  "90:29": "that important. There are two more questions. \ufffdWhat would be some good applications of",
  "90:36": "collaborative filtering outside of recommender systems?\ufffd Well I mean depends how you define",
  "90:45": "recommender system. If you're trying to figure out what kind of other diagnoses might be",
  "90:53": "applicable to a patient, I guess, it's kind of a recommender system, or you're trying",
  "90:58": "to figure out where somebody is going to click next, or whatever, it's kind of a recommender",
  "91:04": "system, but, you know, really conceptually it's anything where you're trying to learn",
  "91:10": "from, from past behavior, where that behavior is, kind of, like a thing happened to an entity.",
  "91:20": "\ufffdWhat is an approach to training using video streams, i.e., from drone footage instead",
  "91:26": "of images? Would you need to break up the footage into image frames?\ufffd In practice",
  "91:32": "quite often you would, because images just tend to be pretty big, sorry, videos tend",
  "91:36": "to be pretty big. There's a lot of... So, I mean, theoretically the time could be the",
  "91:46": "the fourth channel. Yeah, or, or a fifth channel. Fifth channel. So if it's a full color movie",
  "91:53": "you can absolutely have, well I guess fourth, because you, you can have, it would be a five,",
  "92:01": "rank five tensor being batched by time by color by row by column, but often that's too",
  "92:13": "computationally and too memory-intensive. Sometimes people just look at one frame at",
  "92:23": "a time, sometimes people use us a few frames around, kind of, the key frame like three",
  "92:31": "or five frames at a time, and sometimes people use something called a Recurrent Neural Network,",
  "92:37": "which we'll be seeing in the next week or two, you can treat it as a sequence data.",
  "92:41": "Yeah, there's all kinds of tricks you can do to try and go and work with that. Conceptually,",
  "92:48": "though, there's no reason you can't just add an additional axis to your tensors and everything",
  "92:53": "just work. It's just a practical issue around time and memory. And someone else noted that",
  "93:00": "it's pretty fitting that you mentioned the movie The Mask. Yes, was another accident",
  "93:06": "I guess I got masks on the brain. I'm not sure if we're allowed to like that movie anymore,",
  "93:15": "though and I've liked it when it came out. I don't know of, what I think nowadays, it's",
  "93:19": "a while. Okay. So, let's take a look. So we can untar data ML_100k. So ML_100k, is a small",
  "93:32": "subset of the full set. There's another one that we can grab, which is about the whole",
  "93:37": "lot 25 million, but 100k is good enough for messing around. So if you look at the README",
  "93:44": "you'll find the main table, the main table is in a file called \ufffdu.data\ufffd. So let's",
  "93:49": "open it up with \ufffdread_csv\ufffd again. This one is actually not comma separated values,",
  "93:53": "it's tab separated rather confusingly we still use csv, and to say delimiter is a tab, \ufffd\\t\ufffd",
  "93:59": "is a tab, and there's no row at the top saying what the columns are called, so we say header",
  "94:06": "is None, and then pass in a list of what the columns are called. \ufffd.head\ufffd will give",
  "94:11": "us the first five rows, and we mentioned just before what it looks like. It's not a particularly",
  "94:20": "friendly way to look at it, so what I'm going to do is I'm going to, cross tab it, and so",
  "94:28": "what I've done here is I've grabbed the top, I can\ufffdt remember how many it was. Well,",
  "94:35": "who cares? One, two, three, four... fifteen, or twenty movies, based on the most",
  "94:41": "popular movies and the top bunch of users who watch the most movies. And so I basically",
  "94:47": "kind of reoriented this, so for each user I have all the movies they've watched and",
  "94:53": "the rating they gave them. So empty spots represent users that have not seen that movie.",
  "94:59": "So this is just another way of looking at this same data. So basically what we want",
  "95:10": "to do is guess what movies we should tell people they might want to watch. And so it's",
  "95:17": "basically filling in these gaps to tell user 212, do you think we would, they might like",
  "95:22": "movie 49 or 79 or 99 best to watch next. So let's assume that we actually had columns",
  "95:40": "for every movie that represented, say, how much sci-fi they are, how much action they",
  "95:47": "are, and how old they are. And maybe they're between -1 and 1. And so like the last_skywalker",
  "95:53": "is very sci-fi, barely action, and definitely not old. And then we could do the same thing",
  "96:02": "for users. So we could say user1 really likes sci-fi, quite likes action, and really doesn't",
  "96:11": "like old. And so now if you multiply those together, and remember in PyTorch and Numpy,",
  "96:17": "you have element-wise calculation, so this is going to multiply each corresponding item.",
  "96:23": "It's not matrix multiplication. If you're a mathematician, don't go there - this is",
  "96:27": "element-wise multiplication. If we want matrix multiplication, it would be an @ sign. So",
  "96:32": "if we multiply each element together, next with your equivalent element in the other",
  "96:38": "one, and then sum them up, that's going to give us a number which will basically tell",
  "96:43": "us how much do these two correspond. Because remember, two negatives multiplied together",
  "96:48": "to get a positive. So user1 likes exactly the kind of stuff that the last_skywalker",
  "96:56": "has in it, and so we get 2.1. Multiplying things together element-wise and adding them",
  "97:02": "up is called the dot product and we use it a lot, and it's the basis of matrix (shouldn\ufffdt",
  "97:08": "say modification). matrix multiplication. And so make sure you know what a dot product",
  "97:20": "is, it's this. So Casablanca is not at all sci-fi, not much action, and is certainly",
  "97:29": "old. So if we do user1 times Casablanca, we get a negative number. So we might think,",
  "97:35": "\ufffdOK, user1 won\ufffdt like, won't like this movie. Problem is we don't know what the latent",
  "97:42": "factors are, and even if we did we don't know how to label a particular user or a particular",
  "97:47": "movie with them. So we have to learn them. How do we learn them? Well, we can actually",
  "97:59": "look at a spreadsheet, so I wrote a spreadsheet version. So we have a spreadsheet version",
  "98:08": "which is basically, what I did was I popped this table into Excel and then I randomly",
  "98:20": "created a (let\ufffds count this now, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15),",
  "98:28": "I randomly created a 15x5 table here. These are just random numbers and I randomly created",
  "98:35": "a 5x15 table here. And I basically said, Okay, well let's just pretend, let's just assume",
  "98:42": "that every movie and every user has five latent factors. I don't know what they are. And let's",
  "98:49": "then do a matrix multiply of this set of factors by this set of factors and a matrix multiply",
  "98:57": "of a row by a column is identical to a dot product of two vectors. So that's why I can",
  "99:03": "just use matrix multiply now. This is just what this first cell content so they then",
  "99:07": "copied it to the whole thing. So all these numbers there are being calculated",
  "99:13": "from the row latent factors dot product with or matrix model play with the column latent",
  "99:23": "factors. So in other words I'm doing exactly this calculation, but I'm doing them with",
  "99:29": "random numbers. And so that gives us a whole bunch of values, right. And then what I could",
  "99:40": "do, is I could calculate a loss by comparing every one of these numbers here to every one",
  "99:48": "of these numbers here. And then I could do mean squared error. And then I could choose",
  "99:55": "stochastic gradient descent to find the best set of numbers in each of these two locations.",
  "100:03": "And that is what collaborative filtering is. So that's actually all we need. So, rather",
  "100:13": "than doing it in Excel. And we\ufffdll do the Excel version later, if you're interested",
  "100:18": "(because we can actually do this whole thing and it works in Excel), let's jump and do",
  "100:22": "it into PyTorch. Now one thing that might just make this more fun is actually to know",
  "100:30": "what the movies are and MovieLens tells us in u.item what the movies are called and that",
  "100:36": "uses the delimiter of the pipe sign weirdly enough. So here are, here are the names of",
  "100:41": "each movie. And so one of the nice things about Pandas, is it can do joins just like",
  "100:50": "SQL. And so you can use the merge method to combine the ratings table and the movies table",
  "100:56": "and since they both have a column called movie, by default it will join on those. And so now",
  "101:02": "here we have the ratings table with actual movie names, that's going to be a bit more",
  "101:07": "fun. we don't need it for modeling, but it's just going to be better for looking at stuff.",
  "101:11": "So we could use data blocks API at this point or we can just use the built in application",
  "101:18": "factory method. Since it's there we may as well use it, so we can create a collaborative",
  "101:23": "filtering data loaders object from a data frame by passing in the ratings table. By",
  "101:30": "default the user column is called \ufffduser\ufffd, and ours is, so fine. By default the item",
  "101:37": "column is called \ufffditem\ufffd and ours is not, it's called \ufffdtitle\ufffd, so let's pick \ufffdtitle\ufffd",
  "101:43": "and choose a batch size. And so if we now say show_batch, here is some of that data.",
  "101:52": "And the rating is called \ufffdrating\ufffd by default, so that worked fine, too. So here's some data.",
  "102:01": "So we need to now create our (assume we're going to use that five numbers of factors)",
  "102:10": "so the number of users is however many classes there are for user and the number of movies",
  "102:17": "is however many classes there are for title. And so these are, so we don't just have a",
  "102:28": "vocab now, right, we've actually got a list of classes for each categorical variable,",
  "102:36": "for each set of discrete choices. So we've got a whole bunch of users (944) and a whole",
  "102:44": "bunch of titles (1635). So for our randomized latent factor parameters, we're going to need",
  "102:56": "to create those matrices. so we can just create them with random numbers. This is normally",
  "103:00": "distributed random numbers, that's what randn is. And that will be n_users, okay, so 944",
  "103:06": "by n_factors, which is 5. That's exactly the same as this except this is just 15. So let\ufffds",
  "103:15": "do exactly the same thing for movies. Random numbers and movies by 5, okay. And so to calculate",
  "103:24": "the result for some movie and some user we have to look up the index of the movie in",
  "103:30": "our movie latent factors, the index of the user in our user latent factors and then do",
  "103:36": "a cross product. So in other words we would say, Like oh okay, for this particular combination",
  "103:43": "we would have to look up that numbered user over here and that numbered movie over here",
  "103:50": "to get the two appropriate sets of latent factors. But this is a problem because look",
  "103:59": "up in an index is not a linear model. Like remember, our deep learning models really",
  "104:09": "only know how to just multiply matrices together and do simple element-wise nonlinearities",
  "104:16": "like ReLu. There isn't a thing called lookup in an index. Okay, I\ufffdll just finish this",
  "104:24": "bit. Here's a cool thing, though - the lookup in an index can, is actually can be represented",
  "104:34": "as a matrix product, believe it or not. So if you replace our indices with one-hot encoded",
  "104:44": "vectors, then one-hot encoded vector times something is identical to looking up in an",
  "104:54": "index. And let me show you. So if we grab, if we call the one-hot function, that creates",
  "105:08": "a, as it says here, one-hot encoding. And we're going to one-hot encode the value 3",
  "105:15": "with n_users classes. And so n_users, as we discussed, is 944, all right, then. So if",
  "105:31": "we go one-hot one-hot encoding the number 3 in to n_users one_hot_3, you get this big",
  "105:51": "array big tensor and as you can see in index 3, here 1 2 3, we have a 1 and the size of",
  "106:00": "that is 924. So if we then multiply that by user_factors, our user_factors, remember,",
  "106:13": "is that random matrix of this size. Now what's going to happen? so we're going to go 0 by",
  "106:27": "the  first row and so that's going to be your 0s",
  "106:35": "and then we're going to 0 again we're gonna 0 again and then we're going to finally go",
  "106:41": "1, right, on the index 3-row and so it's going to return each of them and then we'll go back",
  "106:48": "to 0 again. So if we do that (remember @ is matrix multiply) and compare that to user_factors_3,",
  "107:07": "same thing. Isn't that crazy? So. it\ufffds some kind of wierd, inefficient way to do it, right",
  "107:15": ",but matrix multiplication is a way to index into an array. And this is the thing that",
  "107:23": "we know how to do SGD with, and we know how to build models with. So it turns out that",
  "107:28": "anything that we can do with indexing to array, we now have a way to optimize. And we have",
  "107:35": "a question. There are two questions. One, \ufffdHow different in practice is collaborative",
  "107:41": "filtering with sparse data compared to dense data?\ufffd We are not doing sparse data in this",
  "107:48": "course, but there's an excellent course out here called Computational Linear Algebra for",
  "107:54": "Coders. It has a lot of information about sparse. The fast.ai course. A second question,",
  "108:00": "\ufffdIn practice, do we tune the number of latent factors?\ufffd Absolutely, we do, yes. It's just",
  "108:08": "a number of filters like we have in at any kind of a big planning model. All right, so",
  "108:18": "now that we know that the procedure of finding out which latent set of latent factors is",
  "108:27": "the right thing, looking something up at an index is the same as matrix multiplication",
  "108:33": "with a one-hot vector (I already had it over here), we can go ahead and build a model with",
  "108:43": "that. So basically if we do this for a whole for a few more indices at once, then we have",
  "108:48": "a matrix of one-hot encoded vectors. So the whole thing is just one big matrix multiplication.",
  "108:57": "Now the thing is, as I said this is a pretty inefficient way to do an index lookup, so",
  "109:05": "there is a computational shortcut, which is called an embedding. An embedding is a layer",
  "109:15": "that has the computational speed of an array lookup and the same gradients as a matrix",
  "109:25": "multiplication. How does it do that? Well, just internally it uses an index lookup to",
  "109:33": "actually grab the values, and it also knows what the gradient of a matrix multiplication",
  "109:40": "by our one-hot encoded vector is, or matrix is, without having to go to all this trouble.",
  "109:47": "And so an embedding is a matrix multiplication with a one-hot encoded vector where you never",
  "109:53": "actually have to create the one-hot encoded vector. You just need the indexes. This is",
  "109:59": "important to remember because a lot of people have heard about embeddings and they think",
  "110:02": "they\ufffdre something special and magical, and, and they're absolutely not. You can do exactly",
  "110:08": "the same thing by creating a one-hot encoded matrix and doing a matrix multiply. It is",
  "110:13": "just a computational shortcut, nothing else. I often find when I talk to people about this",
  "110:19": "in person I have to tell them this six or seven times before they believe me because",
  "110:25": "they think embeddings are something more clever, and they're not. It's just a computational",
  "110:29": "shortcut to do a matrix multiplication more quickly with a one-hot encoded matrix by instead",
  "110:35": "doing an array lookup. Okay, so let's try and create a collaborative filtering model.",
  "110:46": "In PyTorch, a model, or an architecture, or really an nn.module is a class. So to use",
  "110:56": "PyTorch to its fullest, you need to understand object-oriented programming, because we have",
  "111:01": "to create classes. There's a lot of tutorials about this, so I won't go into detail about",
  "111:06": "it, but I'll give you a quick overview. A class could be something like Dog, or ResNet,",
  "111:15": "or Circle - and it's something that has some data attached to it and it has some functionality",
  "111:20": "attached to it. Here\ufffds a class called \ufffdExample\ufffd - the data it has attached to it is \ufffda\ufffd",
  "111:28": "and the functionality attached to it is \ufffdsay\ufffd. And so we can, for example, create an instance",
  "111:34": "of this class, an object of this type Example. We pass in \ufffdSylvain\ufffd, so \ufffdSylvan\ufffd",
  "111:40": "will now be in ex.a and we can then say \ufffdex.say\ufffd and it will call \ufffdsay\ufffd and it will say",
  "111:49": "passing it \ufffdnice to meet you\ufffd so that will be X. And so it'll say, \ufffdHello\ufffd self.a,",
  "111:57": "so that\ufffds \ufffdSylvian, nice to meet you\ufffd. There, it is. Okay, so in Python the way you",
  "112:05": "create a class is to say class and its name, then to say what is passed to it when you",
  "112:11": "create that object, it's a special method called __init__. As we've briefly mentioned",
  "112:16": "before, in Python there are all kinds of special method names of that special behavior - they",
  "112:23": "start with two underscores they end with two underscores and we pronounce that \ufffddunder\ufffd,",
  "112:30": "so \ufffddunder init\ufffd, __init__. All methods in, all regular methods instance methods in",
  "112:37": "Python always get passed the actual object itself first (we normally call that self)",
  "112:44": "and then optionally anything else. And so you can then change the contents of the current",
  "112:49": "object by just setting self.whatever to whatever you like. So after this self.a is now equal",
  "112:56": "to \ufffdSylvian\ufffd. So we call a method, same thing - get passed self, optionally anything",
  "113:03": "you pass to it. And then you can access the contents of self which you stashed away back",
  "113:08": "here when we initialized it. So that's basically how object, or you know the basics of how",
  "113:15": "object-oriented programming works in Python. There's something else you can do",
  "113:22": "when you create a new class, which is you can pop something in parentheses after its",
  "113:27": "name, and that means we're going to use something called inheritance. And what inheritance means",
  "113:32": "is, I want to have all the functionality of this class, plus I want to add some additional",
  "113:39": "functionality. So, Module is a PyTorch class, which fast.ai has customized, so it's kind",
  "113:48": "of a fast.ai version of a PyTorch class. And, probably in the next course we'll see exactly",
  "113:55": "how it works. And, but it looks a lot like a, it acts almost exactly like just a regular",
  "114:04": "Python class - we have an __init__, and we can set attributes to whatever we like. And",
  "114:13": "one of the things we can use is an Embedding. And so an Embedding is just this class that",
  "114:18": "does what I just described - it's the same as an, as a linear layer with a one-hot encoded",
  "114:24": "matrix, but it does it with this computational shortcut. You can say how many, in this case",
  "114:29": "users are there, and how many factors will they have. Now, there is one very special",
  "114:35": "thing about things that inherit from Module, which is that when you call them, it will",
  "114:41": "actually call a method called \ufffdforward\ufffd. So \ufffdforward\ufffd is a special PyTorch method",
  "114:47": "name. It's the most important PyTorch method name. This is where you put the actual computation.",
  "114:53": "So to grab the factors from an embedding, we just call it like a function, right. So",
  "115:00": "this is going to get passed here the user IDs and the movie IDs as two columns. So let's",
  "115:08": "grab the zero index column and grab the embeddings by passing them to user_factors. And then",
  "115:15": "we'll do the same thing for the index one column, that's the movie IDs, pass them to",
  "115:19": "the movie_factors. And then here there's our element-wise multiplication and then sum.",
  "115:27": "And now remember we've got another dimension this time. The first axis is the mini-batch",
  "115:33": "dimension, where we want to sum over the other dimension, the index one dimension. So that's",
  "115:40": "going to give us a dot product for each user, so for each rating for each user movie combination.",
  "115:49": "So this is the DotProduct class. So you can see if we look at one batch of our data, its",
  "116:00": "of size, shape 64x2, because there are 64 items in the mini batch and each one has,",
  "116:09": "this is the independent variables, so it's got the user ID and the movie ID. And, oh,",
  "116:19": "\ufffdDo deep neural network based models for collaborative filtering work better than more",
  "116:25": "traditional approaches like SVG or other matrix?\ufffd Let's wait until we get there. So, here is",
  "116:36": "X, right, so here is one user ID movie ID combination, okay. And then for each one of",
  "116:46": "those 64, here are the ratings. So now we created a DotProduct Module from scratch,",
  "117:00": "so we can instantiate it, passing in the number of users, the number of movies, and let's",
  "117:06": "use 50 factors, and now we can create a learner. Now this time we're not creating a cnn_learner",
  "117:11": "or a specific application learner, It's just a totally generic learner. So this is a learner",
  "117:16": "that doesn't really know how to do anything clever, it just draws away the data you give",
  "117:20": "it and the model you give it. And since we're not using an application-specific learner,",
  "117:25": "it doesn't know what loss function to use, so we'll tell it to use MSE and fit. And that's",
  "117:32": "it, right. So we've just fitted our own collaborative filtering model where we literally created",
  "117:39": "the entire architecture, it's a pretty simple one, from scratch.",
  "117:44": "So that's pretty amazing. Now the results aren't great, if you look at the movie lens",
  "117:53": "data set benchmarks online you'll see this is not actually a great result. So one of",
  "117:59": "the things we should do is take advantage of the tip we just mentioned earlier in this",
  "118:03": "lesson, which is when you're doing regression, which we are here, right. The number between",
  "118:08": "1 and 5 is like a continuous value we're trying to get as close to it as possible. We should",
  "118:13": "tell fastai what the range is, we can use the y_range as before, so here's exactly the",
  "118:23": "same thing we've got a y_range, we've stored it away and then at the end, we use as we",
  "118:31": "discussed, sigmoid_range, passing in, and look here, we pass in *self.y_range, that's",
  "118:36": "going to pass in by default 0,5.5. We can see, yeah not really any better, um it's worth",
  "118:51": "a try, normally this is a little bit better but it always depends on when you run it.",
  "118:58": "I just run it a second time while it's weird looking. Um, now there is something else we",
  "119:06": "can do though, which is that if we look back at our little Excel version. The thing is",
  "119:16": "here, when we multiply these latent factors by these latent factors and add them up, it's",
  "119:25": "not really taking account of the fact that, this user, may just rate movies really badly",
  "119:32": "in general, regardless of what kind of movie they are. And this movie, might be just a",
  "119:39": "great movie in general because everybody likes it, regardless of what kind of stuff they",
  "119:43": "like. And so it'd be nice to be able to represent this directly, and we can do that using something",
  "119:49": "we\ufffdve already learned about, which is bias, we could have another single number for each",
  "119:54": "movie which we just add, and add another single number for each user which we just add, right,",
  "120:01": "now we've already seen this for linear models. You know this idea that it's nice to be able",
  "120:05": "to add a bias value. So let's do that. So that means that we're going to need another",
  "120:14": "embedding for each user, which is of size one it's just a single number we're going",
  "120:19": "to add, so in other words it's just an array lookup, but remember to do an array lookup",
  "120:24": "that we can kind of, take a gradient of, we have to say embedding. We will do the same",
  "120:29": "thing for movie bias and so then, all of this is identical as before and we just add this",
  "120:36": "one extra line, which is to add the user and movie bias values. And so let's train that",
  "120:45": "and see how it goes. Well, that was a shame it got worse, so we used to have, not finished",
  "120:58": "here, 0.87 0.88, 0.89, so it's a little bit worse. Why is that, well if you look earlier",
  "121:08": "on it was quite better it was point 0.86, so it's overfitting very quickly and so what",
  "121:18": "we need to do is, we need to find a way that we can train more epochs without overfitting.",
  "121:26": "Now we've already learned about data augmentation right like rotating images and changing their",
  "121:31": "brightness and color and stuff, but it's not obvious how we would do data augmentation",
  "121:37": "for collaborative filtering right. And so how are we going to make it so that we can",
  "121:42": "train lots of epochs without overfitting. And to do that we're going to have to use",
  "121:49": "something called regularization, and regularization is a set of techniques which basically allow",
  "121:55": "us to use models with lots of parameters and train them for a long period of time, but",
  "122:01": "penalyze them effectively for overfitting. Or, in some way cause them to try to stop",
  "122:07": "overfitting and so that is what we will look at next week. Okay well thanks everybody,",
  "122:15": "so there's a lot to take in here so please remember to practice to experiment but listen",
  "122:21": "to the lessons again because you know for the next couple of lessons things are going",
  "122:27": "to really quickly build on top of all the stuff that we've learnt. So please be as comfortable",
  "122:32": "with it as you can, feel free to go back and re-listen to it and go through and follow",
  "122:37": "through the notebooks, and then try to recreate as much of them yourself. Thanks everybody",
  "122:42": "and I will see you next week or see you in the next lesson whenever you watch it"
}