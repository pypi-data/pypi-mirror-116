{
  "00:00": "So hello, and welcome to Lesson 3 of Practical Deep Learning for Coders. We were looking",
  "00:11": "at getting our model into production last week, and so we're going to finish off that",
  "00:17": "today, and then we're going to start to look behind the scenes at what actually goes on",
  "00:21": "when we train a neural network. We're going to look at the math of what's going on, and",
  "00:28": "we're going to learn about SGD and important stuff like. The order is slightly different",
  "00:36": "to the book: in the book there's a part in the book which says like \u201cHey, you can either",
  "00:39": "go to lesson 4 or lesson 3 now and then go back to the other one afterwards\u201d so we're",
  "00:45": "doing lesson 4 and then lesson 3. Chapter 4 and then Chapter 3, I should say. You can",
  "00:51": "choose it whichever way you're interested in. Chapter 4 is the more technical chapter",
  "00:56": "about the foundations of how deep learning really works. Whereas Chapter 3 is all about",
  "01:01": "ethics, and so with the lessons we'll do that next week. So we're looking at 02 production",
  "01:13": "notebook, and we've got to look at the fastbook version (the one with\u2026in fact everything",
  "01:19": "I'm looking at today will be in the fastbook version). And remember last week we had a",
  "01:25": "look at our bears, and we created this dataloaders object by using the datablock API which i",
  "01:36": "hope everybody's had a chance to experiment with this week--if you haven't, now's a good",
  "01:41": "time to do it! We kind of skipped over one of the lines a little, which is this itm_tfms.",
  "01:50": "So what this is doing here, when we said \u201cResize\u201d: the images we downloaded from the internet",
  "01:56": "were lots of different sizes and lots of different aspect ratios some are tall and some are wide",
  "02:00": "some are square and some are big some are small. When you say resize for an item transform",
  "02:05": "it means each item (so an item in this case is one image) is going to be resized to 128x128",
  "02:14": "by squishing it or stretching it. And so we had a look at, you can always say show_batch",
  "02:19": "to see a few examples, and this is what they look like. Squishing and stretching isn't",
  "02:27": "the only way that we can resize remember we have to make everything into a square before",
  "02:33": "we kind of get it into our model. By the time it gets to our model everything has to be",
  "02:36": "the same size in each mini batch, so that's why... making it a square is not the only",
  "02:41": "way to do that, but it's the easiest way and it\u2019s by far the most common way. Another",
  "02:50": "way to do this is we can create another datablock object, and we can make a datablock object",
  "03:02": "that's an identical copy of an existing datablock object where we can then change just some",
  "03:08": "pieces and we can do that by calling the \u201cnew\u201d method which is super handy. So let's create",
  "03:13": "another datablock object, and this time with different item_transforms where we resize",
  "03:20": "using the \u201cSquish\u201d method. We have a question: what are the advantages of having square images",
  "03:28": "versus rectangular ones? That's a great question. Really, it\u2019s simplicity. If you know all",
  "03:43": "of your images are rectangular, of a particular aspect ratio to start with, you may as well",
  "03:48": "just keep them that way. But if you've got some which are tall and some which are wide,",
  "03:54": "making them all square is kind of the easiest. Otherwise you would have to organize them",
  "03:59": "such as all of the tall ones ended up in a mini batch nor the wide ones ended up in a",
  "04:03": "mini batch, and then you'd have to then figure out what the best aspect ratio for each mini",
  "04:09": "batch is, and we actually have some research that does that in fastai2 ( but it's still",
  "04:15": "a bit clunky). I should mention... Okay, I just lied to you--the default is not actually",
  "04:21": "to squish or stretch: the default (I should have said, sorry) the default when we say",
  "04:26": "resize is actually just to grab the center. So actually all we're doing is we\u2019re grabbing",
  "04:34": "the center of each image. So if we want to squish or stretch you can add the ResizeMethod.Squish",
  "04:39": "argument to Resize and you can now see that this black bear is now looking much thinner,",
  "04:45": "but we have got the kind of leaves that are around on each side for instance.",
  "04:51": "another question when you use the dls dot new method what can and cannot be changed",
  "04:58": "-- is it just the transforms? So it's not dls dot new it's bears dot new, right? So",
  "05:03": "we're not creating a new data loaders object; we're creating a new datablock object. I don't",
  "05:08": "remember off the top of my head so check the documentation and I'm sure somebody can pop",
  "05:12": "the answer into the into the forum. So you can see when we use dot squish that this grizzly",
  "05:21": "bear has got pretty kind of wide and weird-looking and this black bear has got pretty weird and",
  "05:28": "thin-looking and it's easiest kind of to see what's going on if we use ResizeMethod dot",
  "05:34": "pad, and what dot pad does as you can see is it just add some black bars around each",
  "05:39": "side. So you can see the grizzly bear was tall so then when we we stretched (squishing",
  "05:44": "and stretching are opposites of each other) so when we stretched it it ended up wide and",
  "05:49": "the black bear was originally a wide rectangle so it ended up looking kind of thin. You don\u2019t",
  "05:58": "have to user to use zeros. Zeros means pad it with black. You can also say like reflect",
  "06:02": "to kind of have the pixels will kind of look a bit better that way if you use reflect.",
  "06:09": "All of these different methods have their own problems; the the pad method is kind of",
  "06:14": "the cleanest you end up with the correct size, you end up with all of the pixels, but you",
  "06:19": "also end up with wasted pixels so you kind of end up with wasted computation. The squish",
  "06:25": "method is the most efficient because you get all of the information you know and and nothing's",
  "06:33": "kind of wasted, but on the downside your neural nets going to have to learn to kind of like",
  "06:38": "recognize when something's being squished or stretched. And in some cases it might -- it",
  "06:42": "wouldn't even know, so if there's two objects you're trying to recognize, one of which tends",
  "06:46": "to be thin and one of which tends to be thick -- in other words they're the same -- they",
  "06:50": "could actually be impossible to distinguish. And then the default cropping approach actually",
  "06:57": "removes some information so in this case, you know, this grizzly bear here we actually",
  "07:06": "lost a lot of its legs, so if figuring it out, what kind of bear it was required looking",
  "07:12": "at its feet, well, we don't have its feet anymore. So they all have downsides. So there's",
  "07:21": "something else that you can do, a different approach, which is instead of to say resize,",
  "07:25": "you can say RandomResizedCrop. And actually this is the most common approach and what",
  "07:29": "random resize crop does is each time it actually grabs a different part of the image and kind",
  "07:39": "of zooms into it, right? So these, this is all the same image and we're just grabbing",
  "07:44": "a batch of four different versions of it and you can see some are kind of, you know, they're",
  "07:51": "all squished in different ways and we've kind of selected different subsets and so forth.",
  "07:55": "Now this kind of seems worse than any of the previous approaches because I'm losing information.",
  "08:02": "Like this one here -- I've actually lost a whole lot of its, of its back, right, but",
  "08:09": "the cool thing about this is that remember we want to avoid overfitting. And when you",
  "08:15": "see a different part of the animal each time, it's much less likely to overfit because you're",
  "08:21": "not seeing the same image on each epoch that you go around. That make sense? So, so this",
  "08:30": "random resized crop approach is actually super popular, and so min_scale 0.3 means we're",
  "08:36": "going to pick at least 30% of the pixels, of kind of the original size each time, and",
  "08:42": "then we\u2019re going to like zoom in to that that square. So this idea of doing something",
  "08:54": "so that each time the model sees the image it looks a bit different to last time is called",
  "09:00": "data augmentation. And this is one type of data augmentation. It's probably the most",
  "09:06": "common, but there are others and one of the best ways to do data augmentation is to use",
  "09:14": "this aug_transforms function. And what aug_transforms does is it actually returns a list of different",
  "09:24": "augmentations. And so there are augmentations which change contrast, which change brightness,",
  "09:32": "which warps a perspective so you can see in this one here it looks like this bit\u2019s much",
  "09:35": "closer to you and this moves much away from you because it's kind of been perspective",
  "09:38": "warped; it rotates them (see this one's actually being rotated), this one's been made really",
  "09:43": "dark, right?",
  "09:44": "These are batch transforms not item transforms. The difference is that item transforms happen",
  "09:50": "one image at a time and so the thing that resizes them all to the same size that has",
  "09:55": "to be an item transform. Pop it all into a mini batch, put it on the GPU and then a batch",
  "10:00": "transform happens to a whole mini batch at a time. And by putting these as batch transforms",
  "10:06": "the augmentation happens super fast because it happens on the GPU. And I don't know if",
  "10:11": "there's any other libraries as we speak which allow you to write your own GPU accelerated",
  "10:17": "transformations that run on the GPU in this way. So this is a super handy thing in first",
  "10:25": "AI 2. So you can check out the documentation or aug transforms and when you do you'll find",
  "10:36": "the documentation for all of the underlying transforms that it basically wraps. Right",
  "10:41": "so you can see if I shift tab, I don't remember if i have shown you this trick before - if",
  "10:46": "you go inside the parentheses of a function and hit shift tab a few times it'll pop open",
  "10:51": "a list of all of the arguments and so you can basically see you can say like oh can",
  "10:58": "I sometimes flip it left right, can I sometimes flip it up down, what's the maximum amount",
  "11:02": "I can rotate, zoom, change the lighting, warp the perspective and so forth. How can we add",
  "11:12": "different augmentations for train and validation sets? So the cool thing is that automatically",
  "11:20": "fastai will avoid doing data augmentation on the validation set. So all of these aug",
  "11:31": "transforms will only be applied to the training set with the exception of RandomResizedCrop.",
  "11:41": "RandomResizedCrop has a different behavior or each, the behavior for the training set",
  "11:46": "is what we just saw which is to randomly pick a subset and zoom into it and the behavior",
  "11:52": "for the validation set is just to grab the center, the largest center square that it",
  "11:56": "can. You can write your own transformations, they're just Python, they are just standard",
  "12:05": "Pytorch code. And by default it will only be applied to the training set. If you want",
  "12:12": "to do something fancy likeRandomResizedCrop where you actually have different things being",
  "12:15": "applied to each, you should come back to the next course to find out how to do that or",
  "12:19": "read the documentation. It's not rocket science but it's that's something most people need",
  "12:25": "to do. Um okay so last time we did bears.new with a RandomResizedCrop, mean scale of 0.5,",
  "12:38": "we added some transforms and we went ahead and trained. Actually since last week I\u2019ve",
  "12:43": "rerun this notebook and it's on a different computer and I've got different images so",
  "12:47": "it's not all exactly the same but I still got a good confusion matrix. Of the black",
  "12:54": "bears 37 were classified correctly 2 were grizzly's and 1 was a teddy. Now plot top",
  "13:05": "losses is interesting you can see in this case there's some clearly kind of odd things",
  "13:09": "going on this is not a bear at all this looks like it's a drawing of a bear. Which it's",
  "13:15": "decided, is predicted as a Teddy but it's meant to be a drawing of a black bear. I can",
  "13:22": "certainly see the confusion. You can see how some parts that have been cut off we\u2019ll",
  "13:28": "talk about how to deal with that later. Now one of the interesting things is that we didn't",
  "13:33": "really do much data cleaning at all before we built this model the only data cleaning",
  "13:39": "we did was just to validate that each image can be opened, there was that verify images",
  "13:44": "call. And the reason for that is it's actually much easier normally to clean your data after",
  "13:50": "you create a model and I'll show you how. We've got this thing called image classifier",
  "13:55": "cleaner where you can pick a category right and training set or validation set and then",
  "14:07": "what it will do is it will then list all of the images in that set and it will pick the",
  "14:14": "ones which is the least confident about, which is the most likely to be wrong, where the",
  "14:24": "loss is the worst to be more precise. And so this this is a great way to look through",
  "14:33": "your data and find problems. So in this case the first one is not a teddy or a brown bear",
  "14:41": "or a black bear it's a puppy dog, right. So this is a great cleaner because what I can",
  "14:45": "do is I can now click delete here, this one here looks a bit like an Ewok rather than",
  "14:51": "a teddy I'm not sure what do you think Rachel is it an Ewok ?",
  "14:53": "I'm going to call it an Ewok ok and so you can kind of go through okay that's definitely",
  "14:59": "not a teddy and so you can either say like oh that's wrong it's actually a grizzly bear",
  "15:05": "or it's wrong it's a black bear or I should delete it or by default is keep it right and",
  "15:09": "you can kind of keep going through until you think like okay they all seem to be fine maybe",
  "15:14": "that one's not and kind of once you get to the point where all seems to be fine you can",
  "15:21": "kind of say okay probably all the rest to fine too because they all have lower losses",
  "15:26": "so they all fit the kind of the mode of a teddy and so then I can run this code here",
  "15:33": "where I just go through cleaner.delete so that's all the things which I've selected",
  "15:37": "delete for and unlink them so unlink is just another way of saying delete a file that's",
  "15:45": "the Python name and then go through all the ones that we said change and we can actually",
  "15:50": "move them to the correct directory. If you haven't seen this before you might be surprised",
  "15:58": "that we've kind of created our own little GUI inside Jupiter notebook. Yeah you can",
  "16:06": "do this, and we built this with less than a screen of code, you can check out the source",
  "16:11": "code in the past AI notebooks so this is a great time to remind you that this is a great",
  "16:21": "time to remind you that fast.ai is built with notebooks and so if you go to the fast.ai",
  "16:29": "repo and clone it and then go to NBS you'll find all of the code of fast.ai written as",
  "16:39": "notebooks and they've got a lot of prose and examples and tests and so forth. So the best",
  "16:45": "place to learn about how this is implemented is to look at the notebooks rather than looking",
  "16:52": "at the module code. Okay, by the way sometimes you'll see like weird little comments like",
  "17:02": "this. These weird little comments are part of a development environment for Jupiter notebook",
  "17:07": "we use called nbdev which we built so Sylvain and I built this thing to make it much easier",
  "17:13": "for us to kind of create books and websites and libraries in Jupiter notebooks so this",
  "17:20": "particular one here hide means when this is turned into a book or into documentation don't",
  "17:28": "show this cell and the reason for that is because you can see I've actually got it in",
  "17:32": "the text right but I thought when you're actually running it it would be nice to have it sitting",
  "17:37": "here waiting for you to run directly so that's why it's shown in the notebook but not in",
  "17:43": "the in the book has shown differently. And you\u2019ll also see things like s: with a quote",
  "17:50": "in the book that would end up saying Sylvain says and then what he says so there's kind",
  "17:54": "of little bits and pieces in the notebooks that just look a little bit odd and that's",
  "17:59": "because it's designed that way in order to show, in order to create stuff in them. Right,",
  "18:07": "so, then last week we saw how you can export that to a pickle file that contains all the",
  "18:13": "information from the model, and then on the server where you're going to actually do your",
  "18:18": "inference, you can then load that save file and you'll get back a learner that you can",
  "18:23": "call predict on. So predict, perhaps the most interesting part of predict is the third thing",
  "18:34": "that it returns which is a tensor, in this case containing three numbers. But the three",
  "18:40": "numbers there's three of them because we have three classes, teddy bear, grizzly bear and",
  "18:45": "black bear, all right? And so this doesn't make any sense until you know what the order",
  "18:52": "of the classes is, kind of in your data loaders. And you can ask the data loaders what the",
  "19:01": "order is by asking for its vocab. So a vocab in fast.ai is a really common concept it's",
  "19:07": "basically any time that you've got like a mapping from numbers to strings or discrete",
  "19:14": "levels the mapping is always taught in the vocab so here this shows us that the activation",
  "19:24": "of black bear is 1-e6, the activation for grizzly is 1 and the activation for teddy",
  "19:35": "is 1e-6, so very very confident that this particular one it was a grizzly not surprisingly",
  "19:46": "this was something called grizzly.JPEG",
  "19:48": "Umm so you need to know this... this mapping in order to display the correct thing, but",
  "19:58": "of course the data loaders object already knows that mapping, and it's all, the vocab,",
  "20:02": "and it's stored in with the loader, so that's how it knows to say grizzly automatically.",
  "20:07": "So the first thing it gives you is the human readable string that you'd want to display.",
  "20:12": "So this is kind of nice that with fast AI 2 you, you save this object, which has everything",
  "20:18": "you need for inference. It's got all the, you know, information about normalization,",
  "20:23": "about any kind of transformation steps, about what the vocab is, so it can display everything",
  "20:29": "correctly. Right. So now we want to deploy this as an app. Now if you've done some web",
  "20:41": "programming before then all you need to know is that this line of code, and this line of",
  "20:47": "code... So this is the line of codes you would call once when your application starts up,",
  "20:52": "and then this is the line of code you would call every time you want to do inference.",
  "20:56": "And there's also a batch version of it which you can look up if you're interested this",
  "20:59": "is just a \u2018one at a time\u2019. So there's nothing special if you're already a web programmer",
  "21:07": "or have access to a web programmer. These are you know... You just have to stick these",
  "21:11": "two lines of code somewhere and the three things you get back whether, the human readable",
  "21:16": "string if you're doing categorization, the index of that which in this case is one, is",
  "21:21": "grizzly, and the probability of each class. One of the things we really wanted to do in",
  "21:27": "this course though, is not assume that everybody is a web developer. Most data scientists aren't,",
  "21:34": "but gee wouldn't it be great if all data scientists could at least, like, prototype an application",
  "21:39": "to show off the thing they're working on. And so we've... Trying to kind of curate an",
  "21:45": "approach, which none of its stuff we've built, it's really as curated, which shows how you",
  "21:51": "can create a GUI and create a complete application in Jupyter notebook. So the key pieces of",
  "22:01": "technology we use to do this are, ipython widgets which is always called iPy widgets,",
  "22:07": "and Voila. iPy widgets which we import by default as widgets, and that's also what they",
  "22:14": "use in their own documentation, as GUI widgets. For example a file upload button. So if I",
  "22:21": "create this file upload button and then display it, I see, and we saw this in the last lesson",
  "22:28": "as well or maybe lesson one, an actual clickable button. So I can go ahead and click it, and",
  "22:37": "it says now, OK you've selected one thing. So how do I use that? Well these... Well these",
  "22:49": "widgets have all kinds of methods and properties. And the upload button has a data property,",
  "22:56": "which is an array, containing all of the images you uploaded. So you can pass that to PIL",
  "23:04": "image dot create and so dot create is kind of the standard factory method we use in fast",
  "23:12": "AI to create items and PIL image dot create is smart enough to be able to create an item",
  "23:18": "from all kinds of different things and one of the things that it can create it from is",
  "23:22": "a binary blob, which is what a file upload contains. So then we can display it and there's",
  "23:29": "our teddy. Right? So you can see how, you know, cells of Jupyter notebook can refer",
  "23:35": "to other cells that were created, that were... Kind of have GUI created data in them. So",
  "23:43": "let's hide that teddy away for a moment and the next thing to know about is that there's",
  "23:48": "a kind of widget called output and an output widget is... It's basically something that",
  "23:57": "you can fill in later. Right? So if I delete actually this part here. So I've now got an",
  "24:04": "output widget. Yeah, actually let\u2019s do it this way around. And you can't see the output",
  "24:15": "widget even though I said please display it, because nothing is output. So then in the",
  "24:18": "next cell I can say with that output placeholder display a thumbnail of the image and you'll",
  "24:26": "see that the display will not appear here. It appears back here! Right? Because that's",
  "24:33": "how... That's where the placeholder was. So let's run that again to clear out that placeholder.",
  "24:42": "So we can create another kind of placeholder which is a label. The label is kind of a something",
  "24:48": "where you can put text in it. You can give it a value like, I don't know, please choose",
  "24:55": "an image.",
  "24:57": "okay so we've now got a label containing please choose an image. Let's create another button",
  "25:02": "to do a classification, now this is not a file upload button it's just a general button",
  "25:08": "so this button doesn't do anything, right, it doesn't do anything until we attach an",
  "25:15": "event handler to it. An event handler is a callback, we'll be learning all about callbacks",
  "25:20": "in this course, if you've ever done any GUI programming before or even web programming",
  "25:26": "you'll be familiar with the idea that you write a function which is the thing you want",
  "25:31": "to be called when the button is clicked on and then somehow you tell your framework that",
  "25:36": "this is the on click event. So here I go here's my button run, I say the on click event, the",
  "25:44": "button run is, we call this code and this code is going to do all the stuff we just",
  "25:50": "saw. I create an image from the upload, it's going to clear the output, display the image,",
  "25:56": "call predict and then replace the label with a prediction. There it all is. Now so that",
  "26:05": "hasn't done anything but I can now go back to this classify button which now has an event",
  "26:08": "handler attached to it, so watch this: click, boom, and look that's been filled in, thats",
  "26:16": "been filled in. Right, in case you missed it let's run this again, clear everything",
  "26:20": "out. Okay everything's gone, this is please choose an image, there's nothing here, I click",
  "26:30": "classify, bop, bop. Right so it's kind of amazing how our notebook has suddenly turned",
  "26:41": "into this interactive prototyping playground building applications and so once all this",
  "26:47": "works we can dump it all together and so the easiest way to dump things together is to",
  "26:57": "create a V box. So a V box is a vertical box and it's just it's just something that you",
  "27:01": "put widgets in and so in this case we're going to put the following widgets in, and so in",
  "27:05": "this case we going to put the following widgets; a label that says \u201cselect your bear\u201d,",
  "27:07": "then an upload button, a run button an output placeholder and a label for predictions. But",
  "27:14": "let's run these again just to clear everything out so that we're not cheating and let's create",
  "27:21": "our V box. So as you can see it's just got all the all the pieces, right, we've got...oh",
  "27:36": "I accidentally ran the thing that displayed the bear, let's get rid of that. Okay so there",
  "27:48": "it is so now I can click upload, I can choose my bear and then I can click classify and",
  "27:59": "notice this is exactly, that this is, this is the same buttons as these buttons, they're",
  "28:05": "like two places we're viewing the same button, which is kind of a wild idea. So if I click",
  "28:10": "classify it's going to change this label and this label because they're actually both references",
  "28:17": "to the same label; look there we are. So this is our app right and so this is actually how",
  "28:28": "I built that image cleaner GUI, is just using these exact things and I built that image",
  "28:37": "cleaner GUI cell-by-cell in a notebook just like this and so you get this kind of interactive",
  "28:44": "experimental framework for building a GUI so if you're a data scientist who's never",
  "28:49": "done GUI stuff before this is a great time to get started because now you can you can",
  "28:55": "make actual programs. Now of course an actual program running inside a notebook is kind",
  "29:02": "of cool but what we really want is this program to run in a place anybody can run it that's",
  "29:09": "where Voila comes in. So Voila and needs to be installed, so you can just run these lines",
  "29:18": "or install it, it's listed in the prose and what voila does is it takes a notebook and",
  "29:30": "doesn't display anything except for the markdown, the ipython widgets and the outputs, right,",
  "29:38": "so all the code cells disappear and it doesn't give the person looking at that page the ability",
  "29:44": "to run their own code, they can only interact with the widgets, right, so what I did was",
  "29:51": "a copied and pasted that code from the notebook into a separate notebook which only has those",
  "30:00": "lines of code, right, so this is just the same lines of code that we saw before",
  "30:13": "and so this is a notebook, it's just a normal notebook, and then I installed Voila and then",
  "30:21": "when you do that if you navigate to this notebook but you replace \u201cnotebooks\u201d up here with",
  "30:33": "Voila, it actually displays not the notebook but just as I said the markdown and the widgets.",
  "30:44": "So here I've got bear classifier and I can click upload, let's do a grizzly bear this",
  "30:52": "time, and this is a slightly different version I actually made this so there's no classify",
  "31:00": "button I thought it would be a bit more fancy to make it so when you click upload it just",
  "31:04": "runs everything, but as you can see there it all is, right, it's all working. So this",
  "31:10": "is the world's simplest prototype but it's, it's a proof-of-concept right so you can add",
  "31:17": "widgets with dropdowns and sliders and charts and you know, everything that you can have",
  "31:24": "in you know, an angular app or a react app or whatever and in fact there's, there's even",
  "31:32": "stuff which lets you use for example the whole Vue JS framework if you know that, it's a",
  "31:36": "very popular JavaScript framework, the whole Vue JS framework you can actually use it in",
  "31:42": "widgets and Voila. So now we want to get it so that this this app can be run by someone",
  "31:52": "out there in the world. So the voila documentation shows a few ways to do that, but perhaps the",
  "31:57": "easiest one is to use a system called Binder. So Binder is at mybinder.org and all you do",
  "32:09": "is you paste in your github repository name here, right, and this is all in the book,",
  "32:16": "so paste in your Github repo name, you change where it says file, we change that to URL,",
  "32:26": "you can see and then you put in the path which we were just experimenting with, right. So",
  "32:38": "you pop that here and then you say launch and what that does is it then gives you a",
  "32:44": "URL. So then this URL you can pass on to people and this is actually your interactive running",
  "32:54": "application, so Binder is free and so this is, you know, anybody can now use this to",
  "33:00": "take their Voila app and make it a publicly available web application. So try it, as it",
  "33:09": "mentions here the first time you do this Binder takes about five minutes to build your site",
  "33:14": "because it actually uses something called Docker to deploy the whole FastAI framework",
  "33:19": "and Python and blah, blah, blah, but once you've done that, that virtual machine will",
  "33:25": "keep running for, you know, as long as people are using it. It'll keep running for a while,",
  "33:33": "that virtual machine will keep running for a while as long as people are using it and",
  "33:37": "you know it's it's reasonably fast. So a few things to note here, being a free service",
  "33:44": "you won't be surprised to hear this is not using a GPU, its using a CPU, and so that",
  "33:51": "might be surprising but we're deploying to something which runs on a CPU. When you think",
  "33:56": "about it though, this makes much more sense to deploy to a CPU than a GPU the, just a",
  "34:09": "moment, the thing that's happening here is that I am passing along, let's go back to",
  "34:20": "my app; in my app I'm passing along a single image at a time, so when I pass along that",
  "34:26": "single image I don't have a huge amount of parallel work for a GPU to do. This is actually",
  "34:32": "something that a CPU is going to be doing more efficiently so we found that for folks",
  "34:39": "coming through this course, the vast majority of the time they wanted to deploy inference",
  "34:46": "on a CPU not a GPU because they're normally this doing one item at a time. It's way cheaper",
  "34:54": "and easier to deploy to a CPU and the reason for that is that you can just use any hosting",
  "35:00": "service you like because just remember this is just a, this is just a program at this",
  "35:06": "point, right, and you can use all the usual horizontal scaling, vertical scaling you know,",
  "35:13": "you can use Heroku, you can use AWS, you can use inexpensive instances super cheap and",
  "35:19": "super easy. Having said that there are times you might need to deploy to a GPU for example",
  "35:28": "maybe you're processing videos and so like a single video on on a CPU to process it might",
  "35:34": "take all day or you might be so successful that you have a thousand requests per second,",
  "35:43": "in which case you could like take 128 at a time, batch them together and put the whole",
  "35:47": "batch on the GPU and get the results back and pass them back around. You gotta be careful",
  "35:53": "of that right",
  "35:54": "because if your requests aren't coming fast enough, your user has to wait for a whole",
  "35:59": "batch of people to be ready to be processed. But you know conceptually, as long as your",
  "36:08": "site is popular enough that could work. The other thing to talk about is, you might want",
  "36:15": "to deploy to a mobile phone and the point in to a mobile phone our recommendation is",
  "36:23": "wherever possible do that by actually deploying to a server and then have a mobile phone talk",
  "36:28": "to the server over a network. Because if you do that, again you can just use a normal Pytorch",
  "36:36": "program on a normal server and normal network calls, it makes life super easy. When you",
  "36:42": "try to run a Pytorch app on a phone, you are suddenly now not in an environment where Pytorch",
  "36:49": "will run natively and so you'll have to like convert your program into some other form.",
  "36:55": "And there are other forms and the the main form that you convert it to is something called",
  "37:00": "ONNX which is specifically designed for kind of super high speed the high performance you",
  "37:09": "know approach that can run on both servers or on mobile phones and it does not require",
  "37:16": "the whole Python and Pytorch kind of runtime in place but it's much more complex than not",
  "37:28": "using it. It's harder to debug, it's harder to set it up, it's harder to maintain it.",
  "37:33": "So if possible keep things simple, and if you're lucky enough that you're so successful",
  "37:40": "that you need to scale it up to GPUs or and stuff like that then great, you know, hopefully",
  "37:46": "you've got the the finances at that point to justify, you know, spending money on an",
  "37:52": "ONNX expert, or serving expert or whatever. And there are various systems you can use,",
  "37:59": "ONNX runtime, and AWS Sagemaker where you can kind of say, here's my ONNX bundle and",
  "38:04": "it\u2019ll serve it for you or whatever. Pytorch also has a mobile framework, same idea. So,",
  "38:14": "all right, so you've got, I mean it's kind of funny we're talking about two different",
  "38:19": "kinds of deployment here, one is deploying like a hobby application you know that you're",
  "38:24": "prototyping, showing off to your friends, explaining to your colleagues how something",
  "38:28": "might work, you know, a little interactive analysis, that's one thing. But maybe you're",
  "38:32": "actually prototyping something that you want to turn into a real product, or an actual",
  "38:38": "real part of your company's operations. When you're deploying, you know, something in real",
  "38:48": "life, there's all kinds of things you got to be careful of. One example of something",
  "38:54": "to be careful of is, let's say you did exactly what we just did. Which actually, this is",
  "38:59": "your homework, is to create your own application and I want you to create your own image search",
  "39:05": "application you can use my exact set of widgets and whatever if you want to, but better still",
  "39:12": "go to the ipywidgets website, and see what other widgets they have and try and come up",
  "39:15": "with something cool try and come and you know try and show off as best as you can and show",
  "39:21": "us on the forum. Now let's say you decided that you want to create an app that would",
  "39:29": "help the users of your app decide if they have healthy skin or unhealthy skin. So if",
  "39:35": "you did the exact thing we just did rather than searching for grizzly bear and teddy",
  "39:39": "bear and so forth on Bing, you would search for healthy skin and unhealthy skin. And so",
  "39:46": "here's what happens right, if I, and remember in our version we never actually looked at",
  "39:51": "being we just used the Bing API the Image Search API but behind the scenes it's just",
  "39:56": "using the website and so if I click healthy if I type healthy skin and say search, I actually",
  "40:04": "discover that the definition of healthy skin is young white women touching their face lovingly.",
  "40:14": "So that's what your your healthy skin classifier would learn to detect, right, and so this",
  "40:24": "is so this is a great example from Deb Raji and you should check out her paper, \u201cActionable",
  "40:29": "Auditing,\u201d for lots of cool insights about model bias. But I mean here's here's like",
  "40:36": "a fascinating example of how if you weren't looking at your data carefully you you end",
  "40:43": "up with something that doesn't at all actually solve the problem you want to solve.",
  "40:51": "This is tricky. Right? Because the data that you train your algorithm on, if you're building",
  "41:00": "like a new product that didn't exist before, by definition you don't have examples of the",
  "41:06": "kind of data that's going to be used in real life. Right? So you kind of try to find some,",
  "41:10": "from somewhere, and if there and if you do that through like a Google search pretty likely",
  "41:16": "you're not going to end up with a set of data that actually reflects the kind of mix you",
  "41:21": "would see in real life. So you know the main thing here is to say be careful. Right? And,",
  "41:32": "and in particular for your test set, you know, that final set that you check on, really try",
  "41:38": "hard to gather data that reflects the real world. So that goes, you know, for example",
  "41:44": "for the healthy skin example, you might go and actually talk to a dermatologist and try",
  "41:48": "and find like ten examples of healthy and unhealthy skin or something. And that would",
  "41:53": "be your kind of gold standard test. Um. There's all kinds of issues you have to think about",
  "42:01": "in deployment. I can't cover all of them, I can tell you that this O'Reilly book called",
  "42:08": "\u2018Building Machine Learning Powered Applications\u2019 is, is a great resource, and this is one of",
  "42:16": "the reasons we don't go into detail about AP [corrects], A/B testing and when should",
  "42:22": "we refresh our data and how we monitor things and so forth, is because that book has already",
  "42:28": "been written, so we don't want to rewrite it. I do want to mention a particular area",
  "42:36": "that I care a lot about though, which is, let's take this example, let's say you're",
  "42:45": "rolling out this bear detection system, and it's going to be attached to video cameras",
  "42:49": "around a campsite. It's going to warn campers of incoming bears. So if we used the model",
  "42:55": "that was trained with that data that we just looked at, you know, those are all very nicely",
  "43:02": "taken pictures of pretty perfect bears. Right? There's really no relationship to the kinds",
  "43:08": "of pictures you're actually going to have to be dealing with in your, in your campsite",
  "43:12": "bear detector, which has, it's going to have video and not images, it's going to be nighttime,",
  "43:16": "there's going to be probably low resolution security cameras, you need to make sure that",
  "43:23": "the performance of the system is fast enough to tell you about it before the bear kills",
  "43:27": "you. You know, there will be bears that are partially obscured by bushes or in lots of",
  "43:33": "shadow or whatever. None of which are the kinds of things you would see normally in",
  "43:37": "like internet pictures. So what we call this, we call this \u2018out of domain data\u2019. \u2018Out",
  "43:43": "of domain data\u2019 refers to a situation where the data that you are trying to do inference",
  "43:49": "on, is in some way different to the kind of data that you trained with. This is actually...",
  "43:57": "There's no perfect way to answer this question, and when we look at ethics, we\u2019ll talk about",
  "44:04": "some really helpful ways to, to minimize how much this happens. For example, it turns out",
  "44:11": "that having a diverse team is a great way to kind of avoid being surprised by the kinds",
  "44:19": "of data that people end up coming up with, but really is just something you've got to",
  "44:24": "be super thoughtful about. Very similar to that is something called the \u2018main shift\u2019",
  "44:31": "and the \u2018main shift\u2019 is where maybe you start out with all of your data is \u2018in domain",
  "44:37": "data0\u2019, but over time the kinds of data that you're seeing changes and so over time",
  "44:44": "maybe raccoons start invading your campsite, and you weren't training on racoons before,",
  "44:50": "it was just a bear detector, and so that's called \u2018domain shift\u2019 and that's another",
  "44:54": "thing that you have to be very careful of. Rachel, is there a question? No, I was just",
  "44:59": "gonna add to that in saying that, all data is biased, so there's not kind of a, you know,",
  "45:05": "a form of de bias data, perfectly representative in all cases data, and that a lot of the proposals",
  "45:12": "around addressing this have kind of been converging to this idea, and that you see in papers like",
  "45:17": "Timnit Gebru\u2019s \u2018Datasheets for Datasets\u2019 of just writing down a lot of the details",
  "45:24": "about your data set, and how it was gathered, and in which situations it's appropriate to",
  "45:28": "use, and how it was maintained, and so there, that's not that, you've totally eliminated",
  "45:34": "bias but that you're just very aware of the attributes of your data set so that you won't",
  "45:38": "be blindsided by them later. And there have been, kind of, several proposals in that school",
  "45:44": "of thought, which I, which I really like, around this idea of just kind of understanding",
  "45:50": "how your data was gathered and what its limitations are. Thanks Rachel.",
  "45:57": "So a key problem here is that you can't know the entire behavior of your neural network.",
  "46:05": "With normal programming you typed in the if statements and the loops and whatever, so",
  "46:11": "in theory you know what the hell it does. Although, it\u2019s still sometimes surprising.",
  "46:15": "In this case you, you didn't tell it anything, you just gave it examples \u2018alone from\u2019,",
  "46:20": "and hoped that it learned something useful. There are hundreds of millions of parameters",
  "46:25": "in all of these neural networks, and so there's no way you can understand how they all combine",
  "46:30": "with each other to create complex behavior. So really like, there's a natural compromise",
  "46:34": "here is that we're trying to get sophisticated behavior, so like, like recognizing pictures.",
  "46:43": "S-+ophisticated enough behavior we can describe it and so the natural downside is you can't",
  "46:49": "expect the process that the thing is using to do that to be describable. You, for you",
  "46:54": "to be able to understand it. So our recommendation for kind of dealing with these issues is a",
  "47:00": "very careful deployment strategy, which I've summarized in this little graph, this little",
  "47:06": "chart here. The idea would be, first of all whatever it is that you're going to use the",
  "47:12": "model for, start out by doing it manually. So have a park ranger watching for bears.",
  "47:20": "Have the model running next to them and each time the park ranger sees a bear they can",
  "47:25": "check the model and see like, did it seem to have picked it up. So the model is not",
  "47:30": "doing anything. There's just a person who's like, running it and seeing would it have",
  "47:34": "made sensible choices, and once you're confident that it makes sense, that what it's doing",
  "47:39": "seems reasonable, you know, in those as close to the real-life situation as possible, then",
  "47:48": "deploy it in a time and geography limited way. So pick like one campsite, not the entirety",
  "47:55": "of California, and do it for, you know, one day and have somebody watching it super carefully.",
  "48:04": "Right? So now the basic bear detection is being done by the bear detector but there's",
  "48:09": "still somebody watching it pretty closely, and it's only happening in one campsite, for",
  "48:13": "one day, and so then as you say like: \u2018Okay we haven't destroyed our company yet. Let\u2019s",
  "48:20": "do two campsites for a week, and then let's do, you know, the entirety of Marin for a",
  "48:26": "month, and so forth.\u2019 So this is actually what we did when I used to be at this company",
  "48:32": "called \u2018Optimal Decisions\u2019. \u2018Optimal Decisions\u2019 was a company that I founded",
  "48:37": "to do insurance pricing, and if you, if you change insurance prices by, you know, a percent",
  "48:44": "or two in the wrong direction, in the wrong way, you can basically destroy the whole company.",
  "48:50": "This has happened many times, you know. Insurers are companies that set prices. That's basically",
  "48:57": "the product that they provide. So when we deployed new prices for \u2018Optimal Decisions\u2019",
  "49:03": "we always did it by like saying like: \u2018Okay we're going to do it for like five minutes",
  "49:08": "or everybody whose name ends with a D.\u2019 You know? So we kind of try to find some group,",
  "49:15": "which hopefully would be fairly, you know, it would be different, but not too many of",
  "49:20": "them, and we would gradually scale it up, and you've got to make sure that when you're",
  "49:23": "doing this that you have a lot of really good reporting systems in place that you can recognize\u2026",
  "49:29": "Are your customers yelling at you, are your computers burning up, you know, are your,",
  "49:39": "are your computers burning up, are your costs spiraling out of control, and so forth. So",
  "49:45": "it really requires great reporting systems. Does fast AI have methods built-in that provide",
  "49:55": "for incremental learning, i.e., improving the model slowly over time with a single data",
  "50:00": "point each time? Yeah, that's a great question. So this is a little bit different, which is",
  "50:06": "this is really about dealing with \u2018domain shift\u2019 and similar issues by continuing",
  "50:12": "to train your model as you do inference, and so the good news is, you don't need anything",
  "50:17": "special for that. It's basically just a transfer learning problem. So you can do this in many",
  "50:24": "different ways. Probably the easiest is just to say, like: \u2018Okay, each night...\u2019 Probably",
  "50:29": "the easiest is just to say: \u2018Okay, each night, you know, at midnight we're going to",
  "50:35": "set off a task, which grabs all of the previous day's transactions, as mini-batches and trains",
  "50:42": "another epoch.\u2019 And so yeah, that that actually works fine. You can basically think of this",
  "50:50": "as a fine tuning approach, where your pre-trained model is yesterday's model, and your fine-tuning",
  "50:56": "data is today's data.",
  "51:00": "So as you roll out your model, one thing to be thinking about super carefully is that",
  "51:08": "it might change the behavior of the system that it's a part of. And this can create something",
  "51:14": "called a \u2018feedback loop\u2019 and \u2018feedback loops\u2019 are one of the most challenging things",
  "51:18": "for, for real world model deployment, particularly of machine learning models, because they can",
  "51:25": "take a very minor issue and explode it into a really big issue. So, for example, think",
  "51:34": "about a predictive policing algorithm. It's an algorithm that was trained to recognize,",
  "51:42": "you know, basically trained on data that says whereabouts or arrests being made, and then",
  "51:51": "as you train that algorithm based on where arrests are being made, then you put in place",
  "51:58": "a system that sends police officers to places that the model says are likely to have crime,",
  "52:06": "which in this case where were, were there, where were arrests. Well, then more police",
  "52:12": "go to that place, find more crime, because the more police that are there the more they'll",
  "52:18": "see. They arrest more people, causing, you know, and then if you do this incremental",
  "52:23": "learning, like we're just talking about, then it's going to say: \u2018Oh there's actually",
  "52:25": "even more crime here.\u2019 And so tomorrow it sends even more police. And so in that situation",
  "52:31": "you end up like, the predictive policing algorithm ends up kind of sending all of your police",
  "52:36": "on one street block, because at that point all of the arrests are happening there, because",
  "52:42": "that's the only place you have policemen. Right? And I should say police officers. So",
  "52:47": "there's actually a paper about this issue called, \u2018To predict and serve?\u2019. And in",
  "52:53": "\u2018To predict and serve?\u2019 the author's write this really nice phrase: \u2018Predictive policing",
  "52:59": "is aptly named, it is predicting policing, not predicting crime.\u2019 So if the initial",
  "53:07": "model was perfect, whatever the hell that even means, but like it's somehow sent police",
  "53:13": "to exactly the best places to find crime, based on the probability of crimes actually",
  "53:20": "being in place, I guess there's no problem. Right? But as soon as there's any amount of",
  "53:29": "bias. Right? So for example in the US, there's a lot more arrests of black people than of",
  "53:39": "white people, even for crimes where black people and white people are known to do them",
  "53:43": "in the same amount. So in the presence of this bias, or any kind of bias, you're kind",
  "53:51": "of like setting off this domino chain of \u2018feedback loops\u2019, where that bias will be exploded",
  "54:00": "over time. So, you know, one thing I like to think about is to think like well: \u2018What",
  "54:07": "would happen if this, if this model was just really really really good?\u2019. Like: \u2018Who",
  "54:15": "would be impacted?\u2019 You know: \u2018What would this extreme result look like? How would you",
  "54:20": "know what was really happening?\u2019 This incredibly predictive algorithm that was like changing",
  "54:24": "the behavior of yours, of your police officers or whatever, you know. \u2018What would that",
  "54:29": "look like? What would actually happen?\u2019 And then like, think about like: \u2018Okay,",
  "54:35": "what could go wrong?\u2019 And then: \u2018What kind of rollout plan? What kind of monitoring",
  "54:39": "systems? What kind of oversight could provide the circuit breaker?\u2019 Because that's what",
  "54:45": "we really need here. Right? Is, we need like, nothing's going to be perfect, you can't be",
  "54:50": "sure that there's no \u2018feedback loops\u2019, but what you can do is try to be sure that",
  "54:55": "you see when the behavior of your system is behaving in a way that's not what you want.",
  "55:01": "Did you have anything to add to that Rachel? I would add to that is that you're at risk",
  "55:09": "of potentially having a \u2018feedback loop\u2019 anytime that your model is kind of controlling",
  "55:13": "what your next round of data looks like. And I think that's true for pretty much all products,",
  "55:18": "and that can be a hard jump from people, people coming from kind of a science background,",
  "55:24": "where you may be thinking of data as: \u2018I have just observed some sort of experiment.\u2019",
  "55:29": "Where is kind of, whenever you're, you know, building something that interacts with the",
  "55:32": "real world you are now also controlling what your future data looks like based on, kind",
  "55:37": "of, behavior of your algorithm for the current, current round of data. Right? So\u2026 So given",
  "55:45": "that you probably can't avoid \u2018feedback loops\u2019 the, you know, the, the thing you",
  "55:51": "need to then really invest in is the human in the loop. And so a lot of people like to",
  "55:56": "focus on automating things which I find weird, you know, if you can decrease the amount of",
  "56:02": "human involvement by like 90 percent you've got almost all of the economic upside of automating",
  "56:07": "it completely but you still have the room to put human circuit breakers in place. You",
  "56:11": "need these appeals processes, you need the monitoring, you need, you know, humans involved",
  "56:17": "to kind of go: \u2018Hey that's, that's weird. I don't think that's what we want.\u2019",
  "56:22": "Okay, yes Rachel. And just one more note about that. Those humans though do need to be integrated",
  "56:29": "well with kind of product and engineering, and so one issue that comes up is that in",
  "56:35": "many companies I think that ends up kind of being underneath trust and safety handles",
  "56:40": "a lot of sort of issues with, how things can go wrong, or how your platform can be abused,",
  "56:46": "and often trust and safety is pretty siloed away from product and eng, which actually",
  "56:51": "kind of has the, the control over, you know, these decisions that really end up influencing",
  "56:55": "them. And so having... That. They. The engineers probably consider them to be pretty, pretty",
  "56:59": "annoying a lot of the time, how they get in the way, and get in the way of them getting",
  "57:03": "software out the door. Yeah, but like the kind of, the more integration you can have",
  "57:07": "between those I think it's helpful for the kind of the people building the product to",
  "57:11": "see what is going wrong, and what can go wrong. Right. If the engineers are actually on top",
  "57:15": "of that, they're actually seeing these, these things happening, that it's not some kind",
  "57:19": "of abstract problem anymore. So, you know, at this point now that we've got to the end",
  "57:24": "of chapter 2, you actually know a lot more than most people about, about, deep learning,",
  "57:34": "and actually about some pretty important foundations of machine learning, more generally, and of",
  "57:39": "data products more generally. So now\u2019s a great time to think about writing. So, sometimes",
  "57:49": "we have formatted text that doesn't quite format correctly. In Jupyter notebook by the",
  "57:54": "way it only formats correctly in, in the book book. So, that's what it means when you see",
  "57:59": "this kind of pre-formatted text. So... The... The idea here is to think about starting writing,",
  "58:14": "at this point, before you go too much further. Rachel. There's a question. Oh, okay let's",
  "58:20": "hear the question. Question is: \u2018I am, I assume there are fast AI type ways of keeping",
  "58:26": "a nightly updated transfer learning setup. Well could there be one of the fast AI version",
  "58:32": "4 notebooks, have an example of the nightly transfer learning training, like the previous",
  "58:37": "person asked? I would be interested in knowing how to do that most effectively with fast",
  "58:41": "AI.\u2019 Sure. So I guess my view is there's nothing fast AI specific about that at all.",
  "58:48": "So I actually suggest you read Emmanuel\u2019s book. That book I showed you to understand",
  "58:52": "the kind of the ideas, and if people are interested in this I can also point you with some academic",
  "58:57": "research about this as well, and there's not as much as that there should be, but there",
  "59:01": "is some, there is some good work in this area. Okay. So, the reason we mention writing at",
  "59:11": "this point in our journey is because, you know, things are going to start to get more",
  "59:18": "and more heavy, more and more complicated, and a really good way to make sure that you're",
  "59:23": "on top of it is to try to write down what you've learned. So sorry, I wasn\u2019t sharing",
  "59:29": "the right part of the screen before, but this is what I was describing in terms of the pre-formatted",
  "59:33": "text, which doesn't look correct. So... When... So, Rachel actually has this great article",
  "59:45": "that you should check out which is \u2018Why you should blog\u2019, and I will say it's sort",
  "59:51": "of her saying cuz I have it in front of me and she doesn't. Weird as it is. So Rachel",
  "59:57": "says that: \u2018The top advice she would give her younger self is to start blogging sooner.\u2019",
  "60:03": "So Rachel has a math PhD, and this kind of idea of, like, blogging was not exactly something,",
  "60:08": "I think, they had a lot of in the PhD program, but actually it's like, it's a really great",
  "60:15": "way of finding jobs. In fact, most of my students who have got the best jobs are students that",
  "60:22": "have good blog posts. The thing I really love is that it helps you learn by, by writing",
  "60:30": "down, it kind of synthesizes your ideas, and yeah, you know, there's lots of reasons to",
  "60:38": "blog. So there's actually something really cool I want to show you. Yeah. I was also",
  "60:45": "just gonna note I have a second post called \u2018Advice for Better Blog Posts\u2019, that's",
  "60:50": "a little bit more advanced, which I'll post a link to as well, and that, talks about some",
  "60:56": "common pitfalls that I've seen in many, in many blog posts, and kind of the importance",
  "61:00": "of putting, putting the time in to do it well, and and some things to think about. So I'll",
  "61:05": "share that post as well. Thanks Rachel.",
  "61:07": "Um, so one reason that sometimes people don't blog is because it's kind of annoying to figure",
  "61:12": "out how to. Particularly, because I think the thing that a lot of you will want to blog",
  "61:17": "about is cool stuff that you're building in Jupyter notebooks. So, we've actually teamed",
  "61:23": "up with a guy called Hamel Husain, and, and with GitHub to create this free product. As",
  "61:33": "usual with fast AI, no ads, no anything, called \u2018fastpages\u2019, where you can actually blog",
  "61:40": "with Jupyter notebooks. And so you can go to \u2018fastpages\u2019 and see for yourself how",
  "61:46": "to do it, but the basic idea is that, like, you literally click one button, it sets up",
  "61:53": "a plug for you, and then you dump your notebooks into a folder called underscore notebooks,",
  "62:01": "and they get turned into blog posts. It's... It's basically like magic, and Hamel's done",
  "62:07": "this amazing job of this, and so... This means that you can create blog posts where you've",
  "62:14": "got charts, and tables, and images, you know, where they're all actually the output of,",
  "62:20": "of Jupyter notebook, along with all the, the markdown formatted text, headings, and so",
  "62:28": "forth, and hyperlinks, and the whole thing. So this is a great way to start writing about",
  "62:34": "what you're learning about here. So something that Rachel and I both feel strongly about",
  "62:41": "when it comes to blogging is this, which is, don't try to think about the absolute most",
  "62:51": "advanced thing you know and try to write a blog post that would impress Geoff Hinton.",
  "62:56": "Right? Because most people are not Geoff Hinton. So like, (a) you probably won't do a good",
  "63:02": "job, because you're trying to, like, blog for somebody who's more, got more expertise",
  "63:06": "than you, and (b) you've got a small audience now. Right? Actually there's far more people",
  "63:13": "that are not very familiar with deep learning, than people who are. So try to think, you",
  "63:18": "know, and, and you really understand what it's like, what it was like six months ago",
  "63:22": "to be you, because you were there six months ago. So try and write something, which the",
  "63:27": "six months ago version of you would have been, like, super interesting, full of little tidbits",
  "63:32": "you would have loved, you know, that you would, that would have delighted you, that six months",
  "63:38": "ago version of you. Okay. So once again, don't move on until you've had a go at the questionnaire,",
  "63:47": "to make sure that you, you know, understand the key things we think that you need to understand,",
  "63:54": "and, yeah, have a think about these further research questions as well, because they might",
  "64:00": "help you to engage more closely with material. So let's have a break, and we'll come back",
  "64:05": "in five minutes time. So welcome back everybody. This is an interesting moment in the course,",
  "64:18": "because we're kind of jumping from a part of the course, which is, you know, very heavily",
  "64:25": "around kind of the, kind of the, the structure of like what are we trying to do with machine",
  "64:33": "learning, and what are the kind of the pieces, and what do we need to know to make everything",
  "64:38": "kind of work together. There was a bit of code, but not masses. There was basically",
  "64:44": "no math, and we kind of want to put that at the start for everybody who's not, you know,",
  "64:52": "who's kind of wanting to, an understanding of, of these issues, without necessarily wanting",
  "65:01": "to, kind of, dive deep into the code, in the math themselves. And now we're getting into",
  "65:05": "the diving deeper part. If, if you're not interested in that diving deep yourself, you",
  "65:12": "might want to skip to the next lesson about ethics, where we, you know, is kind of, that",
  "65:17": "rounds out the kind of, you know, slightly less technical material. So what we're going",
  "65:26": "to look at here is, we're going to look at what we think of as kind of a toy problem,",
  "65:33": "but just a few years ago is considered a pretty challenging problem. The problem is recognizing",
  "65:40": "handwritten digits, and we're going to try and do it from scratch. Right? And we're gonna",
  "65:47": "try and look at a number of different ways to do it. So, we're going to have a look at",
  "65:52": "a dataset called MNIST, and so, if you've done any machine learning before you may well",
  "65:58": "have come across MNIST. It contains handwritten digits and it was collided into a machine",
  "66:04": "learning data set by a guy called Yann LeCun and some colleagues, and they used that to",
  "66:09": "demonstrate one of the, you know, probably the first computer system to provide really",
  "66:14": "practically useful scalable recognition of handwritten digits. LeNet-5 was the system,",
  "66:20": "was actually used to automatically process like 10% of the checks in the, in the US.",
  "66:28": "So, one of the things that really helps, I think, when building a new model is to, kind",
  "66:34": "of, start with something simple, and gradually scale it up. So, we've created an even simpler",
  "66:41": "version of MNIST, which we call MNIST_SAMPLE, which only has threes and sevens. Okay, so",
  "66:47": "this is a good starting point to make sure that we can, kind of, do something easy. I",
  "66:51": "picked threes and sevens for MNIST_SAMPLE, because they're very different. So I feel",
  "66:54": "like, if we can't do this, we're going to have trouble recognizing every digit. [coughs]",
  "67:02": "So step one is to call untar_data, untar_data is the fast AI function which takes a URL,",
  "67:10": "checks whether you've already downloaded it, if you haven't it downloads it, checks whether",
  "67:16": "you've already uncompressed it, if you haven't, it uncompress is it, and then it finally returns",
  "67:21": "the path of where that ended up. So you can see here URLs.MNIST_SAMPLE. So you could just",
  "67:30": "hit tab to get autocomplete. Is just some, some location. Right? Doesn't really matter",
  "67:41": "where it is, and so then when we... All that, I've already downloaded it, and already uncompressed",
  "67:49": "it, because I've already run this once before, so it happens straight away, and so path shows",
  "67:55": "me where it is. Now in this case path is dot, and the reason path is dot is, because I've",
  "68:01": "used this special base path attribute to path, to tell it kind of like where's my, where's",
  "68:08": "my starting point, you know, and, and that's used to print so when I go here ls, which",
  "68:13": "prints a list of files, these are all relative to where I actually untarred this to. So it",
  "68:20": "just makes it a lot easier not to have to see the whole set of parent path folders.",
  "68:28": "Um ls is actually... So, so path is a... Let's see what kind of type it is. So, it's a pathlib",
  "68:40": "path object. Um, pathlib is part of the Python standard library. It's a really very, very,",
  "68:48": "very nice library, but it doesn't actually have ls. Where there are libraries that we",
  "68:54": "find super helpful, but they don't have exactly the things we want, we liberally add the things",
  "68:58": "we want to them. So we add ls. Right? So if you want to find out what ls is, you know,",
  "69:09": "there's, as we've mentioned it's a few ways you can do it you can pop a question mark",
  "69:13": "there, and that will show you where it comes from. So there's actually a library called",
  "69:18": "fastcore, which is a lot of the foundational stuff in fast AI that is not dependent on",
  "69:23": "PyTorch, or pandas, or any of these big heavy libraries. So, this is part of fastcore and",
  "69:32": "if you want to see exactly what it does, you, of course remember, you can put in a second",
  "69:35": "question mark, to get the source code, and as you can see there's not much source code",
  "69:42": "to it. And, you know, maybe most importantly, please, don't forget about doc, because really",
  "69:52": "importantly that gives you this \u2018Show in docs\u2019 link, which you can click on to get",
  "69:56": "to the documentation to see examples, pictures, if relevant, tutorials, tests ,and so forth.",
  "70:07": "So what's, so when you're looking at a new data set, you kind of just used, I always",
  "70:13": "start with just ls, see what's in it, and I can see here there's a train folder, and",
  "70:18": "there's a valid folder, that's pretty normal. So let's look at ls on the train folder, and",
  "70:26": "it's got a folder called 7 and a folder called 3, and so this is looking quite a lot like",
  "70:31": "our bear classifier dataset. We downloaded each set of images into a folder based on",
  "70:38": "what its label was. This is doing it at another level though. The first level of the folder",
  "70:44": "hierarchy is, is it training or valid, and the second level is, what's the label. And",
  "70:50": "this is the most common way for image datasets to be distributed. So let's have a look. Let's",
  "71:01": "just create something called 3s, that contains all of the contents of the three directory.",
  "71:07": "Training. And let's just sort them, so that this is consistent. Do the same for sevens,",
  "71:11": "and let's look at the 3s and you can see there's just, they\u2019re just numbered. All right.",
  "71:17": "So let's grab one of those, open it, and take a look. Okay. So, there's the picture of a",
  "71:26": "3. And so what is that really?",
  "71:31": "But not 3, im3. So PIL is the Python Imaging Library. It's the most popular library by",
  "71:40": "far for working with images on Python and it's a PNG, not surprisingly. So Jupyter notebook",
  "71:52": "knows how to display many different types and you can actually tell if you create a",
  "71:58": "new type you can tell it how to display your type. And so PIL comes with something that",
  "72:02": "will automatically display the image, like so. What I want to do here though is to look",
  "72:08": "at like how we're going to treat this as numbers, right. And so one easy way to treat things",
  "72:14": "as numbers is to turn it into an array. The array is part of numpy, which is the most",
  "72:20": "popular array programming library for Python. And so if we pass our PIL image object to",
  "72:31": "array, it just converts the image into a bunch of numbers. And the truth is, it was a bunch",
  "72:37": "of numbers the whole time. It was actually stored as a bunch of numbers on disk. It's",
  "72:42": "just that there's this magic thing in Jupyter that knows how to display those numbers on",
  "72:46": "the screen. Now let me say, array(), turning it back into a numpy array. We're kind of",
  "72:52": "removing this ability for Jupyter notebook to know how to display it like a picture.",
  "72:57": "So once I do this, we can then index into that array and (create everything from the)",
  "73:02": "grab everything, all the rows from 4 up to but not including 10, and all the columns",
  "73:07": "from 4 up to and not including 10. And here are some numbers and they are 8-bit unsigned",
  "73:14": "integers, so they are between 0 and 255. So an image, just like everything on a computer,",
  "73:21": "is just a bunch of numbers. And therefore, we can compute with it. We could do the same",
  "73:28": "thing, but instead of saying array(), we could say tensor(). Now our tensor is basically",
  "73:34": "the PyTorch version of a numpy array. And so you can see it looks, it's exactly the",
  "73:41": "same code as above, but I've just replaced array() with tensor(). And the output looks",
  "73:45": "almost exactly the same, except it replaces array with tensor and so you'll see this - that",
  "73:51": "basically a PyTorch tensor and an numpy array behave nearly identically, much if not most",
  "73:59": "of the time. But the key thing is that a PyTorch tensor can also be computed on a GPU, not",
  "74:06": "just a CPU. So in in our work, and in the book, and in the notebooks, in our code, we",
  "74:13": "tend to use tensors, PyTorch tensors, much more often than numpy arrays because they",
  "74:18": "kind of have nearly all the benefits of numpy arrays, plus all the benefits of GPU computation.",
  "74:24": "And they've got a whole lot of extra functionality as well. A lot of people who have used Python",
  "74:32": "for a long time, always jump into numpy because that's what they used to. If that's you, you",
  "74:38": "might want to start considering jumping into tensor. Like wherever you used to write array,",
  "74:43": "just start writing tensor and just see what happens. Because you might be surprised at",
  "74:46": "how many things you can speed up or do it more easily. So let's grab that that 3 image,",
  "74:55": "turn it into a tensor and so that's going to be a 3 image tensor - that's why I've got",
  "75:00": "a im3_t here. And let's grab a bit of it, okay, and turn it into a panda's data frame.",
  "75:06": "And the only reason I'm turning it into a panda's data frame is that pandas has a very",
  "75:10": "convenient thing called background_gradient() that turns a background into a gradient, as",
  "75:15": "you can see. So here is the top bit of the 3. You can see that the 0s are the whites",
  "75:22": "and the numbers near 255 are the blacks. Okay, and there\u2019s some whatsit bits in the middle",
  "75:27": "which, which are grey. So here we have, we can see what's going on when our images, which",
  "75:35": "are numbers, actually get displayed on the screen. It's just it's just doing this, okay,",
  "75:41": "and so I'm just showing a subset here the actual phone number and MNIST is a 28 by 28",
  "75:46": "pixels square. So that's 768 pixels. So that's super tiny, right. Well my mobile phone, I",
  "75:54": "don't know how many megapixels it is, but it's millions of pixels. So it's nice to start",
  "75:59": "with something simple and small, okay. So, here's our goal - create a model, but by model,",
  "76:08": "I just mean some kind of computer program learnt from data that can recognize 3s versus",
  "76:14": "7s. You can think of it as a 3 detector. Is it a 3, because if it's not a 3, it's a 7.",
  "76:21": "So have a stop here, pause the video and have a think. How would you do it? How would you,",
  "76:28": "like you don't need to know anything about neural networks, or anything else. How might",
  "76:32": "you, just with common sense, build a 3 detector, okay?",
  "76:38": "So I hope you grabbed a piece of paper, a pen, jotted it some notes down. I\u2019ll tell",
  "76:43": "you the first idea that came into my head was \u2026 what if we grab every single 3 in",
  "76:51": "the data set and take the average of the pixels? So what's the average of this pixel, the average",
  "76:59": "of this pixel, the average of this pixel, the average of this pixel, right. And so there'll",
  "77:03": "be a 28 by 28 picture which is the average of all of the 3s, and that would be like the",
  "77:11": "ideal 3. And then we'll do the same for 7s. And then so when we then grab something from",
  "77:17": "the validation set to classify, we\u2019ll say, \u201cLike, oh, is this image closer to the ideal",
  "77:24": "3s, the ideal 3, the mean of the 3s, or the ideal 7? This is my idea and so I'm going",
  "77:31": "to call this the pixel similarity approach. I'm describing this as a baseline. A baseline",
  "77:37": "is like a super simple model that should be pretty easy to program from scratch with very",
  "77:42": "little magic. You know, maybe it's just a bunch of kind of simple averages, simple arithmetic,",
  "77:47": "which you're super confident is going to be better than, better than a random model, right.",
  "77:53": "And one of the biggest mistakes I see, in even experienced practitioners, is that they",
  "77:59": "fail to create a baseline. And so then they build some fancy Bayesian model or, or some",
  "78:06": "fancy, fancy Bayesian model or some fancy neural network and they go, \u201cWow, Jeremy",
  "78:14": "look at my amazingly great model!\u201d And I'll say like, \u201cHow do you know it's amazingly",
  "78:18": "great?\u201d and they\u2019ll say, \u201coh, look, the accuracy is 80%.\u201d And then I'll say,",
  "78:21": "\u201cOkay, let's see what happens if we create a model where we always predict the mean.",
  "78:26": "Oh look, that's 85%.\u201d And people get pretty disheartened when they discover this, right.",
  "78:33": "And so make sure you start with a reasonable baseline and then gradually build on top of",
  "78:37": "it. So we need to get the average of the pixels, so we're going to learn some nice Python programming",
  "78:48": "tricks to do this. So the first thing we need to do is we need a list of all of the 7s.",
  "78:55": "So remember we've got the 7s - maybe it is just a list of file names, right. And so for",
  "79:06": "each of those file names in the 7s, lets Image.open() that file just like we did before to get a",
  "79:13": "PIL object, and let's convert that into a tensor. So this thing here is called a list",
  "79:18": "comprehension. So if you haven't seen this before, this is one of the most powerful and",
  "79:22": "useful tools in Python. If you've done something with C#, it's a little bit like link - it's",
  "79:28": "not as powerful as link, but it's a similar idea. If you've done some functional programming",
  "79:33": "in in JavaScript, it's a bit like some of the things you can do with that, too. But",
  "79:36": "basically, we're just going to go through this collection, each item will become called",
  "79:43": "\u201co\u201d, and then it will be passed to this function, which opens it up and turns it into",
  "79:47": "a tensor. And then it will be collated all back into a list. And so this will be all",
  "79:52": "of the 7s as tensors. So Silva and I use lists and dictionary comprehensions every day. And",
  "80:04": "so you should definitely spend some time checking it out, if you haven't already. So now that",
  "80:10": "we've got a list of all of the 3s as tensors, let's just grab one of them and display it.",
  "80:20": "So remember, this is a tensor, not a PIL image object. Ao Jupyter doesn't know how to display",
  "80:27": "it. So we have to use something a command to display it - and show_image() is a fast.ai",
  "80:34": "command that displays a tensor. And so here is 3. So we need to get the average of all",
  "80:43": "of those 3s. So to get the average, the first thing we need to do is to (turn) change this",
  "80:50": "so it's not a list, but it's a tensor itself. Currently three_tensors[1] has a shape which",
  "81:06": "is 28 by 28. Oh this is this is the rows by columns, the size of this thing, right. But",
  "81:13": "three_tensors itself, it's just a list. But I can't really easily do mathematical computations",
  "81:23": "on that. So what we could do is we could stack all of these 28 by 28 images on top of each",
  "81:27": "other to create a, like a 3d cube of images. And that's still quite a tensor. So a tensor",
  "81:36": "can have as many of these axes or dimensions as you like. And to stack them up you use,",
  "81:42": "funnily enough, stack(). And so this is going to turn the list into a tensor. And as you",
  "81:48": "can see the shape of it is now 6131 by 28 by 28. So it's kind of like a cube of height",
  "81:57": "6131 by 28 by 28.",
  "82:07": "The other thing we want to do is, if we're going to take the mean we want to turn them",
  "82:11": "into floating-point values, because we don't want to kind of have integers rounding off.",
  "82:18": "The other thing to know is that it's just kind of a standard in computer vision that",
  "82:25": "when you are working with floats, that you expect them to be between 0 and 1. So we just",
  "82:31": "divide by 255, because they were between 0 and 255 before. So this is a pretty standard",
  "82:37": "way to kind of represent a bunch of images in PyTorch. So these three things here are",
  "82:47": "called the axes -- first axis, second axis, third axis, and overall we would say that",
  "82:55": "this is a rank 3 tensor, as it has three axes. So this one here was a rank two tensor -- just",
  "83:05": "has two axes. So you can get the rank from a tensor by just taking the length of its",
  "83:12": "shape: one, two, three. You can also get that from, so the word -- I've been using the word",
  "83:23": "axis -- you can also use the word dimension. I think numpy tends to call it axis; pytorch",
  "83:31": "tends to call it dimension. So the rank is also the number of dimensions: ndim. So you",
  "83:42": "need to make sure that you remember this word. Rank is the number of axes or dimensions in",
  "83:46": "a tensor, and the shape is a list containing the size of each axis in a tensor.",
  "83:58": "So we can now say stacked_threes.mean(). Now, if we just say stacked_threes.mean(), that",
  "84:09": "returns a single number -- that's the average pixel across that whole cube, that whole rank",
  "84:14": "three tensor. But if we say mean(0), that is: take the mean over this axis, so that's",
  "84:21": "the mean across the images, right? And so that's now 28 by 28 again, because we kind",
  "84:32": "of like reduced over this 6131 axis. We took the mean across that axis and so we can show",
  "84:42": "that image, and here is our ideal three. So here's the ideal seven using the same approach.",
  "84:50": "All right, so now let's just grab a three -- it's just any old three -- there it is.",
  "84:56": "And what I'm going to do is I'm going to say, \u201cWell, is this three more similar to the",
  "85:01": "perfect three, or is it more similar to the perfect seven?\u201d And whichever one it's more",
  "85:05": "similar to, I'm going to assume that that's the answer. So we can't just say look at each",
  "85:14": "pixel and say what's the difference between this pixel you know zero zero here, and zero",
  "85:21": "zero here, and then 0 1 here, and then 0 1 here, and take the average. And the reason",
  "85:25": "we can't just take the average is that there's positives and negatives, and they're going",
  "85:29": "to average out to nothing, right, so I actually need them all to be positive numbers.",
  "85:36": "So there's two ways to make them all positive numbers. I could take the absolute value,",
  "85:40": "which simply means remove the minus signs, okay? And then I could take the average of",
  "85:46": "those; that's called the mean absolute difference or L1 norm. Or I could take the square of",
  "85:57": "each difference and then take the mean of that, and then at the end I could take the",
  "86:02": "square root, kind of undoes the squaring, and that's called the root mean squared error,",
  "86:09": "or L2. So let's have a look. Let's take a three and subtract from it the mean of the",
  "86:18": "threes, and take the absolute value, and take the mean and call that the distance using",
  "86:25": "absolute value of the three to a_3. And there is the number, .1. And so this is the mean",
  "86:33": "absolute difference, or L1 norm. So when you see a word like L1 norm, if you haven't seen",
  "86:38": "it before it may sound pretty fancy, but all these math terms that we see, you know you",
  "86:44": "can turn them into a tiny bit of code, right? It's, you know, don't let the mathy bits fool",
  "86:53": "you. They're often -- like in code it's just very obvious what they mean, whereas with",
  "86:57": "math you just, you just have to learn it, or learn how to google it.",
  "87:03": "So here\u2019s the same version for squaring: take the difference, square it, take the mean,",
  "87:08": "and then take the square root. So now we'll do the same thing for our three; this time",
  "87:15": "we'll compare it to the mean of the sevens. All right, so the distance from a_3 to the",
  "87:20": "mean of the threes in terms of absolute was .1, and the distance from a_3 to the mean",
  "87:26": "of the sevens was 0.15. So it's closer to the mean of the threes than it is to the mean",
  "87:33": "of the sevens, so we guess therefore that this is a three, based on the mean absolute",
  "87:40": "difference. Same thing with RMSE (root mean squared error) would be to compare this value",
  "87:47": "with this value, and again root mean squared error is closer to the mean3 than to the mean7.",
  "87:54": "So this is like a machine learning model (kind of); it\u2019s a data-driven model which attempts",
  "88:01": "to recognize threes versus sevens, and so this is a good baseline. I mean, it's a reasonable",
  "88:07": "baseline, it's going to be better than random. We don't actually have to write out \u201c- abs",
  "88:15": "mean\u201d -- we can just actually use L1 loss. Now, L1 loss does exactly that; we don't have",
  "88:25": "to write \u201c- squared\u201d -- we can just write mse_loss, and that doesn't do the square root",
  "88:30": "by default so we have to pop that in. Okay? And as you can see, they're exactly the same",
  "88:36": "numbers. It's very important before we kind of go too",
  "88:43": "much further, to make sure we're very comfortable working with arrays and tensors. And you know,",
  "88:49": "they're so similar. So we could start with a list of lists, right, which is kind of a",
  "88:56": "matrix. We can convert it into an array, or into a tensor. We can display it, and they",
  "89:05": "look almost the same. You can index into a single row, you can index into a single column,",
  "89:13": "and so it's important to know -- this is very important -- colon means every row, because",
  "89:20": "I put it in the first spot. Right, so if it were in the second spot it would mean every",
  "89:26": "column and so therefore comma colon ( ,: ) is exactly the same as removing it. So it just",
  "89:37": "turns out you can always remove colons that are at the end, because they're kind of, they're",
  "89:42": "just implied, right? You never have to, and I often kind of put them in anyway, because",
  "89:47": "just kind of makes it a bit more obvious how these things kind of match up, or how they",
  "89:55": "differ. You can combine them together so give me the first row and everything from the first",
  "90:01": "up to but not including the third column -- back to this at 5, 6. You can add stuff to them;",
  "90:09": "you can check their type. Notice that this is different to the Python type, right, so",
  "90:18": "type is a function; this tells you it's a tensor. If you want to know what kind of tensor,",
  "90:23": "you have to use type as a method. So it's a long tensor. You can multiply them by a",
  "90:31": "float, turns it into a float. You know so have a fiddle around if you haven't done much",
  "90:34": "stuff with numpy or PyTorch before, this is a good opportunity to just go crazy -- try",
  "90:43": "things out. Try things that you think might not work and see if you actually get an error",
  "90:47": "message, you know. So we now want to find out how good is our",
  "90:57": "model? Our model that involves just comparing something to to the mean. So we should not",
  "91:11": "compare\u2026 you should not check how good our model is on the training set. As we've discussed,",
  "91:17": "we should check it on a validation set, and we already have a validation set: it's everything",
  "91:23": "inside the valid directory. So let's go ahead and like combine all those steps before. Let's",
  "91:28": "go through everything in the validation set 3.ls(). Open them, turn them into a tensor,",
  "91:35": "stack them all up, turn them into floats, divide by 255.",
  "91:40": "Okay, let's do the same for sevens. So we're just putting all the steps we did before into",
  "91:47": "a couple of lines.",
  "91:50": "I always try to print out shapes, like all the time, because if a shape is not what you",
  "91:56": "expected then you can, you know, get weird things going on. So the idea is we want some",
  "92:03": "function is_three that will return true if we think something is a three. So to do that",
  "92:10": "we have to decide whether our digit that we're testing on is closer to the ideal three or",
  "92:17": "the ideal seven. So let's create a little function that returns the difference between",
  "92:28": "two things, takes the absolute value and then takes the mean. So we're going to create this",
  "92:35": "function mnist_distance that takes the difference between two tensors, takes their absolute",
  "92:43": "value, and then takes the mean. And it takes the mean, and look at this, we got minus this",
  "92:47": "time, it takes the mean over the last -- over the second last and third last -- sorry the",
  "92:58": "last and second last dimensions. So this is going to take the mean across the kind of",
  "93:07": "x and y axes. And so here you can see it's returning a single number, which is the distance",
  "93:14": "of a three from the mean3. So that's the same as the value that we got earlier: .1114. So",
  "93:25": "we need to do this for every image in the validation set because we're trying to find",
  "93:30": "the overall metric. Remember: the metric is the thing we look at to say how good is our",
  "93:34": "model. So here's something crazy: we can call mnist_distance not just on a three, but on",
  "93:43": "the entire validation set, against the mean three. That's wild! Like, there's no normal",
  "93:53": "programming that we would do where we could somehow pass in either a matrix or a rank",
  "94:00": "3 tensor and somehow it works both times. And what actually happened here is that instead",
  "94:08": "of returning a single number it returned 1,010 numbers. And it did this because it used something",
  "94:18": "called broadcasting. And broadcasting is like the super special magic trick that lets you",
  "94:26": "make Python into a very very high-performance language, and in fact, if you do this broadcasting",
  "94:33": "on GPU tensors and PyTorch, it actually does this operation on the GPU even though you",
  "94:37": "wrote it in Python. Here's what happens. Look here this a - b. So we\u2019re doing a-b on two",
  "94:48": "things. We've got first of all valid_3_tens, so valid three tensor is a thousand or so",
  "94:59": "images, right, and remember that mean3 is just our single ideal three. So what is something",
  "95:09": "of this shape minus something of this shape? Well, broadcasting means that if this shape",
  "95:18": "doesn't match this shape, like if they did match it would just subtract every corresponding",
  "95:25": "item, but because they don't match, it actually acts as if there's a thousand and ten versions",
  "95:33": "of this. So it's actually going to subtract this from every single one of these okay.",
  "95:43": "So broadcasting -- let's look at some examples. So broadcasting requires us to first of all",
  "95:50": "to understand the idea of element-wise operations. This is an element-wise operation. Here is",
  "95:55": "a rank 1 tensor of size 3 and another rank 1 tensor of size 3, so we would say these",
  "96:02": "sizes match (they're the same) and so when I add 1, 2, 3, to 1, 1, 1 I get back 2 3 4.",
  "96:10": "It just takes the corresponding items and adds them together. That's called element-wise",
  "96:15": "operations. So when I have different shapes, as we described before, what it ends up doing",
  "96:31": "is it basically copies this number a thousand and ten times, and it acts as if we had said",
  "96:38": "valid_3_tens minus 1,010 copies of mean3. As it says here it doesn't actually copy mean3",
  "96:50": "1,010 times; it just pretends that it did, right? It just acts as if it did, so basically",
  "96:55": "kind of loops back around to the start again and again and it does the whole thing in C",
  "97:00": "or in CUDA on the GPU. So then we see absolute value, right? So let's go back up here after",
  "97:09": "we do the minus, we go absolute value so what happens when we call absolute value on something",
  "97:18": "of size 1010 by 28 by 28? It just calls absolute value on each underlying thing right and then",
  "97:29": "finally we call mean. -1 is the last element always in Python, -2 is the second-last.",
  "97:38": "So this is taking the mean over the last two axes, and so then it's going to return just",
  "97:45": "the first axis. So we're going to end up with 1,010 means -- 1,010 distances, which is exactly",
  "97:53": "what we want: we want to know how far away is our each of our validation items from the",
  "98:01": "the ideal three. So then we can create our is_3 function, which is, \u201cHey, is the distance",
  "98:11": "between the number in question and the perfect three less than the distance between the number",
  "98:17": "in question and the perfect seven?\u201d If it is, it's a three, right? So our three, that",
  "98:23": "was an actual three we had: is it a three? Yes. Okay, and then we can turn that into",
  "98:29": "a float, and \u201cyes\u201d becomes 1.0. Thanks to broadcasting, we can do it for that entire",
  "98:38": "set, right? So this is so cool! We basically get rid of loops. In this kind of programming,",
  "98:47": "you should have very few, very very few loops. Loops make things much harder to read, and",
  "98:54": "hundreds of thousands of times slower (on the GPU potentially tens of millions of times",
  "98:58": "slower). So we can just say is_3 on our whole valid_3_tens and then turn that into float,",
  "99:07": "and then take the mean; so that's going to be the accuracy of the threes on average.",
  "99:11": "And here's the accuracy of the sevens -- it's just one minus that -- and so the accuracy",
  "99:16": "across threes is about 91 and a bit percent. The accuracy on sevens is about 98%, and the",
  "99:23": "average of those two is about 95%. So here we have a model that's 95 percent accurate",
  "99:31": "at recognizing threes from sevens. It might surprise you that we can do that using nothing",
  "99:38": "but arithmetic, right, but so that's what I mean by getting a good baseline.",
  "99:48": "Now the thing is, it's not obvious how we kind of improve this, right? I mean the thing",
  "99:57": "is, it doesn't match Arthur Samuel\u2019s description of machine learning. This is not something",
  "100:04": "where there's a function which has some parameters which we're testing against some kind of measure",
  "100:11": "of fitness, and then using that to like improve the parameters iteratively. We kind of, we",
  "100:16": "just did one step and that's that, okay? So we will try and do it in this way where",
  "100:24": "we arrange for some automatic means of testing the effectiveness of -- he called it a weight",
  "100:28": "assignment, we'd call it a parameter assignment -- in terms of performance, and a mechanism",
  "100:33": "for altering the weight assignment to maximize the performance. But we won\u2019t do it that",
  "100:38": "way, right, because we know from Chapter 1, from Lesson 1, that if we do it that way,",
  "100:44": "we have this like magic box called machine learning that can do -- you know, particularly",
  "100:52": "combined with neural nets -- should be able to solve any problem, in theory, if you can",
  "100:58": "at least find the right set of weights. So we need something that we can get better and",
  "101:04": "better, to learn. So let's think about a function which has parameters. So instead of finding",
  "101:17": "an ideal image and seeing how far away something is from the ideal image, so instead of like",
  "101:28": "having something where we test how far away we are from an ideal image, what we could",
  "101:33": "instead do is come up with a set of weights for each pixel. So we're trying to find out",
  "101:40": "if something is the number three, and so we know that like in the places that you would",
  "101:46": "expect to find \u20183\u2019 pixels, you could give those like high weights. So you can say,\u201dHey,",
  "101:51": "if there's a dot in those places, we give it like a high score and if there's dots in",
  "101:57": "other places we'll give it like a low score. So we can actually come up with a function",
  "102:02": "where the probability of something being, well in this case let's say an eight, is equal",
  "102:10": "to the pixels in the image multiplied by some sort of weights, and then we sum them up,",
  "102:18": "right, so then anywhere where our -- the image we're looking at, you know, has pixels where",
  "102:28": "there are high weights, it's going to end up with a high probability. So here x is the",
  "102:34": "image that we're interested in, and we're just going to represent it as a vector, so",
  "102:40": "let's just have all the rows stacked up, end to end into a single long line. So we're going",
  "102:48": "to use an approach where we're going to start with a vector W. So a vector is a Rank 1 tensor,",
  "102:55": "okay? We\u2019re going to start with a vector W that's going to contain random weights,",
  "103:03": "random parameters, depending on whether you use the Arthur Samuel version of the terminology",
  "103:08": "or not.",
  "103:10": "And so, we'll then predict whether a number appears to be a three or a seven by using",
  "103:18": "this tiny little function. And then we will figure out how good the model is. Where we",
  "103:27": "will calculate like, how accurate it is or something like that. Yeah this is the loss,",
  "103:34": "and then the key step is we're then going to calculate the gradient. Now the gradient",
  "103:39": "is something that measures for each weight if I made it a little bit bigger will the",
  "103:44": "loss get better or worse. If I made it a little bit smaller will the loss get better or worse?",
  "103:50": "And so if we do that for every weight we can decide for every weight whether we should",
  "103:54": "make that weight a bit bigger or a bit smaller. That\u2019s called the gradient. Right? So once",
  "104:00": "we have the gradient we then step, is the word we use is step. Change all the weights,",
  "104:09": "up a little bit for the ones where the gradient we should, said, we should make them a bit",
  "104:13": "higher, and down a little bit for all the ones where the gradient said they should be",
  "104:16": "a bit lower. So now it should be a tiny bit better and then we go back to step two and",
  "104:23": "calculate a new set of predictions, using this formula, calculate the gradient again,",
  "104:29": "step the weights, keep doing that. So this is basically the flow chart and then at some",
  "104:34": "point when we're sick of waiting or when the loss gets good enough we'll stop. So these",
  "104:42": "seven steps 1, 2, 3, 4, 5, 6, 7\u2026 These seven steps are the key to training all deep learning",
  "104:53": "models. This technique is called stochastic gradient descent. Well, it's called gradient",
  "104:58": "descent, we\u2019ll see the stochastic bit very soon. And for each of these seven steps there's",
  "105:05": "lots of choices around exactly how to do it. Right? We've just kind of hand waved a lot,",
  "105:11": "like what kind of random initialization, and how do you calculate the gradient, and exactly",
  "105:16": "what step do you take based on the gradient, and how do you decide when to stop, blah blah",
  "105:20": "blah. Right? So in this... In this course we're going to be like learning about, you",
  "105:26": "know, these steps, you know, that's kind of part one, you know. I then the other big part",
  "105:33": "is like, well what's the actual function, neural network. So how do we train the thing",
  "105:37": "and what is the thing that we train. So, we initialize parameters with random values.",
  "105:43": "We need some function that's going to be the loss function that will return a number that's",
  "105:47": "small if the performance of the model is good. We need some way to figure out whether the",
  "105:54": "weight should be increased a bit or decreased a bit, and then we need to decide like when",
  "106:01": "to stop, which will just say let's just do a certain number of epochs. So, let's like,",
  "106:08": "go even simpler. Right? We're not even going to do MNIST. We're going to start with this",
  "106:13": "function x squared, okay? And in fast AI we've created a tiny little thing called plot function,",
  "106:19": "that plots a function. All right, so there\u2019s our function f, and what we're going to do",
  "106:29": "is we're going to try to find this is our loss function. So we're going to try and find",
  "106:36": "the bottom point. Right? So we're going to try and figure out what is the x value, which",
  "106:41": "is at the bottom. So our seven step procedure requires us to start out by initializing,",
  "106:48": "so we need to pick some value. Right? So the value we pick, which is to say: \u2018oh let's",
  "106:53": "just randomly pick minus one and a half.\u2019 Great! So now we need to know, if I increase",
  "107:01": "x a bit, does my, but remember this is my loss does my loss get a bit better, remember",
  "107:06": "better is smaller, or a bit worse. So we can do that easily enough. We can just try a slightly",
  "107:11": "higher x and a slightly lower x and see what happens. Right? And you can see it's just",
  "107:17": "the slope. Right? The slope at this point tells you that if I increase x by a bit then",
  "107:25": "my loss will decrease, because that is the slope at this point. So, if we change our,",
  "107:33": "our weight, our parameter, just a little bit in the direction of the slope. Right? So here",
  "107:40": "is the direction of the slope and so here's the new value at that point, and then do it",
  "107:46": "again, and then do it again, eventually we'll get to the bottom of this curve. Right?",
  "107:53": "So this idea goes all the way back to Isaac Newton, at the very least, and this basic",
  "107:59": "idea is called Newton's method. So a key thing we need to be able to do is to calculate this",
  "108:07": "slope. And the bad news is to do that we need calculus. At least that\u2019s bad news for me",
  "108:16": "because I've never been a fan of calculus. We have to calculate the derivative. Here's",
  "108:21": "the good news, though. Maybe you spent ages in school learning how to calculate derivatives",
  "108:27": "- you don't have to anymore, the computer does it for you, and the computer does it",
  "108:33": "fast. It uses all of those methods that you learned at school and a whole lot more - like",
  "108:40": "clever tricks for speeding them up, and it just does it all automatically. So, for example,",
  "108:46": "it knows (I don't know if you remember this from high school) that the derivative of x",
  "108:50": "squared is 2x. It\u2019s just something it knows, it's part of its kind of bag of tricks, right.",
  "108:58": "So, so PyTorch knows that. PyTorch has an engine built in that can take derivatives",
  "109:05": "and find the gradient of functions. So to do that we start with a tensor, let's say,",
  "109:14": "and in this case we're going to modify this tensor with this special method called requires_grad.",
  "109:21": "And what this does is it tells PyTorch that any time I do a calculation with this xt,",
  "109:28": "it should remember what calculation it does so that I can take the derivative later. You",
  "109:34": "see the underscore at the end? An underscore at the end of a method in PyTorch means that",
  "109:40": "this is called an in-place operation it actually modifies this. So, requires_grad_ modifies",
  "109:48": "this tensor to tell PyTtorch that we want to be calculating gradients on it. So that",
  "109:54": "means it's just going to have to keep track of all of the computations we do so that it",
  "109:58": "can calculate the derivative later. Okay, so we've got the number 3 and let's say we",
  "110:08": "then call f on it (remember f is just squaring it, so 3 squared is 9. But the value is not",
  "110:16": "just 9, it's 9 accompanied with a grad function which is that it knows that a power operation",
  "110:22": "has been taken. So we can now call a special method, backward(). And backward(), which",
  "110:31": "refers to backpropagation, which we'll learn about, which basically means take the derivative.",
  "110:37": "And so once it does that we can now look inside xt, which we said requires grad, and find",
  "110:44": "out its gradient. And remember, the derivative of x squared is 2x. In this case that was",
  "110:52": "3, 2 times 3 is 6. All right, so we didn't have to figure out the derivative we just",
  "111:01": "call backward(), and then get the grad attribute to get the derivative. so that's how easy",
  "111:07": "it is to do calculus in PyTorch. So what you need to know about calculus is not how to",
  "111:16": "take a derivative, but what it means. And what it means is it's a slope at some point.",
  "111:26": "Now here's something interesting - let's not just take3, let's take a Rank 1 tensor also",
  "111:34": "known as a vector [3., 4., 10.] and let's add sum to our f function. So it's going to",
  "111:42": "go x squared .sum. and now we can take f of this vector, get back 125. And then we can",
  "111:53": "say backward() and grad and look - 2x 2x 2x. So we can calculate, this is, this is vector",
  "112:07": "calculus, right. We're getting the gradient for every element of a vector with the same",
  "112:14": "two lines of code. So that's kind of all you need to know about calculus, right. And if",
  "112:23": "this is, if this idea that, that a derivative or gradient is a slope is unfamiliar, check",
  "112:31": "out Khan Academy. They had some great introductory calculus. And don't forget you can skip all",
  "112:36": "the bits here they teach you how to calculate the gradients yourself. So now that we know",
  "112:43": "how to calculate the gradient, that is the slope of the function, that tells us if we",
  "112:48": "change our input a little bit, how will our output change correspondingly. That's what",
  "112:55": "a slope is, right. And so that tells us that for every one of our parameters, if we know",
  "113:02": "their gradients, then we know if we change that parameter up a bit or down a bit, how",
  "113:07": "will it change our loss. So therefore, we then know how to change our parameters. So",
  "113:13": "what we do is, let's say all of our weights are called \u201cw\u201d, we just subtract off them",
  "113:21": "the gradients multiplied by some small number and that small number is often a number between",
  "113:29": "about 0.001 and 0.1 and it's called the learning rate and this here is the essence of gradient",
  "113:39": "descent",
  "113:41": "So if you pick a learning rate that's very small, then you take the slope and you take",
  "113:46": "a really small step in that direction, and another small step, another small step, another",
  "113:51": "small step, and so on, it's going to take forever to get to the end. If you pick a learning",
  "113:56": "rate that's too big, you jump way too far each time and again, it's going to take forever.",
  "114:04": "And in fact in this case, sorry this case we're assuming we're starting here and it's",
  "114:09": "actually is so big it got worse and worse. Or here's one where we start here and it's",
  "114:16": "like it's not so big it gets worse and worse, but it just takes a long time to bounce in",
  "114:21": "and out right. So picking a good learning rate is really important, both to making sure",
  "114:28": "that it's even possible to solve the problem and that it's possible to solve it in a reasonable",
  "114:33": "amount of time. So we'll be learning about picking, how to pick learning rates in this",
  "114:38": "course. So let's try this, let's try using gradient",
  "114:47": "descent. I said SGD, that's not quite accurate, it's just going to be gradient descent to",
  "114:52": "solve an actual problem. So the problem we're going to solve is, let's imagine you were",
  "114:59": "watching a roller coaster go over the top of a hump, right. So as it comes out of the",
  "115:06": "previous hill it's going super fast and it's going up the hill and it's going slower and",
  "115:12": "slower and slower until it gets to the top of the hump, and then it goes down the other",
  "115:16": "side, it gets faster and faster and faster. So if you like how to stopwatch or whatever",
  "115:20": "or some kind of speedometer and you are measuring it just by hand at kind of equal time points",
  "115:28": "you might end up with something that looks a bit like this, right. And so the way I did",
  "115:33": "this was I just grabbed a range, just grabbed the numbers from naught up to, but not including",
  "115:39": "20, right. These are the time periods at which I'm taking my speed measurement. And then",
  "115:45": "I've just got some quadratic function here - I multiplied by 3 and then square it and",
  "115:51": "then add 1, whatever, right. And then I also, actually sorry. I take my time - 9.5 square",
  "116:00": "it, times .75, and add 1. And then I add a random number to that or add a random number",
  "116:06": "to every observation. So I end up with a quadratic function which is a bit bumpy. So this is",
  "116:11": "kind of like what it might look like in real life because my speedometer kind of testing",
  "116:17": "is not perfect. All right, so we want to create a function that estimates at any time what",
  "116:27": "is the speed of the roller-coaster. So we start by guessing what function it might be.",
  "116:33": "So we guess that it's a function - a times time squared, plus b times time, plus c - you",
  "116:41": "might remember from school is called a quadratic. So let's create a function, right. And so",
  "116:48": "let's create it using kind of the Alpha Samuels technique, the machine learning technique.",
  "116:53": "This function is going to take two things - it's going to take an input, which in this",
  "116:57": "case is a time, and it's going to take some parameters. And the parameters are a, b, and",
  "117:04": "c. So in Python you can split out a list or a collection into its components, like so.",
  "117:11": "And then here's that function. So we\u2019re not just trying to find any function in the",
  "117:17": "world, we're just trying to find some function which is a quadratic by finding an a, and",
  "117:22": "a b, and a c. So the Arthur Samuel technique for doing this is to next up come up with",
  "117:30": "a loss function; come up with a measurement of how good we are. So if we've got some predictions",
  "117:35": "that come out of our function and the targets which are these, you know, actual values,",
  "117:43": "then we could just do the mean squared error. Okay, so here's that means squared error we",
  "117:50": "saw before - the difference squared, then take the mean. So now we need to go through",
  "117:57": "our seven step process, we want to come up with a set of three parameters a, b and c,",
  "118:03": "which are as good as possible. So step one is to initialize a, b, and c to random values.",
  "118:08": "So this is how you get random values, three of them in PyTorch. And remember we're going",
  "118:13": "to be adjusting them, so we have to tell PyTorch that we want the gradients. I'm just going",
  "118:20": "to save those away so I can check them later. And then I calculate the predictions using",
  "118:25": "that function, f, which was this. And then let's create a little function which just",
  "118:34": "plots how good at this point are our predictions. So here is a function that prints in red our",
  "118:42": "predictions, and in blue our targets. So that looks pretty terrible.",
  "118:47": "So let\u2019s calculate the loss, using the mse function we wrote. Okay, so now we want to",
  "118:55": "improve this. So calculate the gradients using the two steps we saw, call backward and then",
  "119:01": "get grad. And this says that each of our parameters has a gradient that's negative. Let's pick",
  "119:10": "a learning rate of ten to the minus five, or we multiply that by ten to the minus five,",
  "119:19": "and step the weights, And remember step the weights means minus equals the learning rate",
  "119:25": "times the gradient. There\u2019s a wonderful trick here, which I\u2019ve called .data. The",
  "119:33": "reason I've called .data is that .data is a special attribute in PyTorch, which if you",
  "119:38": "use it, then the gradient is not calculated. And we certainly wouldn't want the gradient",
  "119:46": "to be calculated of the actual step we're doing. We only want the gradient to be calculated",
  "119:51": "of our function, f. All right, so when we step the weights we have to use this special",
  "119:58": ".data attribute. After we do that, delete the gradients that we already had and let's",
  "120:06": "see if loss improved. So the loss before was 25800, now it's 5,400. And the plot has gone",
  "120:17": "from something that goes down to -300 to something that looks much better. So let's do that a",
  "120:26": "few times. So I just grabbed those previous lines of code and pasted them all into a single",
  "120:31": "cell. Okay so preds, loss.backward, data grad = none. And then from time-to-time print the",
  "120:38": "loss out, and repeat that ten times. And look getting better and better. And so we can actually",
  "120:48": "look at it getting better and better. So this is pretty cool, right. We have a technique,",
  "120:56": "this is the Arthur Samuel technique for finding a set of parameters that continuously improves",
  "121:06": "by getting feedback from the result of measuring some loss function. So that was kind of the",
  "121:13": "key step, right. This, this is the gradient descent method. So you should make sure that",
  "121:20": "you kind of go back and feel super comfortable with what's happened. And you know, if you're",
  "121:27": "not feeling comfortable, that that's fine, right. If it's been a while, or if you've",
  "121:30": "never done this kind of gradient descent before, this might feel super unfamiliar. So kind",
  "121:37": "of try to find the first cell in this notebook where you don't fully understand what it's",
  "121:42": "doing, and then stop and figure it out. Look at everything that's going on, do some experiments,",
  "121:50": "do some reading until you understand that cell where you're stuck before you move forwards.",
  "121:59": "So let's now apply this to MNIST. So for MNIST we want to use this exact technique and there's",
  "122:12": "basically nothing extra we have to do. Except one thing - we need a loss function. And the",
  "122:22": "metric that we've been using is the error rate, or the accuracy. It's like how often",
  "122:27": "are we correct, right. And and that's the thing that we're actually trying to make good,",
  "122:32": "our metric. But we've got a very serious problem - which is, remember we need to calculate",
  "122:39": "the gradient to figure out how we should change our parameters. And the gradient is the slope",
  "122:46": "or the steepness, which you might remember from school is defined as rise over run. It's",
  "122:52": "(y_new - y_old) divided by (x_new - x_old). So the gradients actually defined when x_new",
  "123:01": "is is very very close to x_old, meaning their difference is very small. That, think about",
  "123:09": "it - accuracy. If I change a parameter by a tiny tiny tiny amount, the accuracy might",
  "123:16": "not change at all because there might not be any 3 that we now predict as a 7 or any",
  "123:24": "7 that we now predict as a 3, because we change the parameter by such a small amount. So it's",
  "123:31": "it's it's possible, in facr, it's certain, that the gradient is zero at many places and",
  "123:38": "that means that our parameters aren't going to change at all. Because learning rate times",
  "123:43": "gradient is still zero when the gradient\u2019s zero for any learning rate. So this is why",
  "123:52": "the loss function and the metric are not always the same thing. We can't use a metric as our",
  "124:02": "loss if that metric has a gradient of zero. So we need something different. So, we want",
  "124:11": "to find something that kind of is pretty similar to the accuracy in that like as the accuracy",
  "124:19": "gets better",
  "124:21": "this ideal function we want gets better as well but it should not have a gradient of",
  "124:26": "zero. So let's think about that function. Suppose we had three images. Actually, you",
  "124:38": "know what? This is actually probably a good time to stop. Because actually, you know,",
  "124:45": "we've we've kind of, we've got to the point here where we understand gradient descent.",
  "124:52": "We kind of know how to do it with a simple loss function and I actually think before",
  "124:57": "we start lookin",
  "124:58": "g at the MNIST loss function, we shouldn't move on. Because we've got so much so much",
  "125:05": "assignments to do for this week already. So, we've got built your web application, and",
  "125:10": "we've got both step-through-step through this notebook to make sure you fully understand",
  "125:15": "it. So I actually think we should probably stop right here before we make things too",
  "125:23": "crazy. So before I do, Rachel, are there any questions? Okay great, all right. Well thanks",
  "125:31": "everybody. Sorry for that last-minute change of tack there but I think this is going to",
  "125:35": "make sense. So I hope you have a lot of fun with your web applications. Try and think",
  "125:41": "of something that's really fun, really interesting. It doesn't have to be like, important. It",
  "125:47": "could just be some you know cute thing. We've had students before, a student that I think",
  "125:52": "he said he had 16 different cousins, and he created something that would classify a photo",
  "126:00": "based on which of his cousins... It was for, like his fiancee meeting his family. [laughs]",
  "126:04": "You know you can come up with anything you like, but you know, yeah, show off your application",
  "126:11": "and maybe have a look around at what ipywidgets can do, and try and come up with something",
  "126:17": "that you think is pretty cool. All right, thanks everybody. I will see you next week!"
}