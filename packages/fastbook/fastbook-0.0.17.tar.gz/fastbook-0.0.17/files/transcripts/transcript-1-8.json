{
  "00:00": "Hi everybody and welcome to lesson eight, the last lesson of part one of this course.",
  "00:07": "Thanks so much for sticking with us. Got a very interesting lesson today where we're",
  "00:12": "going to dive into natural language processing, and remind you we did see natural language",
  "00:17": "processing in Lesson One. This was it here: we looked at a dataset where we could pass",
  "00:26": "in many movie reviews like so and get back probabilities that it's a positive or negative",
  "00:33": "sentiment, and we trained it with a very standard-looking classifier trainer approach. But we haven't",
  "00:41": "really talked about what's going on behind the scenes there, so let's let's do that and",
  "00:46": "we\ufffdll also learn about how to make it better. So we were getting about 93%, so 93% accuracy",
  "00:52": "for sentiment analysis which is actually extremely good, and it only took a bit over ten minutes,",
  "00:59": "but let's see if we can do better. So we're going to go to notebook number 10 and in notebook",
  "01:09": "number ten we are going to start by talking about what we are going to do to train an",
  "01:16": "NLP classifier. So a sentiment analysis which is: is this movie review positive or negative",
  "01:22": "sentiment, is just a classifier; the dependent variable is binary, and the independent variable",
  "01:28": "is the kind of the interesting bit. So we're going to talk about that, but before we do,",
  "01:33": "we're going to talk about what was the pre-trained model that got used here? Because the reason",
  "01:40": "we got such a good result so quickly, is because we are doing fine tuning of a pre-trained",
  "01:44": "model. So what is this pre-trained model, exactly? Now the pre-trained model is actually",
  "01:51": "a pre-trained language model. So what is a language model? A language model is a special",
  "02:00": "kind of model, and it's a model where we try to predict the next word of a sentence. So",
  "02:08": "for example if our language model received \ufffdeven if our language model knows the\ufffd",
  "02:17": "then its job would be to predict \ufffdbasics.\ufffd Now, the language model that we use as our",
  "02:24": "pre-trained model was actually trained on Wikipedia. So we took all the, you know, non-trivial",
  "02:32": "sized articles in Wikipedia, and we built a language model which attempted to predict",
  "02:37": "the next word of every sequence of words, in every one of those articles, and it was",
  "02:45": "a neural network of course. And we then take those pre-trained weights, and those are the",
  "02:50": "pre-trained weights that when we said text_classifier_learner were automatically loaded in. So, conceptually,",
  "02:57": "why would it be useful to pre-train a language model? How does that help us to do sentiment",
  "03:02": "analysis, for example? Well, just like an ImageNet model has a lot of information about",
  "03:10": "what pictures look like and what they're consisting of, a language model tells us a bit, a lot",
  "03:16": "about what sentences look like and what they know about the world. So a language model,",
  "03:24": "for example, if it's going to be able to predict the end of the sentence, \ufffdIn 1998 this law",
  "03:34": "was passed by president...what?\ufffd So a language model to predict that correctly would have",
  "03:41": "to know a whole lot of stuff. It would have to know about, well, how English language",
  "03:45": "works in general and what kind of sentences go in what places; that after the word President",
  "03:51": "would usually be the surname of somebody; it would need to know what country that law",
  "03:56": "was passed in and would need to know what President was president of that country in",
  "04:01": "nineteen-- what did I say? 1998. So it\ufffdd have to know a lot about the world it'd have",
  "04:06": "to know a lot about language. To create a really good language model is really hard,",
  "04:12": "and in fact this is something that people spend many many many millions of dollars on",
  "04:18": "creating language models of huge datasets Our particular one doesn't take particularly",
  "04:24": "long to pre-trained but there's no particular reason for you to pre-train one of these language",
  "04:29": "models because you can download them through fastai or through other places. So what happened",
  "04:37": "in Lesson One is we downloaded this pre-trained wikipedia model and then we fine-tuned it.",
  "04:45": "So as per usual we threw away the last layer which was specific for",
  "04:49": "predicting the next word of Wikipedia and fine-tuned the model, initially just the last",
  "04:56": "layer to learn to predict sentiment of movie reviews, and then as per usual, then fine-tune",
  "05:04": "the rest of the model and that got us 93%. Now, there's a trick we can use, though, which",
  "05:11": "is we start with this Wikipedia language model, and the particular subset we use is called",
  "05:16": "a WikiText-103, and rather than just jumping straight to a classifier, which we did in",
  "05:22": "Lesson One, we can do even better if we first of all create an IMDB language model. That",
  "05:28": "is to say, a language model that learns to predict the next word of a movie review. The",
  "05:33": "reason we do that is that this will help it to learn about IMDB-specific kinds of words,",
  "05:40": "like, like it'll learn a lot more about the names of actors and directors; it'll learn",
  "05:44": "about the kinds of words that people use in movie reviews. And so if we do that first",
  "05:50": "then we would hope we will end up with a better classifier. So that's what we're going to",
  "05:54": "do in the first part of today's lesson, and we're going to kind of do it from scratch.",
  "06:01": "And we're going to show you how to do a lot of the things from scratch even though later",
  "06:05": "we'll show you how fastai does at all for you. So how do we build a language model?",
  "06:12": "So as we point out here, sentences can be different lengths, and documents like movie",
  "06:17": "reviews can be very long. So how do we go about this? Well, a word is basically a categorical",
  "06:28": "variable and we already know how to use categorical variables as an independent variable in a",
  "06:32": "neuron net, which was we make a list of all of the possible levels of a categorical variable,",
  "06:37": "which we call the vocab, and then we replace each of those categories with its index so",
  "06:44": "they all become numbers. We create an initially random embedding matrix for each, so each",
  "06:50": "row then is for one element from the vocab, and then we make that the first layer of a",
  "06:56": "neural net. So that's what we've done a few times now, and we've even created our own",
  "07:03": "embedding layer from scratch, remember? So we can do the same thing with text, right?",
  "07:08": "We can make a list of all the possible words in -- in the whole corpus, the whole dataset,",
  "07:15": "and we can replace each word with the index of the vocab and create an embedding matrix.",
  "07:21": "So in order to create a list of all levels -- in this case a list of all possible words",
  "07:27": "-- let's first of all concatenate all the documents, all the movie reviews, together",
  "07:32": "into one big long string, and split it into words. Okay and then our independent variable",
  "07:39": "will basically be that sequence, starting with the first word in the long list and ending",
  "07:44": "with the second last, and our dependent variable will be the sequence of words starting with",
  "07:48": "the second word and ending with the last. So they're kind of offset by one. So as you",
  "07:53": "move through the first sequence you're then trying to predict the next word in the next,",
  "07:59": "in the second part. That's kind of what we're doing, right? We'll see more detail in a moment.",
  "08:06": "Now when we create our vocab by finding all the unique words in this concatenated corpus,",
  "08:14": "a lot of the words we see will be already in the embedding matrix, already in the vocab",
  "08:20": "of the pre-trained Wikipedia model. But there's also going to be some new ones, right? There",
  "08:26": "might be some particular actors that don't appear in Wikipedia, or maybe some informal",
  "08:32": "slang words and so forth. So when we build our vocab and then our embedding matrix for",
  "08:42": "the IMDB language model, any words that are in the vocab of the pre-trained model we'll",
  "08:49": "just use them as is. But for new words, we\ufffdll create a new random vector. So here's the",
  "08:58": "process we're going to have to go through. First we're going to have to take our big",
  "09:03": "concatenated corpus and turn it into a list of tokens: could be words, could be characters,",
  "09:09": "could be substrings. That's called tokenization. And then we'll do numericalization, which",
  "09:18": "is basically these two steps, which is replacing each word with its index in a vocab, which",
  "09:23": "means we have to create that vocab. So create the vocab and then convert. Then",
  "09:28": "we're going to need to create a data loader that has lots of substrings, lots of sequences",
  "09:34": "of tokens from our IMDB corpus as an independent variable, and the same thing offset by one",
  "09:41": "as a dependent variable, and then we're going to have to create a language model. Now, a",
  "09:49": "language model is going to be able to handle input lists that can be arbitrarily big or",
  "09:55": "small, and we're going to be using something called a recurrent neural network to do this,",
  "09:59": "which we'll learn about later. So basically, so far we've always assumed that everything",
  "10:03": "is a fixed size, a fixed input, so we're going to have to mix things up a little bit here",
  "10:08": "and deal with architectures that can be different sizes. For this notebook, notebook 10, we're",
  "10:15": "going to kind of treat it as a black box, it's just going to be just a neural net, and",
  "10:20": "then later in the lesson we'll look at delving inside what's happening in that architecture.",
  "10:26": "Okay so let's start with the first of these, which is tokenization. So converting a text",
  "10:34": "into a list of words or a list of tokens. What does that mean? Is a full-stop a token?",
  "10:42": "What about \ufffddon't\ufffd -- is that single word or is it two words, do-n't? Or is it -- would",
  "10:47": "I convert it to a \ufffddo not?\ufffd What about long medical words that are kind of made up",
  "10:52": "of lots of pieces of medical jargon that are all stuck together? What about hyphenated",
  "10:56": "words? And really interestingly then, what about something like Polish where you -- or",
  "11:02": "Turkish -- where you can create really long words? All the time they create really long",
  "11:07": "words that are actually, lots of separate parts are concatenated together. Or languages",
  "11:11": "like Japanese and Chinese that don't use spaces at all? They don't really have a well defined",
  "11:19": "idea of \ufffdword?\ufffd Well, there's no right answer, but there's basically three approaches.",
  "11:26": "We can use a word-based approach, which is what we use by default at the moment for English",
  "11:31": "(although that might change) which is: we split a sentence on spaces, and then there",
  "11:35": "are some language-specific rules, for example turning don't into do-n\ufffdt and putting punctuation",
  "11:41": "marks as a separate token most of the time. Really interestingly, there are tokenizers",
  "11:48": "that are subword-based, and this is where we split words into smaller parts based on",
  "11:53": "the most commonly occurring substrings. We'll see that in a moment. Or the simplest, character-based:",
  "12:00": "split a sentence into its characters. We're going to look at word- and sub-word tokenization",
  "12:05": "in this notebook. And then if you look at the questionnaire at the end, you'll be asked",
  "12:09": "to create your own character-based tokenizer, so please make sure you do that if you can,",
  "12:14": "it'll be a great exercise! So fastai doesn't invent its own tokenizers. We just provide",
  "12:25": "a consistent interface to a range of external tokenizers, because there's a lot of great",
  "12:29": "tokenizers out there. So you can switch between different tokenizers pretty easily. So let's",
  "12:37": "start. Let's grab our IMDb dataset like we did in lesson 1 and in order to try out a",
  "12:43": "tokenizer, let's grab all the text files. So we can, instead of calling get_image_files,",
  "12:49": "we'll call get_text_files, and it'll -- to have a look at what that's doing, that get,",
  "12:54": "we can even look at the source code and you can see actually it's calling a more general",
  "12:59": "thing called get_files and saying what extensions at once right so if anything in fast AI doesn't",
  "13:04": "work quite the way you want and there isn't an option which works the way you want, you",
  "13:08": "can often look, always look underneath to see what we're calling, and you can call the",
  "13:13": "lower-level stuff yourself. So files is now a list of files. So we can grab the first",
  "13:19": "one, we can open it, we can read it, have a look at the start of this review, and here",
  "13:26": "it is. Okay so at the moment at the default English word tokenizer we use is called spaCy,",
  "13:35": "which uses a pretty sophisticated set of rules -- the",
  "13:39": "special rules for particular words and URLs, and so forth -- but we're just going to go",
  "13:46": "ahead and say WordTokenizer which will automatically use fastai\ufffds default word tokenizer, currently",
  "13:53": "spaCy. And so if we pass a list of documents (we'll just make it a list of one document",
  "13:59": "here) to the tokenizer we just created and just grab the first, since we just created",
  "14:04": "a list, that's going to show us, as you can see, the tokenized version. So you can see",
  "14:11": "here that \ufffdThis movie which I just discovered at the video store has\ufffd etc. it changed",
  "14:19": "\ufffdit\ufffds\ufffd into \ufffdit\ufffd and \ufffd\ufffds\ufffd and it's put a comma as a separate punctuation",
  "14:26": "mark, and so forth. Okay so you can see how it has tokenized this review. Let's look at",
  "14:39": "a more interesting one: \ufffdThe US dollar\ufffd blah blah blah, and you can see here it actually",
  "14:43": "knows that US is special so it doesn't put the full-stop in as a separate place for U.S.;",
  "14:48": "it knows about 1.00 is special, so you can see there's a lot of tricky stuff going on",
  "14:54": "with spaCy to try and be as kind of thoughtful about this as possible. Fastai then provides",
  "15:03": "this tokenizer wrapper which provides some additional functionality to any tokenizer,",
  "15:10": "as you can see here which is, for example, the word \ufffdit\ufffd here which previously was",
  "15:21": "capital \ufffdIt\ufffd has been turned into a lowercase \ufffdit\ufffd and then a special token xxmaj has",
  "15:27": "appeared at the front. Everything starting with xx is a special fastai token, and this",
  "15:32": "means that the next match means that the next word was previously started with a capital",
  "15:38": "letter. So here's another one: \ufffdthis\ufffd used to be capital T, so we make it lowercase",
  "15:43": "and then add xxmaj; xxbos means this is the start of a document. So there's a few special",
  "15:51": "rules going on there. So why do we do that? Well if you think about it, if we didn't lowercase",
  "15:56": "\ufffdit\ufffd for instance or \ufffdthis\ufffd then the capitalized version and the lowercase version",
  "16:03": "are going to be two different words in the embedding matrix. Which probably doesn't make",
  "16:07": "sense, you know, regardless of the capitalization they probably basically mean the same thing.",
  "16:12": "Having said that, sometimes the capitalization might matter, so we kind of want to say all",
  "16:19": "right, use the same embedding every time you see the word \ufffdthis,\ufffd but add some kind",
  "16:23": "of marker that says that this was originally capitalized. Okay so that's why we do it like",
  "16:28": "this. So there's quite a few rules, you can see them in text_proc_rules, and you can see",
  "16:37": "the source code. Here's a summary of what they do but let's look at a few examples.",
  "16:41": "So if we use that tokenizer we created and pass in for example this text, you can see",
  "16:48": "the way it's tokenized, we get the xx beginning of stream, or beginning of string, beginning",
  "16:52": "of document. This HTML entity has become a real unicode. We've got the xxmaj we discussed.",
  "17:00": "Now here www has been replaced by xx rep 3 w. That means the letter w is repeated three",
  "17:08": "times. So for things where you've got like, you know, a hundred exclamation marks in a",
  "17:13": "row or the word \ufffdso\ufffd with like fifty o\ufffds, this is a much better representation. And",
  "17:22": "then you can see all uppercase has been replaced with xxup followed by the word. So there's",
  "17:29": "some of those rules in action. Oh you can also see multiple spaces have been replaced",
  "17:35": "with just making it standard tokens. So that's the word tokenizer. The really interesting",
  "17:42": "one is the subword tokenizer. So how, why would you need a subword tokenizer? Well,",
  "17:48": "consider for example this sentence here [reads Chinese]. So this is \ufffdMy name is Jeremy,\ufffd",
  "17:56": "but the interesting thing about it is there's no spaces here, right, and that's because",
  "18:04": "there are no spaces in Chinese and there isn't really a great sense of what a word is in",
  "18:09": "Chinese. I mean this particular sentence it's fairly clear what the words are but it's not",
  "18:12": "always obvious. Sometimes the words are actually split, you know, so some of it\ufffds at the",
  "18:18": "start of a sentence, and some of its at the end. So you can't really do word tokenization",
  "18:23": "to something like Chinese. So instead we use sub word tokenization, which is where we look",
  "18:29": "at a corpus of documents, and we find the most commonly occurring groups of letters,",
  "18:35": "and those commonly occurring groups of letters become the vocab. So, for example, we would",
  "18:41": "probably find \ufffdWo de\ufffd would appear often, because that means \ufffdmy\ufffd, \ufffdm\ufffdngz\ufffd,",
  "18:47": "whoopsie-daisy, and then \ufffdm\ufffdngz\ufffd, for example is \ufffdname\ufffd, and this is my westernized",
  "18:55": "version of a Chinese name, which wouldn't be very common to call, common to call at",
  "18:58": "all, so they would probably appear separately. So let's look at an example. Let's grab the",
  "19:05": "first 2000 movie reviews, and let's create the default SubwordTokenizer(), which currently",
  "19:16": "uses something called \ufffdSentencePiece\ufffd, that might change. And now we're going to",
  "19:20": "use something special, something very important which is called \ufffd.setup\ufffd. Transforms in",
  "19:27": "fastai, you can always call this special thing called \ufffd.setup()\ufffd, it often doesn't do",
  "19:31": "anything, but it's always there, but some transforms like a SubwordTokenizer() actually",
  "19:38": "need to be set up before you can use them. In other words you can't tokenize into sub",
  "19:43": "words until you know what the most commonly occurring groups of letters are. So passing",
  "19:49": "a list of texts, and here this list of texts, to \ufffd.setup()\ufffd will, will train the sub",
  "19:57": "word tokenizer. It'll find those commonly occurring groups of letters. So having done",
  "20:02": "that we can then, this is just for experimenting, we're going to pass in some size, we'll say",
  "20:08": "what vocab size we want for our SubwordTokenizer(), we'll set it up with our texts, and then we",
  "20:13": "will have a look at a particular sentence. So for example if we create a SubwordTokenizer()r",
  "20:21": "with a thousand tokens, and it returns this, this tokenized string. Now this kind of long",
  "20:31": "underscore thing is what we replace space with because now we're using sub word tokens",
  "20:36": "we kind of want to know where the sentences actually start and stop. Okay, and you can",
  "20:41": "see here a lot of sentence words are common enough sequences of letters that they get",
  "20:46": "their own vocab item, or else discovered, \ufffddid\ufffd was not, wasn't common enough. So",
  "20:52": "that became \ufffddis\ufffd, \ufffdc\ufffd, \ufffdover\ufffd, \ufffded\ufffd. Right? \ufffdVideo\ufffd appears enough,",
  "20:59": "whereas \ufffdstore\ufffd didn't. So that became \ufffdst\ufffd, \ufffdor\ufffd, \ufffde\ufffd, so you get the",
  "21:04": "idea. Right? So if we wanted a smaller vocab size, that would, as you see, even \ufffdthis\ufffd",
  "21:12": "doesn't become its own word, \ufffdmovie\ufffd is so common that it's a, is its own word, so",
  "21:17": "it \ufffdjust\ufffd becomes \ufffdj\ufffd, \ufffdus\ufffd, \ufffdt\ufffd, for example. We have a question. Okay. \ufffdHow",
  "21:25": "can we determine if the given pre-trained model, in this case wikitext 103, is suitable",
  "21:32": "enough for our downstream task. If we have limited vocab overlap should we need to add",
  "21:37": "an additional dataset to create a language model from scratch?\ufffd If it's in the same",
  "21:46": "language, so if you're doing English, it's always, it's almost always, sufficient to",
  "21:50": "use Wikipedia. We've played around this a lot and it was one of the key things that",
  "21:55": "Sebastian Ruder and I found when we created the ULMFiT paper. Was, before that time people",
  "22:01": "really thought you needed corpus specific pre-trained models, but we discovered you",
  "22:06": "don't, just like you don't that often need corpus specific pre-trained vision models.",
  "22:13": "ImageNet works surprisingly well across a lot of different domains. So Wikipedia has",
  "22:23": "a lot of words in it. It would be really really... I haven't come across an English corpus that",
  "22:29": "didn't have a very high level of overlap with Wikipedia. On the other hand if you're doing",
  "22:35": "ULMFiT with like genomic sequences or Greek or whatever then",
  "22:41": "obviously you're going to need a different pre-trained model so once we got to a 10,000",
  "22:47": "word vocab, as you can see, basically every word, at least common word, becomes its own",
  "22:54": "vocab item in the subword vocab, except say \ufffddiscovered\ufffd which becomes \ufffddiscover\ufffd,",
  "23:00": "\ufffded\ufffd. So my guess is that sub word approaches are going to become, kind of, the most common,",
  "23:08": "maybe they will be by the time you watch this. We've got some fiddling to do to get this",
  "23:15": "working super well for fine tuning, but I think I know what we have to do so hopefully",
  "23:22": "we'll get it done pretty soon. All right. So after we split it into tokens the next",
  "23:30": "thing to do is numericalization. So let's go back to our word tokenized text, which",
  "23:37": "looked like this, and in order to numericalize we will first need to call \ufffd.setup()\ufffd.",
  "23:48": "So to save a bit of time let's create a subset of our text. So just create a couple of hundred",
  "23:53": "of the corpuses, that's so a couple hundred of the reviews. So here's an example of one,",
  "23:59": "and we'll create our Numericalize() object and we will call \ufffdsetup\ufffd and that's the",
  "24:02": "thing that's going to create the vocab for us, and so after that we can now take a look",
  "24:07": "at the vocab. This is \ufffdcoll_repr()\ufffd is showing us a representation of a collection.",
  "24:12": "It's what the L class uses underneath, and you can see, when we do this, that the vocab",
  "24:20": "starts with the special tokens and then we start getting the English tokens in order",
  "24:29": "of frequency. So the default is a vocab size of 60,000. So that'll be the size of your",
  "24:38": "embedding matrix by default and if there are more than 60,000 unique words in your vocabulary,",
  "24:45": "in your corpus, then any, the least common ones will be replaced with a special xxunk",
  "24:52": "unknown token. So that'll help us avoid having a too big embedding matrix. All right, so",
  "25:01": "now we can treat the Numericalize() object, which we created as if it was a function,",
  "25:06": "as we so often do in both fastai and PyTorch, and when we do it will replace each of our",
  "25:13": "words with numbers. So two for example is 0, 1, 2 beginning of string beginning of,",
  "25:21": "beginning of stream. 8 0, 1, 2, 3, 4, 5, 6, 7, 8. Okay, so a capitalized letter there",
  "25:29": "they are, xxbos, xxmaj, etc. Okay, and then we can come and get them back by indexing",
  "25:37": "into the vocab and get back what we started with. Okay? Right, so now we have done the",
  "25:49": "tokenization, we've done the numericalization, and so the next thing we need to do is to",
  "25:53": "create batches. So let's say this is the text that we want to create batches from, and so",
  "26:03": "if we tokenize that text it'll convert it into this, and so let's, let's",
  "26:17": "take that and write it out here. Let's do it here. Let's take that and write it out",
  "26:27": "here, so \ufffdxxbos xxmaj in this chapter\ufffd, \ufffdxxbos xxmaj in this chapter, we will go",
  "26:35": "back over the example of classifying\ufffd, and then next row starts here \ufffdmovie reviews",
  "26:41": "we studied in chapter one and dig deeper under the surface full stop xxmaj\ufffd, \ufffdfirst we",
  "26:46": "will look at the[...]\ufffd etc. Okay? So we've taken these ninety tokens, and to create a",
  "26:53": "batch size of six we've broken up the text into six contiguous parts, each of length",
  "27:00": "15. One, two, three, four, five, six, and then we have 15 columns. Okay? So 6 by 15.",
  "27:13": "Now ideally we would just provide that to our model as a batch, and if indeed that was",
  "27:18": "all the data we had we could just pass it in as a batch, but that's not going to work",
  "27:26": "for IMDb, because IMDb once we concatenate all the reviews together and then, let's say,",
  "27:33": "we want to use a batch size of 64, then we're going to have 64 rows and, you know, probably",
  "27:43": "there's a few million tokens of IMDb, so a few million divided by 64 across, it's going",
  "27:49": "to be way too big to fit in our GPU. So what we're going to do then is we're going to split",
  "27:58": "up that big wide array, and we're going to split it up horizontally so we'll start with",
  "28:05": "\ufffdxxbos xxmaj in this chapter\ufffd, and then down here \ufffdwe will go back\ufffd, \ufffdover the",
  "28:12": "example of classifying\ufffd, \ufffdmovie reviews we studied in\ufffd, \ufffdchapter 1 and",
  "28:17": "dig deeper\ufffd, \ufffdunder the surface[...]\ufffd, etc. So this would become our first mini-batch.",
  "28:25": "Right, and so you can see what's happened is the, kind of, second row, right, actually",
  "28:34": "is fit, is is continuing what was like way down here, and so we basically treated each",
  "28:40": "row as totally independent. So when we predict the second, from the second mini-batch, you",
  "28:47": "know, the second mini-batch is going to follow from the first, and then each row to row one",
  "28:52": "in the second mini-batch will join up to row one of the first, row two of the second mini-batch",
  "28:58": "will join up to row two of the first. So please look at this example super carefully, because",
  "29:04": "we found that this is something that every year a lot of students get confused about,",
  "29:10": "because it's just not what they expected to see happen. Right? So go back over this and",
  "29:15": "make sure you understand what's happening in this little example. So that's what our",
  "29:21": "mini-batches are going to be. So the good news is that all these fiddly steps you don't",
  "29:27": "have to do yourself, you can just use the language model data loader or LMDataLoader.",
  "29:34": "So if we take those, all the tokens from the first 200 movie reviews, and map them through",
  "29:38": "our Numericalize object. Right? So now we've got numericalized versions of all those tokens,",
  "29:44": "and then pass them into LMDataLoader, and then grab the first item from the data loader,",
  "29:51": "and we have 64 by 72. Why is that? Well 64 is the default batch size, and 72 is the default",
  "30:03": "sequence length. You see here we've got 1, 2, 3, 4, 5, here we used a sequence length",
  "30:10": "of five. Right? So what we do in practice is we use a default sequence length of 72.",
  "30:19": "So if we grab the first of our independent variables and grab the first few tokens, and",
  "30:24": "look them up in the vocab... Here it is, \ufffdthis movie which I just something at the video",
  "30:29": "store\ufffd. So that's interesting so this was not common enough to be in a vocab, \ufffdhas",
  "30:34": "apparently sit around for a\ufffd, and then if we look at the exact same thing but for the",
  "30:39": "dependent variable rather than being \ufffdxxbos xxmaj match this movie\ufffd, its \ufffdxxmaj this",
  "30:46": "movie\ufffd, so you can see it's offset by 1, which means the end rather than being around",
  "30:51": "for \ufffda\ufffd, it's \ufffdfor a couple\ufffd. So this is exactly what we want. This is offset by",
  "30:57": "1 from here. So that's looking good. So we can now go ahead and use these ideas to try",
  "31:12": "and build our even better IMDb sentiment analysis, and the first step will be to as, we discussed,",
  "31:18": "create the language model but let's just go ahead and use the fastai built in stuff to",
  "31:24": "do it for us, rather than doing all that messing around manually, so we can just create a DataBlock,",
  "31:29": "and our blocks are, it's going to be a TextBlock, \ufffd.from_folder\ufffd, and the items are going",
  "31:41": "to be text files from these folders, and we're going to split things randomly and then going",
  "31:49": "to turn that into \ufffd.dataloaders\ufffd with a batch size of 128, and a sequence length",
  "31:54": "of 80. In this case our blocks... We're not just passing in a class directly, but we're",
  "32:05": "actually passing in here a class method, and that's so that we can allow the tokenization,",
  "32:15": "for example, to be saved, to be cached in some path, so that the next time we run this",
  "32:20": "it won't have to do it all from scratch. So that's why we have a slightly different syntax",
  "32:27": "here. So once we've run this we can call \ufffdshow_batch\ufffd, and so you can see here we've got for example",
  "32:39": "\ufffdwhat xxmaj I've read, xxmaj death[...]\ufffd bla bla bla, and you can see so that's the",
  "32:45": "independent variable and so the dependent variable is the same thing offset by one.",
  "32:49": "So we don't have to \ufffdwhat\ufffd anymore it just goes straight to \ufffdxxmaj I've read\ufffd",
  "32:54": "and then at the end this was \ufffdalso, this\ufffd, and of course in the dependent variable \ufffdalso,",
  "32:58": "this is\ufffd. So this is that offset by one, just like we were hoping for. \ufffdshow_batch\ufffd",
  "33:03": "is automatically denumericalizing it for us turning back into",
  "33:09": "strings but if we look at the actual (or you should look at the actual) x and y to confirm",
  "33:15": "that you actually see numbers there -- that'll be a good exercise for you, is to make sure",
  "33:19": "that you can actually grab a mini-batch from dls_lm. So now that we've got the data loaders",
  "33:28": "we can fine-tune our language model. So fine tuning the language model means we're going",
  "33:33": "to create a learner which is going to learn to predict the next word of a movie review.",
  "33:40": "So that's our data, the data loaders for the language model. This is the pre-trained model,",
  "33:45": "it's something called AWD_LSTM which we\ufffdll see how to create from scratch in a moment,",
  "33:50": "or something similar to it. Dropout we'll learn about later, there we see how much dropout",
  "33:56": "to use, this is how much regularization we want, and what metrics do we want. We know",
  "34:01": "about accuracy; perplexity is not particularly interesting so I won't discuss it but feel",
  "34:06": "free to look it up if you're interested. And let's train with fp16 to use less memory on",
  "34:12": "the GPU, and for any modern GPU it'll also run two or three times faster. So this gray",
  "34:21": "bit here has been done for us, the pre-training of the language model for Wikitext103, and",
  "34:26": "now we're up to this bit which is fine-tuning the language model for IMDB. So let's do one",
  "34:34": "epoch, and as per usual the using a pre-trained model automatically calls freeze so we don't",
  "34:42": "have to freeze. So this is going to just actually train only the new embeddings initially and",
  "34:51": "we get an accuracy after a ten minutes or so of 30 percent. So that's pretty cool. So",
  "34:56": "about a bit under a third of the time, our model is predicting the next word of a string.",
  "35:04": "So I think that's pretty cool. Now, since this takes quite a while for each epoch, we",
  "35:12": "may as well save it and you can save it under any name you want. And that's going to put",
  "35:19": "it into your path, into your learner's path, into a model subfolder, and it will give it",
  "35:24": "a dot PTH extension for PyTorch. And then later on you can load that with learn.load()",
  "35:30": "after you create the learner. And so then we can unfreeze, and we can train a few more",
  "35:37": "epochs, and we eventually get up to an accuracy of thirty-four percent. So that's pretty great.",
  "35:48": "So once we've done all that we can save the model but actually all we really need to do",
  "35:52": "is to save the encoder. What's the encoder? The encoder is all of the model except for",
  "35:59": "the final layer. Oh and we're getting a thunderstorm here! That could be interesting. We've never",
  "36:04": "done a lesson with a thunderstorm before, but that's the joy of teaching during COVID-19",
  "36:11": "-- you get all the sound effects. So yeah, the final layer of our language model is the",
  "36:21": "bit that actually picks a particular word out, which we don't need. So when we say save",
  "36:27": "encoder, it saves everything except for that final layer. And that's the pre-trained model",
  "36:32": "we're going to use; that is a pre-trained model of a language model that is fine-tuned",
  "36:38": "from Wikipedia, fine-tuned using IMDB, and doesn't contain the very last layer. Rachel,",
  "36:45": "any questions at this point? \ufffdDo any language models attempt to provide meaning? For instance,",
  "36:53": "\ufffdI'm going to the store\ufffd is the opposite of \ufffdI'm not going to the store.\ufffd Or \ufffdI",
  "36:58": "barely understand this stuff\ufffd and \ufffdThat ball came so close to my ear I heard it whistle\ufffd",
  "37:03": "both contain the idea of something almost happening, being right on the border. Is there",
  "37:08": "a way to indicate this kind of subtlety in a language model?\ufffd Yeah, absolutely our",
  "37:16": "language model will have all of that in it, or hopefully it will have it, or learn about",
  "37:21": "it. We don't have to program that. The whole point of machine learning is it learns it",
  "37:24": "for itself, but when it sees a sentence like \ufffdHey careful that ball nearly hit me,\ufffd",
  "37:33": "the expectation of what word is going to happen next is going to be different to the sentence,",
  "37:40": "\ufffdHey that ball hit me!\ufffd So, so yeah, language models generally you see in",
  "37:46": "practice tend to get really good at understanding all of these nuances of, of English or whatever",
  "37:53": "language it's learning about. Okay so we have a fine-tuned language model so the next thing",
  "38:00": "we're going to do is we're going to try to fine-tuning a classifier, but before we do,",
  "38:04": "just for fun, let's look at text generation. We can create, write ourselves some words",
  "38:10": "like \ufffdI liked this movie because,\ufffd and then we can create, say, two sentences each",
  "38:18": "containing, say, 40 words. And so we can just go through those two sentences and call learn.predict,",
  "38:24": "passing in this text and asking it to predict this number of words, with this amount of",
  "38:31": "kind of randomization, and see what it comes up with. \ufffdI liked this movie because of",
  "38:38": "its story and characters. The story line is very strong, very good for a sci-fi. The main",
  "38:42": "character, Alucard, was very well developed and brought the whole story\ufffd\ufffd But second",
  "38:47": "attempt: \ufffdI liked this movie because I like the idea of the premise of the movie the very",
  "38:52": "convenient virus which well when you have to kill a few people the evil machine has",
  "38:56": "to be used to protect\ufffd blah blah blah. So as you can see it's done a good job of inventing",
  "39:02": "language. There are much -- well I shouldn't say more sophisticated -- there are, there",
  "39:09": "are more careful ways to do a generation from a language model. This learn.predict() uses",
  "39:14": "the most kind of basic possible one, but even with a very simple approach, you can see we",
  "39:19": "can get from a fine-tuned model some pretty authentic-looking text. And so in practice",
  "39:28": "this is really interesting, because we can now, you know, by using the the prompt you",
  "39:33": "can kind of get it to generate a, you know, appropriate context-appropriate text, particularly",
  "39:42": "if you fine-tune for it from a particular corpus. Anyway that was really just a little",
  "39:47": "demonstration of something we accidentally created on the way, because of course the",
  "39:51": "whole purpose of this is actually just to be a pre-trained model for classification.",
  "39:56": "So to do that we're going to need to create another DataBlock, and this time we've got",
  "40:01": "two blocks, not one. We've got a text block again just like before, but this time we're",
  "40:05": "going to ask fastai not to create a vocab from the unique words, but using the vocab",
  "40:12": "that we already have from the language model. Because otherwise, obviously there's no point",
  "40:17": "reusing a pre-trained model if the vocab is different: the numbers would mean totally",
  "40:21": "different things. So that's the independent variable, and the dependent variable, just",
  "40:27": "like we've used before, is a category. So CategoryBlock is for that. As we've used many",
  "40:31": "times, we're going to use parent label to create our dependent variable, that's a function.",
  "40:37": "get_items we use get_text_files just like before, and we'll split using GrandparentsSplitter",
  "40:43": "as we've used before for vision. So this has been used for vision, this has been used for",
  "40:49": "vision and then we'll create our data loaders with a batch size of 128, a sequence length",
  "40:53": "of 72. And now show_batch here we can see an example of subset of a movie review and",
  "41:02": "the category. Yes, question? Do the tokenizers use any tokenization techniques like stemming",
  "41:13": "or lemmatization, or is that an outdated approach? That would not be a tokenization approach.",
  "41:21": "So stemming is something that actually removes the stem and we absolutely don't want to do",
  "41:27": "that. That is certainly an outdated approach. In English, we have stems for a reason: they",
  "41:36": "tell us something, so we don't like to remove anything that can give us some kind of information.",
  "41:43": "We used to use that for a kind of pre-deep learning NLP quite a bit, because that we",
  "41:49": "didn't really have good ways like embedding matrices of handling, you know, big vocabs",
  "41:54": "that just differed in the little, kind of the end of a word, but nowadays we definitely",
  "42:01": "don't want to do that. Oh yeah one other difference here is previously",
  "42:10": "we had an is_lm equals true when we said TextBlock.from_folder to save as a language model. We don't have",
  "42:16": "that anymore because it's not a language model. Okay. Now, one thing with a language model",
  "42:25": "that was a bit easier was that we could concatenate all the documents together and then we could",
  "42:32": "split them by batch size to create -- well not split them by batch size -- fit them into",
  "42:37": "a number of substrings based on the batch size. And that way we could ensure that every",
  "42:43": "mini-batch was the same size. It would be batch size by a sequence length. But for classification",
  "42:52": "we can't do that. We actually need each dependent variable label to be associated with each",
  "43:00": "complete movie review. And we're not showing the whole movie review here, we've truncated",
  "43:05": "it just for display purposes, but we're going to use the whole movie review to make our",
  "43:09": "prediction. Now the problem is that if we're using a batch size of 128 then, and our movie",
  "43:18": "reviews are often like 3,000 words long we could end up with something that's way too",
  "43:23": "big to fit into the GPU memory. So how are we going to deal with that? Well again, we're",
  "43:31": "going, we can split them up, so first of all let's grab a few of the movie reviews just",
  "43:39": "to demo here and numericalize them, and if we have a look at the length, so map the length",
  "43:44": "over each, you can see that they do vary a lot in length. Now we can we can split them",
  "43:52": "into sequences and indeed we have asked to do that -- sequence length 72 -- but when",
  "43:58": "we do so we're, you know, we don't even have the same number of sub-sequences. When we",
  "44:03": "split each of these into 72 long sections, they're going to be all different lengths.",
  "44:11": "So how do we deal with that? Well just like in vision we can handle different sized sequences",
  "44:18": "by adding padding. So we're going to add a special xx_pad token to every sequence in",
  "44:29": "a mini-batch. So like in this case it looks like 581 is the longest. So we would add enough",
  "44:33": "padding tokens to make this 581 and this 581 and this 581 and so forth, and then we can",
  "44:40": "split them into sequence_len and to 72 long, and it's where I'm in the mini-batches, and",
  "44:46": "we'll be right to go. Now obviously, if your lengths are very different like this, adding",
  "44:52": "a whole lot of padding is going to be super wasteful, so another thing that fastai does",
  "44:56": "internally is, it tries to shuffle the documents around so that similar length documents are",
  "45:03": "in the same mini-batch. It also randomizes them but it kind of approximately sorts them",
  "45:09": "so it wastes a lot less time on padding. Okay so that is how, that is what happens when,",
  "45:19": "we don't have to do any of that manually. When we call TextBlock.from_folder without",
  "45:22": "the is_lm, it does all that for us. And then we can now go ahead and create a learner.",
  "45:34": "This time it's going to be a text_classifier_learner; again we're going to base it off AWD_LSTM,",
  "45:41": "pass in the data loaders we just created; for metric we\ufffdll just use accuracy, make",
  "45:46": "it fp16 again. And now we don't want to use a pre-trained Wikipedia model, in fact there",
  "45:52": "is no pre-trained Wikipedia classifier because, you know, what you classify matters a lot.",
  "45:57": "So instead we load the encoder (so remember, everything except the last layer) which we",
  "46:04": "saved just before. So we're going to load as our pre-trained model our language model",
  "46:11": "for predicting the next word of a movie review. So let's go ahead and fit one cycle, and again",
  "46:21": "by default it will it be frozen so it's only the final layer which is the randomly added",
  "46:27": "classifier layer that's going to be trained. It took 30 seconds and look at this -- we",
  "46:32": "already have 93 percent! So that's pretty similar to what we got back in lesson one",
  "46:41": "but rather than taking about 12 minutes once all the pre-training has been done it",
  "46:44": "takes about 30 seconds. This is quite cool: you can create a language model for your kind",
  "46:51": "of general area of interest and then you can create all kinds of different classifiers",
  "46:56": "pretty quickly. And so that's just with, that's just looking at fine-tuning the final randomly",
  "47:05": "added layer. So now we could just unfreeze and keep learning, but something we found",
  "47:13": "is for NLP it's actually better to only unfreeze one layer at a time, not to unfreeze the whole",
  "47:21": "model. So we've, in this case we've automatically unfrozen the last layer and so then to unfreeze",
  "47:27": "the last couple of layer groups, we can say freeze_to(-2) and then train a little bit",
  "47:33": "more, and look at this! We're already beating, after a bit over a minute, easily beating",
  "47:40": "what we got in Lesson 1. And then freeze_to(-3) to unfreeze another few layers. Now we're",
  "47:47": "up to 94. And then finally unfreeze the whole model and we're up to about ninety four point",
  "47:53": "three percent accuracy, and that was literally the state of the art for this very heavily",
  "47:59": "studied dataset just three years ago. If you also reverse all of the reviews to make them",
  "48:06": "go backwards and train a second model on the backwards version, and then average the predictions",
  "48:12": "of those two models as an ensemble. you get to ninety-five point one percent accuracy.",
  "48:17": "And that was the state of the art that we actually got in the ULMFIT paper, and it was",
  "48:22": "only beaten for the first time a few months ago, using a way, way bigger model, way more",
  "48:27": "data, way more compute, and way more data augmentation. I should mention actually with",
  "48:34": "the data augmentation, one of the cool things they did do was they actually figured out",
  "48:38": "also a way to even beat our 95.1 with less data as well. So I should mention that actually",
  "48:43": "the data augmentation has become a really, since we created the ULMFIT paper, has become",
  "48:48": "a really, really important approach. Any questions, Rachel? \ufffdCan someone explain how a model",
  "48:57": "trained to predict the last word in a sentence can generalize to classify sentiment? They",
  "49:02": "seem like different domains.\ufffd Yeah, that's a great question. They're very different domains",
  "49:08": "and it's it's really amazing and basically the trick is that to be able to predict the",
  "49:14": "next word of a sentence, you just have to know a lot of stuff about not only the language,",
  "49:20": "but about the world. So if you know... let's say we wanted to finish the next word of this",
  "49:27": "sentence: \ufffdBy training a model on all the text read backwards and averaging the predictions",
  "49:32": "of these two models, we can even get to 95.1% accuracy, which was the state of the art introduced",
  "49:37": "by the --\ufffd what? So to be able to fill in the word \ufffdULMFIT\ufffd you would have to know",
  "49:43": "a whole lot of stuff about, you know, the fact that there's a thing called fine-tune,",
  "49:48": "you know, pre-trained language models and which one gets which results and that ULMFIT",
  "49:54": "got this particular result. I mean that would be an amazing language model that could fill",
  "49:58": "that in correctly. I'm not sure that any language models can but to give you a sense of like,",
  "50:05": "what you have to be able to do to be good at language modeling. So if you're going to",
  "50:09": "be able to predict the next word of a sentence, like, \ufffdWow I really love this movie, I love",
  "50:17": "every movie containing Meg\ufffd... what? Right, maybe it's Ryan. You would have to know about",
  "50:24": "like the fact that Meg Ryan is an actress, and actresses are in movies, and so forth,",
  "50:28": "so when you know so much about English and about the world, to then turn that into something",
  "50:35": "which recognizes that \ufffdI really love this movie\ufffd is a good thing rather than a bad",
  "50:42": "thing is just not a very big step. And as we saw, you can actually get that far using",
  "50:49": "just fine-tuning just the very last layer or two. So it is, it's amazing, and I think",
  "50:58": "that's super super cool. All right another question. \ufffdHow would you do data",
  "51:04": "augmentation on text?\ufffd [Laughs] Well\ufffd You would probably google for unsupervised",
  "51:14": "data augmentation, and read this paper, and things that have cited it. So this was the",
  "51:19": "one that easily beat our IMDb result with only 20 labeled examples, which is amazing,",
  "51:29": "right, and so they did things like, if I remember correctly, translate every sentence into a",
  "51:37": "different language and then translate it back again. So you kind of get like, different",
  "51:41": "rewordings of the sentence that way. Yeah. So kind of tricks like that. Now let's go",
  "51:56": "back to the generation thing. So remember we saw that we can generate context appropriate",
  "52:06": "sentences, and it's important to think about what that means in practice. When you can",
  "52:11": "generate context appropriate sentences... Have a look, for example, at even before this",
  "52:16": "technology existed in 2017. The FCC asked for comments about a proposal to repeal net",
  "52:25": "neutrality, and it turned out that less than 800,000 of the 22 million comments actually",
  "52:37": "appeared to be unique, and this particular person Jeff Kao discovered that a lot of the",
  "52:44": "submissions were slightly different to each other by, kind of, like picking up different,",
  "52:52": "you know, the green bit would either be \ufffdcitizens\ufffd, \ufffdor people like me\ufffd, or \ufffdAmericans\ufffd",
  "52:58": "and the red bit would be \ufffdas opposed to\ufffd or \ufffdrather than\ufffd, and so forth. So like...",
  "53:04": "And, and that made a big difference to, I believe to, American policy. You know, here's",
  "53:11": "an example of a Reddit conversation, \ufffdYou're wrong the defense budget is a good example",
  "53:16": "of how badly the U.S. spends money on the military.\ufffd dot dot dot. Somebody else, \ufffdYeah,",
  "53:20": "but that's already happening. There's a huge increase in the military budget[...]\ufffd dot",
  "53:24": "dot dot. \ufffdI didn't mean to sound like \ufffdstop paying for the military.\ufffd I'm not saying",
  "53:27": "that we cannot pay the bills[...]\ufffd dot dot dot. Now, all of these are actually created",
  "53:31": "by a language model or GPT-2, and this is a very concerning thing around disinformation.",
  "53:39": "Is that never mind fake news, never mind deep fakes. Think about like what would happen",
  "53:43": "if somebody invested a few million dollars in creating a million Twitter bots, and Facebook",
  "53:52": "Groups bots, and Weibo bots, and made it so that 99% of the content on social networks",
  "53:59": "were deep learning bots, and furthermore they were trained not just to optimize the next",
  "54:07": "word of a sentence, but were trained to optimize the level of disharmony created, or the level",
  "54:15": "of agreeableness, from some of the half of them, and disagreeableness for the other half",
  "54:20": "of them. You know you could create like a whole lot of, you know, just awful toxic discussion,",
  "54:28": "which is actually the goal of a lot of propaganda outfits. Is not so much to push a particular",
  "54:34": "point of view, but to make people feel like \ufffdthere's no point engaging because the truth",
  "54:41": "is too hard to understand\ufffd or, or whatever. So I'm... Rachel and I are both super worried",
  "54:47": "about what could happen to discourse, now that we have this incredibly powerful tool,",
  "54:56": "and I'm not even sure we have... We don't have a great sense of what to do about it.",
  "55:00": "Algorithms are unlikely to, are unlikely to save us here. If you could create a classifier",
  "55:06": "which could do a good job of figuring out whether something was generated by a algorithm",
  "55:10": "or not, then I could just use your classifier as part of my training loop to train an algorithm",
  "55:17": "that can actually learn to trick your classifier. So this is a real worry, and the only solutions",
  "55:25": "I've seen are those which are, kind of, based on cryptographic signatures, which is another",
  "55:32": "whole can of worms, which has never really been properly sorted out, at least not in",
  "55:37": "the Western world, and a privacy centric way. All right. So\ufffd Oh... Yes, before we have",
  "55:42": "a break. Just on that note I'll add and I'll link to this on the forums, I gave a keynote",
  "55:48": "at SciPy Conference last summer, which is the Scientific Python conference, and went",
  "55:53": "into a lot more detail about the, the threat that Jeremy is describing about,",
  "55:58": "using advanced language models to manipulate public opinion, and so if you want to, kind",
  "56:04": "of, learn more about the dangers there and exactly what that threat is, you can find",
  "56:08": "that in, in my SciPy keynote. Great. Thanks so much Rachel. So let's have a five-minute",
  "56:15": "break, and see you back here in five minutes. So we're going to finish with a kind of a",
  "56:30": "segue into what will eventually be part two of the course, which is to go right underneath",
  "56:36": "the hood, and see exactly how more complex architecture works, and specifically we're",
  "56:44": "going to see how a neu recurrent neural network works. Do we have a question first? \ufffdIn",
  "56:55": "the previous lesson MNIST example, you showed us that under the hood the model was learning",
  "57:00": "parts of the image like curves of a 3 or angles of a 7. Is there a way to look under the hood",
  "57:05": "of the language models to see if they are learning rules of grammar and syntax? Would",
  "57:10": "it be a good idea to fine-tune models with examples of domain-specific syntax like technical",
  "57:17": "manuals, or does that miss the point of having the model learn for themselves?\ufffd Yeah there",
  "57:22": "are tools that allow you to, kind of, see what's going on inside an NLP model. We're",
  "57:28": "not going to look at them in this part of the course. Maybe we will in part two, but",
  "57:33": "certainly worth doing some research to see what you can find and they\ufffdre certainly",
  "57:37": "PyTorch libraries you can download and play with. Yeah, I mean, I think it's a perfectly",
  "57:45": "good idea to incorporate some kind of technical manuals and stuff into your training corpus.",
  "57:53": "There's actually been some recent papers on this general idea of, trying to, kind of,",
  "57:59": "create some carefully curated sentences as part of your training corpus. It's unlikely",
  "58:06": "to hurt and it could well help. All right so let's have a look at RNNs. Now, when Sylvain",
  "58:17": "and I started creating the RNN stuff for fastai, the first thing I did actually was to create",
  "58:26": "a new dataset, and the reason for that is I didn't find any datasets that would allow",
  "58:32": "for quick prototyping, and really easy debugging. So I made one which we call \ufffdhuman numbers\ufffd,",
  "58:41": "and it contains the first 10,000 numbers, written out in English. And I am surprised",
  "58:52": "at how few people create datasets. I create datasets frequently. You know, I specifically",
  "59:00": "look for things that can be, kind of, small, easy to prototype, good for debugging, and",
  "59:05": "quickly trying things out, and very, very few people do this, even though like this",
  "59:10": "\ufffdhuman numbers\ufffd dataset, which has been so useful for us, took me, I don't know, an",
  "59:14": "hour or two to create. So this is definitely an underappreciated, underutilized technique.",
  "59:26": "So we can grab the \ufffdhuman numbers\ufffd dataset, and we can see that there's a training and",
  "59:30": "a validation text file. We can open each of them, and for now we're just going to concatenate",
  "59:36": "the two together into a file called \ufffdlines\ufffd, and you can see that the contents are 1, 2,",
  "59:44": "3, etc., and so there's a new line at the end of each. We can concatenate those all",
  "59:51": "together and put a full-stop between them. As so... Okay? And then you could tokenize",
  "59:58": "that by splitting on spaces, and so for example here's tokens 100 to 110. New number 42, new",
  "60:06": "number 43, new number, 44, and so forth. So you can see I'm just using plain Python here,",
  "60:11": "there's not even any PyTorch, certainly not any fastai. To create a vocab we can just",
  "60:18": "create all the unique tokens, of which there are 30, and then to create a lookup from...",
  "60:27": "So that's a lookup from a word to an ID. Sorry from an ID to a word. To go from a word to",
  "60:32": "an ID, we can just enumerate that, and create a dictionary from word to ID. So then we can",
  "60:43": "numericalize our tokens by calling word to index on each one, and so here's our tokens,",
  "60:53": "and here is the equivalent numericalized version. So you can",
  "60:56": "see on fairly small datasets, when we don't have to worry about scale, and speed, and",
  "61:03": "have the details of tokenization in English, you can do the whole thing in just plain Python.",
  "61:12": "The only other thing we used, did for to save a little bit of time was use L(), but you",
  "61:16": "could easily do that with the Python Standard Library in about the same amount of code.",
  "61:24": "so hopefully that gives you a good sense of really what's going on with tokenization and",
  "61:29": "numericalization, all done by hand. So let's create a language model. So one way to create",
  "61:34": "a language model would be to go through all of our tokens, and let's create a range from",
  "61:41": "0 to the length of our tokens minus 4, and every 3 of them, and so that's going to allow",
  "61:46": "us to grab three tokens at a time 1 dot 2 dot 3 dot 4 dot five dot 6 dot 7 dot 8, and",
  "61:58": "so forth. Right? So here's the first three tokens, and then here's the 4th token, and",
  "62:04": "here's the second three tokens, and here's the seventh token, and so forth. So these",
  "62:10": "are going to be our independent variables and this will be our dependent variable. So",
  "62:16": "here's a super, super, kind of, naive simple language model dataset for the \ufffdhuman numbers\ufffd",
  "62:26": "question. So we can do exactly the same thing as before, but use the numericalized version",
  "62:32": "and create tensors. So this is exactly the same thing as before, but now is as through",
  "62:37": "numericalized tensors, and we can create a DataLoaders() object \ufffd.from_datasets\ufffd,",
  "62:46": "and remember these are datasets because they have a length, and we can index into them.",
  "62:51": "Right? And so we can just grab the first 80% of the tokens as the training set, the last",
  "62:56": "20% is the validation set, like so. Batch size 64, and we're ready to go. So we really",
  "63:05": "used very, very little, I mean, the only Pytorch we used was to create these tensors, and the",
  "63:12": "only fastai we used was to create the DataLoaders(), and it's just grabbing directly from the datasets,",
  "63:18": "so it's really not doing anything clever at all. So let's see if we can now create a neural",
  "63:25": "network architecture, which takes three numericalized words at a time as input, and tries to predict",
  "63:32": "the fourth, as dependent variable. So here is just such language model. It's a three",
  "63:44": "layer neural network. So we've got a linear layer here, which we're going to use once,",
  "63:53": "twice, three times, and after each of them, we call relu(), as per usual, but there's",
  "64:03": "a little bit more going on. The first interesting thing is that rather than each of these being",
  "64:10": "a different linear layer, we've just created one linear layer here, which we've reused,",
  "64:20": "as you can see, one, two, three times. So that's the first thing that's a bit tricky,",
  "64:29": "and so there's a few things going on. It's a bit, a little bit different to usual, but",
  "64:32": "the basic idea is here. We've created an Embedding, an nn.Linear, another nn.Linear, and in here",
  "64:38": "we've used the linear layers, and relu(), so it's very nearly a totally standard three",
  "64:45": "layer neural net. We have a.... I guess four really, because this is an output layer. Yes",
  "64:49": "Rachel? We have a question. Sure. \ufffdIs there a way to speed up fine-tuning the NLP model?",
  "64:55": "10 plus minutes per epochs slows down the iterative process quite a bit. Any best practices",
  "65:01": "or tips?\ufffd I can't think of any obviously other than to say you don't normally need",
  "65:09": "to fine-tune it that often. You know, the work is often more at the classifier stage.",
  "65:17": "So yeah I tend to, kind of, just leave it running overnight, or while I have lunch,",
  "65:22": "or something like that. Yeah, just don't make sure you, make sure you don't sit there watching",
  "65:26": "it. Go and do something else. This is where it can be quite handy to have a second GPU,",
  "65:33": "or fire up a second AWS instance, or whatever, so you can, kind of, keep, keep moving while",
  "65:40": "something's training in the background. All right, so what's going on here in this model?",
  "65:49": "To describe it we're actually going to develop a little, kind of, pictorial representation,",
  "65:55": "and the pictorial representation is going to work",
  "65:57": "like this: Let's start with a simple linear model to define this pictorial representation.",
  "66:04": "A simple linear model has an input of size batch size by number of inputs and so we're",
  "66:11": "going to use a rectangle to represent an input. We're going to use an arrow to represent a",
  "66:20": "layer of computation. So in this case, there's going to be a matrix product for a simple",
  "66:27": "linear model there'd be a matrix, actually sorry, this is a single hidden layer model.",
  "66:32": "There'll be a matrix product followed by a ReLU. So that's what this arrow represents,",
  "66:37": "and out of that we're going to get some activations. And so, circles represent computed activations,",
  "66:43": "and it would be, we call this a hidden layer, it would be of size batch size by number of",
  "66:48": "activations. That's its size. And then, to create a neural net we're going to do a second",
  "66:53": "matrix product and this time of softmax so the computation again, represented by the",
  "66:57": "arrow, and then output activations are a triangle. So the output would be batch size by num classes.",
  "67:05": "So let me show you the pictorial version of this. So this is going to be our legend, triangle",
  "67:14": "is output, circle, hidden, rectangle, input. And here it is, we're going to take the first",
  "67:23": "word as an input, it's going to go through a linear layer and ReLU, and you'll notice",
  "67:30": "here, I've deleted the details of what the operations are at this point and I've also",
  "67:35": "deleted the sizes. So every arrow is basically just a linear layer followed by a non-linearity,",
  "67:44": "so we take the word one input, and we put it through the layer, the linear layer and",
  "67:53": "the non-linearity, to give us some activations. So there's our first set of activations. And",
  "68:00": "when we put that through another linear layer, and non-linearity to get some more activations,",
  "68:07": "and at this point we get word two. And word two, is now, goes through linear layer and",
  "68:17": "a non-linearity, and these two, when two arrows together come to a circle, it means that we",
  "68:23": "add or concatenate (either is fine), the two sets of activations. So we'll add the set",
  "68:31": "of activations from this input, to the set of activations from here to create a new set",
  "68:35": "of activations, and then we'll put that through another linear layer and a ReLU. And again",
  "68:42": "word three is now going to come in and go through a linear layer and a ReLU, and they'll",
  "68:45": "get added to create another set of activations and then they'll find, go through a final",
  "68:50": "linear layer and ReLU, and I guess, softmax to create our output activations. So this",
  "68:59": "is our model, it's basically a standard one, two, three, four, layer model but a couple",
  "69:09": "of interesting things are going on the first is that we have inputs coming in to later",
  "69:14": "layers and get added, so that's something we haven't seen before, and the second is,",
  "69:18": "all of the arrows that are the same color, use the same weight matrix. So every time",
  "69:24": "we get an input, we're going to put it through a particular weight matrix, and every time",
  "69:29": "we go from one set of activations to the next or put it through a different weight matrix,",
  "69:33": "and then to go through the activations to the output we'll use the different weight",
  "69:37": "matrix. So if we now go back to the code, to go from input to hidden, not surprisingly,",
  "69:46": "we always use an embedding. So in other words an embedding is, the green okay, and you'll",
  "69:53": "see we just create one embedding, and here is the first, so here's X which is the three",
  "69:58": "words. So here's the first word X zero, and it goes through that embedding. And word two,",
  "70:04": "goes through the same embedding, and word three index number two, goes through the same",
  "70:08": "embedding. And then each time you see, we add it to the current set of activations.",
  "70:15": "And so having put the, got the embedding, we then put it through this linear layer.",
  "70:21": "And again, we get the embedding, add it to the hid, to the activations, and put it through",
  "70:26": "the linear, that with linear layer. And again, the same thing here, put it through the same",
  "70:30": "linear layer, so h_h is the orange. So these set of activations we call the hidden state,",
  "70:41": "okay. And so the hidden state is why it's called \ufffdh\ufffd and so if you follow through",
  "70:48": "these steps, you'll see how each of them corresponds to a step in this diagram. And then finally",
  "70:54": "at the end, we go from the hidden state to the output (which is this linear layer) hidden",
  "70:59": "state to the output, okay. and then we don't have the actual Softmax there, because as",
  "71:09": "you'll remember, we can incorporate that directly into the loss function, the cross-entropy",
  "71:13": "loss function using PyTorch. So one nice thing about this is, everything",
  "71:21": "we're using we have previously created from scratch. So there's nothing magic here. We've",
  "71:26": "created our own embedding layer from scratch, we've created our own linear layer from scratch,",
  "71:30": "we've created our own ReLU from scratch, we've created our own cross entropy loss from scratch.",
  "71:36": "So you can actually try building this whole thing yourself, from scratch. So why do we,",
  "71:45": "just in terms of the nomenclature, \ufffdi_h\ufffd, so \ufffdh\ufffd refers to hidden so this is a layer",
  "71:52": "that goes from input to hidden. This is one that goes from hidden to hidden, this is one",
  "71:56": "that goes from hidden to output. So if any of this is feeling confusing at any point,",
  "72:03": "go back to where we actually created each one of these things from scratch and create",
  "72:06": "it from scratch again. Make sure you actually write the code, so that nothing here is mysterious.",
  "72:16": "So why do we use the same embedding matrix each time we have a new input word, for an",
  "72:24": "input word index 0, 1, and 2? Well because conceptually, they all represent English words",
  "72:32": "of content, you know for human numbers. So why would you expect them to be a different",
  "72:37": "embedding? They all should have the same representation, because they alll have the same meaning. Same",
  "72:42": "for this hidden to hidden - at each time we're basically describing how to, how to go from",
  "72:46": "one token to the next of our language model, so we would expect it to be the same computation.",
  "72:53": "So that's basically what's going on here. So having created that model, we can go ahead",
  "73:01": "and instantiate it. So we\ufffdre going to have to pass in the vocab size for the embedding",
  "73:06": "and the number of hidden, right, so that's the number of activations. So here we create",
  "73:14": "the model, and then we could create a learner by passing in a model and our data loaders",
  "73:20": "and a loss function and optionally metrics. And we can fit. Now of course this is not",
  "73:29": "pre-trained, right. This is not an application-specific learner, so it wouldn't know what pre-trained",
  "73:34": "model to use. So this is all random. And we're getting somewhere around the 45% to 50% or",
  "73:43": "so accuracy. Is that any good? Well you should always compare to random or, not random - you",
  "73:49": "should always compare to like the simplest model, where the simplest model is like some",
  "73:53": "average or something. So what I did is, I grabbed the validation set (so all the tokens),",
  "73:59": "put it into a Python standard library counter (which simply counts how many times each thing",
  "74:04": "appears). I found that the word \ufffdthousand\ufffd is the most common. And then I said, okay,",
  "74:11": "what if we used 7104 with \ufffdthousand\ufffd (that's here) and divide that by the length of the",
  "74:19": "tokens, and we get 15%. Which in other words means if we always just predicted, I think",
  "74:24": "the next word will be \ufffdthousand\ufffd, we would get 15% accuracy. But in this model we got",
  "74:31": "around 45% to 50% accuracy. So in other words, our model is a lot better than the simplest",
  "74:38": "possible baseline, so we've learnt something useful, that's great. So the first thing we're",
  "74:44": "going to do is we're going to refactor this code. Because you can see, we've got x going",
  "74:52": "into i_h, going into h_h, going into relu. x going into i_h, going into h_h, going into",
  "74:58": "relu, going into i_h, going into h_h, going into relu. How would you refactor that in",
  "75:03": "Python? You would, of course, use a for loop so let's go ahead and write that",
  "75:08": "again. So these lines are code or identical. In fact, these lines of code are identical",
  "75:13": "(as is this), and we're going to instead of doing all that stuff manually we\ufffdve got",
  "75:18": "a loop that goes through three times and in each time it goes - i_h add to our h_h value",
  "75:28": "and then at the end, hidden to output. So this is exactly the same thing as before,",
  "75:33": "but it's just reflected with a for loop. And we can train it again, and again we get the",
  "75:39": "same basically 45% to 50% as you would expect, because it's exactly the same, it's just been",
  "75:45": "refactored. So here's something crazy - this is a recurrent neural network. Even though",
  "75:58": "it's like exactly the same as ... it's exactly the same as this, right? It's just been refactored",
  "76:10": "into a loop. And so believe it or not, that's actually all an RNN is. An RNN is a simple",
  "76:18": "refactoring of that model with that deep learning linear model we saw. I shouldn't say linear",
  "76:28": "model, a deep learning model of simple linear layers with ReLUs. So let's draw our pictorial",
  "76:37": "representation again (so remember this was our previous pictorial representation). We",
  "76:42": "can refactor the picture as well, so instead of showing these dots separately, we can just",
  "76:48": "take this arrow and represent it it, represent it as a loop. Because that's all that's happening,",
  "76:54": "right. So the word 1 goes through an embedding, goes into this activations, which then just",
  "77:00": "gets repeated from 2 to, 2 to n-1, where n at this time is, you know, we've got three",
  "77:07": "words basically, for each word coming in as well. And so we've just refactored our diagram.",
  "77:14": "And then eventually it goes through our blue to create the output. So this diagram is exactly",
  "77:21": "the same as this diagram, just replacing the middle with that loop. So that's a recurrent",
  "77:28": "neural net and so \ufffdh\ufffd, remember was something that we just kept track of here \ufffdh\ufffd, \ufffdh\ufffd,",
  "77:35": "\ufffdh\ufffd, \ufffdh\ufffd, \ufffdh\ufffd, \ufffdh\ufffd, as we added each layer to it. And here we just have",
  "77:42": "it inside the loop. We initialize it as 0, which is kind of tricky. And the reason we",
  "77:48": "can do that is that 0 plus a tensor will broadcast a 0. So that's a little neat feature. That's",
  "77:56": "why we don't have to make this a particular size tensor to start with. Okay. So we're",
  "78:06": "going to be seeing the word hidden state a lot. And so it's important to remember that",
  "78:10": "hidden state simply represents these activations that are occurring inside our recurrent neural",
  "78:16": "net and a recurrent neural net is just a refactoring of a particular kind of fully connected deep",
  "78:24": "model. So that's it, that's what an RNN is. No questions at this point? Rachel? Something",
  "78:42": "that's a bit weird about it, though, is that for every batch we're setting our hidden state",
  "78:47": "to zero, even although we're going through the entire set of numbers, the human numbers",
  "78:53": "dataset in order. So you would think that by the time you've gone like 1, 2, 3 you shouldn't",
  "78:59": "then forget everything we've learnt when you go to 4, 5, 6, right. It would be great to",
  "79:04": "actually remember where we're up to and not reset the hidden state back to 0 every time.",
  "79:14": "So we can absolutely do that. We can maintain the state of our RNN. And here's how we would",
  "79:24": "do that. Rather than having something called \ufffdh\ufffd we'll call it self.h and we'll set",
  "79:29": "it to 0 at the start when we first create our model. Everything else here is the same,",
  "79:39": "and everything else here is the same. And then there's just one extra line of code here.",
  "79:45": "What's going on here. Well here's the thing. If \ufffdh\ufffd is something which persists from",
  "79:53": "batch to batch, then effectively this loop is effectively kind of becoming infinitely",
  "80:02": "long, right. Our deep learning model, therefore, is getting effectively (well, not infinitely",
  "80:10": "deep), but as deep as the entire size of our dataset because every time we're stacking",
  "80:15": "new layers on top of the previous layers. The reason this matters is that when we then",
  "80:21": "do back propagation, when we then calculate the gradients, we're",
  "80:25": "going to have to calculate the gradients all the way back through every layer going all",
  "80:31": "the way. So by the time we get to the end of the dataset, we're going to be effectively",
  "80:36": "backpropagating, not just through this loop, but remember self.h was created also by the",
  "80:43": "previous call to forward. and the previous call forward and the previous call to forward.",
  "80:46": "So we're going to have this incredibly slow calculation of the gradients all the way back",
  "80:54": "to the start. It's also going to use up a whole lot of memory, because it's going to",
  "80:59": "have to store all those intermediate gradients in order to calculate them. So that's a problem.",
  "81:06": "And so the problem is easily solved by saying \ufffddetach\ufffd. And what detach does is it basically",
  "81:12": "says, \ufffdThrow away my gradient history, forget that I, forget that I was calculated in terms",
  "81:18": "of other gradients.\ufffd So the activations are still stored, but the gradient history",
  "81:23": "is no longer stored. And so this kind of cuts off the gradient computation. And so this",
  "81:31": "is called truncated backpropagation. So, exactly the same lines of code as the other two models.",
  "81:39": "h=0 is being has been moved into self.h=0. These lines of code are identical. And we've",
  "81:47": "added one more line of code. So the only other thing is that from time to time, we might",
  "81:52": "have to reset self.h to 0. So I've created a method for that. And we'll see how that",
  "81:59": "works shortly. Okay, so back propagation .. Oh sorry, I was using the wrong jargon - \ufffdbackpropagation",
  "82:08": "through time\ufffd is what we call it when we calculate the backprop over going back through",
  "82:15": "this loop. All right, now we do need to make sure that the samples are seen in the correct",
  "82:24": "order. You know, given that we need to make sure that every batch connects up to the previous",
  "82:30": "batch. So go back to a Notebook 10 to remind yourself of what that needs to look like.",
  "82:35": "But basically the first batch, we see that the number (the), the length of our sequences",
  "82:42": "divided by the batch size is 328. So the first batch will be index #0, then m, then 2*m,",
  "82:50": "and so forth. The second batch will be 1, m+1, 2*m +1, and so forth. So the details",
  "82:57": "don't matter, but here's how we create, you know, do that indexing. So now we can go ahead",
  "83:04": "and call that group_chunks function to calculate, to create our training set and our validation",
  "83:12": "set. And certainly don't shuffle, because that would break everything in terms of the",
  "83:18": "ordering. And then there's one more thing we need to do, which is we need to make sure",
  "83:25": "that at the start of each epoch we call reset. Because at the start of the epoch, we're going",
  "83:33": "back to the start of our natural numbers. So we need to set self.h back to zero. So",
  "83:41": "something that we'll learn about in Part 2 is that fast.ai has something called Callbacks.",
  "83:50": "And callbacks are classes which allow you to basically say, \ufffdDuring the training loop",
  "83:56": "I want you to call some particular code.\ufffd And in particular, this is going to call this",
  "84:06": "code. And so you can see callbacks are very small, or can be very small, they're normally",
  "84:12": "very small. When we start training, it'll call reset. When we start validation, it'll",
  "84:18": "call reset (so this is each epoch). And when we're all finished fitting, it will call reset.",
  "84:24": "And what does reset do? It does whatever you tell it to do and we told it to set self.h",
  "84:29": "to equal zero. So if you want to use a callback, you can simply add it to the callbacks list,",
  "84:38": "cbs, when you create your Learner. And so now when we train, that's way better, okay.",
  "84:47": "So we've now actually kept this, it\ufffds called a stateful RNN. It's actually keeping the",
  "84:53": "state, keeping the hidden state from batch to batch. Now we still got a bit of a obvious",
  "85:02": "problem here, which is that if you look back to the data",
  "85:07": "that we created, we used these first three tokens to predict the fourth, and then the",
  "85:17": "next three tokens to predict the seventh, and then the next three tokens to predict",
  "85:25": "the one after, and so forth. Effectively what we\ufffdd rather do you would think is, is predict",
  "85:32": "every word, not just every fourth word. It seems like we're throwing away a lot of signal",
  "85:37": "here, which is pretty wasteful. So we want to create more signal, and so the way to do",
  "85:44": "that would be rather than putting, rather than putting this output stage outside the",
  "85:58": "loop. Right? So this dotted area is the bit that it's looped. What if we put the output",
  "86:04": "inside the loop? So in other words, after every hidden state was created we immediately",
  "86:09": "did a prediction, and so that way we could predict after every time step, and our dependent",
  "86:15": "variable could be the entire sequence of numbers offset by one. So that would give us a lot",
  "86:21": "more signal. So we have to change our data, so the dependent variable has each of the",
  "86:27": "next three words after each of the three inputs, so instead of being just the numbers from",
  "86:34": "i to i+sl as input, and then i+sl+1 as output, we're going to have the entire set offset",
  "86:43": "by one as our dependent variable. So, and then, we can now do exactly the same as we",
  "86:48": "did before to create our DataLoaders(), and so you can now see that each sequence is exactly",
  "86:56": "the previ[...], is exactly the independent variable and the dependent variable. The same",
  "87:00": "thing, but offset by one. Okay? And then we need to modify our model very slightly. This",
  "87:08": "code is all exactly the same as before, but rather than now returning one output, we\ufffdll",
  "87:14": "create a list of outputs, and will append to that list after every element of the loop.",
  "87:22": "And then at the end we'll stack them all up, and then this is the same. So it's nearly",
  "87:26": "exactly the same. Okay? Just a very minor change. Our loss function needs to... We need",
  "87:36": "to create our own loss function, which is just the cross entropy loss, but we need to",
  "87:42": "just flatten it out. So the target gets flattened out, the input gets flattened out, and so",
  "87:51": "then... We can now pass that as our loss function. Everything else here is the same, and we can",
  "87:58": "fit, and we've gone from.... I can't remember. 58 to 64. So it's improved a little bit, so",
  "88:14": "that's good. You know, I did, we did find this a little, little flaky. Sometimes it",
  "88:22": "would train really well, sometimes it wouldn't train great, but sometimes, you know, we often",
  "88:27": "got this reasonably good answer. Now, one problem here is although effectively we have",
  "88:38": "quite a deep neural net, if you, kind of, go back to the version... So this, this version",
  "88:44": "where we have the loop in it, is kind of the normal way to think about an RNN, but perhaps",
  "88:50": "an easier way to think about it is what we call the unrolled version, and the unrolled",
  "88:55": "version is when you at it like this. Now, if you unroll this stateful neural net we",
  "89:03": "have, you know, it's, it is quite deep, but every single one of the hidden to hidden layers",
  "89:11": "uses exactly the same weight matrix. So really, it's not really that deep at all, because",
  "89:19": "it can't really do very sophisticated computation, because it has to use the same weight matrix",
  "89:23": "every time. So in some ways it's not really any smarter than a plain linear model. So",
  "89:32": "it would be nice to try to, you know, create a truly deep model. Have multiple different",
  "89:39": "layers that it can go through. So we can actually do that easily enough by creating something",
  "89:45": "called a Multilayer RNN, and all we do is we basically take that diagram we just saw",
  "89:50": "before, and we repeat it, but, and this is actually a bit unclear, the, the dotted arrows",
  "89:59": "here are different weight matrices, to the non dotted arrows here. So we can have a different",
  "90:08": "hidden to hidden weight matrix in the, kind of, second set of RNN layers, and a different",
  "90:15": "weight matrix here for this second set, and so this is called a stacked RNN or a multi-layer",
  "90:22": "RNN. And so here's the same thing in the unrolled version. Right? So this is exactly the",
  "90:31": "same thing, but showing you the unrolled version. Writing this out by hand, maybe that's quite",
  "90:39": "a good exercise, or particularly this one would be quite a good exercise, but it's kind",
  "90:43": "of tedious, so we're not going to bother, instead we're going to use PyTorch\ufffds RNN",
  "90:47": "class, and so PyTorch\ufffds RNN class is basically doing exactly what we saw here. Right? And",
  "90:58": "specifically this, this part here, and this part here. Okay? But it's nice that it also",
  "91:08": "has an extra number of layers parameter, that lets you tell it how many to stack on top",
  "91:16": "of each other. So it's important when you start using PyTorch\ufffds RNN to realize there's",
  "91:21": "nothing magic going on. Right? You're just using this refactored for loop that we've",
  "91:27": "already seen. So we still need the input to hidden embedding. This is now the hidden to",
  "91:34": "hidden, with the loop all done for us, and then this is the hidden to output, just as",
  "91:40": "before, and then this is our hidden, just like before. So now we don't need the loop",
  "91:46": "we can just call \ufffdself.rnn()\ufffd and it does the whole loop for us. We can do all the input",
  "91:52": "to hidden at once to save a little bit of time, because thanks to the wonder of embedding",
  "91:57": "matrices, and as per usual we have to go to call \ufffddetach()\ufffd to avoid getting a super",
  "92:03": "deep effective network, and then pass it through our output linear layer. So this is exactly",
  "92:10": "the same as the previous model, except that we have just refactored it using an \ufffdnn.RNN()\ufffd,",
  "92:18": "and we said we want more than one layer. So let's request, say two layers. Now, we still",
  "92:25": "need the ModelReseter, just like before, because remember nothing's changed, and let's go ahead",
  "92:29": "and fit, and oh, it's terrible. So, why is it terrible? Well the reason it's terrible",
  "92:42": "is that now we really do have a very deep model, and very deep models are really hard",
  "92:50": "to train, because we can get exploding or disappearing activations. So what that means",
  "93:00": "is, we start out with some initial state and we're gradually putting it through all of",
  "93:10": "these layers, and all of these layers. Right? And so each time we're doing a matrix multiplication,",
  "93:15": "which remember is just doing a whole bunch of multiplies and adds, and then we multiply",
  "93:20": "and add, and we multiply and add, and we multiply and add, and if you do that enough times you",
  "93:27": "can end up with very, very, very big results, or it's so that would be if the kind of things",
  "93:32": "are multiplying and adding by a pretty big, or very, very, very, very small results. Particularly",
  "93:37": "because we're putting it through the same layer again and again. Right? And why is that",
  "93:44": "a problem? Well if you multiply by two a few times, you get 1, 2, 4, 8, etc., and after",
  "93:54": "32 steps you're already at four billion, or if you start at one and you're multiply by",
  "94:02": "half, a few times after, 32 steps you're down with this tiny number. So a number even slightly",
  "94:09": "higher or lower than one can, kind of, cause an explosion or disappearance of a number,",
  "94:15": "and matrix multiplication is just multiplying numbers and adding them up. So exactly the",
  "94:19": "same thing happens to a matrix multiplication, you kind of have matrices that, that grow",
  "94:23": "really big or grow really small. And when that does that you're also going to have exactly",
  "94:31": "the same things happening to the gradients. They'll get really big or really small. And",
  "94:35": "one of the problems here is that numbers are not stored precisely in a computer. They're",
  "94:42": "stored using something called floating point, so we stole this nice diagram from this article",
  "94:51": "called, \ufffdWhat you never wanted to know about floating point but will be forced to find",
  "94:56": "out\ufffd, and here we're at this point where we're forced to find out, and it's basically",
  "94:59": "showing us the granularity with which numbers are stored, and so the numbers that are further",
  "95:05": "away from zero are stored much less precisely than the numbers that are close to zero, and",
  "95:12": "so if you think about it that means that the gradients further away from zero, could actually,",
  "95:20": "for very big numbers, could actually become zero themselves, because you could actually",
  "95:30": "end up in, kind of, with two numbers that is, that are between these, kind of, little",
  "95:36": "gradations here. And you actually end up with the same thing with the really small numbers,",
  "95:42": "because the really small numbers although they're closer together, the numbers that",
  "95:45": "they represent are also very close together. So in both cases the, kind of, the relative",
  "95:51": "accuracy gets worse and worse. So you really want to avoid this happening. There's a number",
  "96:02": "of ways to avoid this happening, and this is the same for really deep convolutional",
  "96:09": "neural nets, or really deep, kind of, tabular, standard tabular networks. Anytime you have",
  "96:16": "too many layers, it become, it can become difficult to train and you generally have",
  "96:19": "to use like the, really small learning rates, or you have to use special techniques that",
  "96:24": "avoid exploding or disappearing activations or gradients. For RNNs one of the most popular",
  "96:34": "approaches to this is to use an architecture called an LSTM, and I am not going to go into",
  "96:43": "the details of an LSTM from scratch today, but it's in the, it's in the book, and in",
  "96:49": "the notebook, but the key thing to know about an LSTM is... Let's have a look.... Is that",
  "96:58": "rather than just being a matrix multiplication, it is this, which is that there are a number",
  "97:07": "of linear layers that it goes through, and those linear layers are combined in particular",
  "97:13": "ways, and the way they're combined, which is shown in this, kind of, diagram here, is",
  "97:20": "that it basically is designed such that the, that there are like little mini neural networks",
  "97:29": "inside the layer, which decide how much of the previous state is kept, how much is thrown",
  "97:36": "away, and how much of the new state is added. And by letting it have little neural nets",
  "97:42": "to, kind of, calculate each of these things it allows the LSTM layer, which, again, is",
  "97:49": "shown here, to decide how much of, kind of, how much of an update to do at each time,",
  "97:57": "and then with that capability it basically allows it to avoid, kind of, updating too",
  "98:09": "much or updating too little, and by the way this, this code you can refactor, which Sylvain",
  "98:16": "did here into a much smaller amount of code, but these two things are exactly the same",
  "98:22": "thing. So, as I said, I'm not going to worry too much about the details of how this works,",
  "98:27": "now. The important thing, just to know, is that you can replace the matrix multiplication",
  "98:34": "in an RNN with this sequence of matrix multiplications, and sigmoids, n times a plus, and when you",
  "98:43": "do so, you will very significantly decrease the amount of gradient or activation exploding,",
  "98:52": "explosions or disappearances. So that's called an LSTM cell, and an RNN which uses this,",
  "99:00": "instead of a matrix multiplication, is called an LSTM, and so you can replace \ufffdnn.rnn()\ufffd",
  "99:09": "with \ufffdnn.LSTM()\ufffd. Other than that we haven't really changed anything, except that LSTMs,",
  "99:18": "because they have more of these layers in them, we actually have to make our hidden",
  "99:24": "state have more layers in, as well, but other than that we can just replace LSTM, RNN with",
  "99:34": "LSTM, and we can call it just the same way as we did before. We can \ufffddetach()\ufffd just",
  "99:39": "like before, but there's now a list, so we have to detach all of them, and pop it through",
  "99:43": "our output layer, which is exactly as before. Our \ufffdreset()\ufffd is just as before, except",
  "99:48": "it's got to loop through each one, and we can fit it in exactly the same way as before,",
  "99:55": "and as you can see we end up with a much better result, which is great. We have\ufffd We have",
  "100:01": "two questions. Okay, perfect. \ufffdCould we somehow use regularization to try to make",
  "100:07": "the RNN parameters close to the identity matrix, or would that cause bad results because the",
  "100:11": "hidden layers want to deviate from the identity during training?\ufffd So we're actually about",
  "100:20": "to look at regularization. So we will take a look. The",
  "100:27": "identity matrix for those that don't know or don't remember, is the matrix where if",
  "100:32": "you multiply by it, you get exactly the same thing that you started with. So just like",
  "100:35": "if you multiply by one you get back the same number you started with. For linear algebra",
  "100:40": "if you multiply by the identity matrix you get the same matrix you started with, and",
  "100:45": "actually one quite popular approach to initializing the hidden to hidden activations is to initialize",
  "100:53": "with a identity matrix, which ensures that you start with something which doesn't have",
  "101:00": "gradient explosions, or activation explosions. There are... Yeah... Well I won't, and we're",
  "101:08": "about to have a look at some more regularization approaches so let's, let's wait until we do",
  "101:12": "that. All right, next question. \ufffdIs there a way to quickly check if the activations",
  "101:16": "are disappearing/exploding?\ufffd Absolutely just go ahead and calculate them and we'll",
  "101:25": "be looking at that a lot more detail in part two, but a really great exercise would be",
  "101:31": "to try to figure out how you can actually output the activations of each layer. And",
  "101:37": "it would certainly be very easy to do that in the, in the RNNs that we built ourselves",
  "101:43": "from scratch, because we can actually see the linear layers, and so you could just print",
  "101:49": "them out, or print out some statistics, or store them away, or, or something like that.",
  "101:59": "fastai  has a class called ActivationStats(), which,",
  "102:13": "kind of, you can check out if you're interested. That's a really good way to specifically to",
  "102:18": "do this. Okay. So yeah... So regularization is important. We have potentially a lot of",
  "102:33": "parameters and a lot of layers. It would be really nice if we can do the same kind of",
  "102:40": "thing that we've done with, with our CNNs and so forth, which is to use more parameters,",
  "102:46": "but then use regularization to ensure that we don't overfit, and so we can certainly",
  "102:52": "do that with an LSTM as well, and perhaps the best way to do that is to use something",
  "102:58": "called dropout, and dropout is not just used for RNNs. Dropout is used all over the place,",
  "103:05": "but it works particularly well in RNNs. This is a picture from the dropout paper, and what",
  "103:13": "happens in dropout is... Here's a, here\ufffds a, kind of a, picture of a, of three fully",
  "103:19": "connected layers. Not sorry, I guess it's two, one, two. Yeah, no three fully connected",
  "103:26": "layers. And so in these two fully connected layers at the start here, what we could do",
  "103:34": "is we could delete some of the activations at random, and so this has happened here but",
  "103:39": "X... This is what X means, it's like deleting those, those activations at random, and if",
  "103:46": "we do so you can see we end up with a lot less computation going on, and what dropout",
  "103:51": "does is each batch, each mini-batch, it randomly deletes a different set of activations from",
  "104:02": "whatever layers you ask for. That's what dropout does. So so basically the idea is that dropout",
  "104:13": "helps to generalize because if a particular activation was, kind of, effectively learning",
  "104:22": "some input, some, some particular piece of input, memorizing it, then sometimes it gets",
  "104:28": "randomly deleted, and so then suddenly it's not going to do anything useful at all. So",
  "104:35": "by randomly deleting activations it ensures that activations can't become over specialized",
  "104:42": "at doing just one thing, because then if it did, then the times they're randomly deleted,",
  "104:47": "it's, it's not going to work. So here is the entire implementation of a dropout layer.",
  "104:55": "You pass it some value p, which is the probability that an activation gets deleted. So we'll",
  "105:01": "store that away, and so then in the forward you're going to get your activations. Now,",
  "105:06": "if you're not training, so if you're doing validation, then we're not going to do dropout.",
  "105:11": "Okay? But if we are training, then we create a mask, and so the mask is Bernoulli random,",
  "105:21": "a Bernoulli random variable. So what does the know any random variable means? It means",
  "105:27": "it's a bunch of ones and zeros, where this is the probability that we get",
  "105:34": "a 1, which is 1 minus the probability we get a 0. And so then we just multiply that by",
  "105:41": "our input, so that's going to convert some of the inputs into zeroes, which is basically",
  "105:47": "deleting them. So you should check out some of the details, for example, about why we",
  "105:53": "do divide 1 minus p, which is described here, and we do we point out here that normally",
  "105:59": "and I would normally in the lesson show you an example of the, of what Bernoulli does,",
  "106:06": "but of course nowadays, you know, we're getting to the advanced classes, you're expected to",
  "106:11": "do it yourself. So be sure to create a little cell here, and make sure you actually create",
  "106:16": "a tensor, and then run Bernoulli underscore on it, and make sure you see exactly what",
  "106:21": "it's doing, so then you can understand this class. Now, of course we don't have to use",
  "106:27": "this class we made ourselves, we can just use nn.Dropout, but you can use this class",
  "106:33": "yourself, because it does the same thing. So again, you know, we're trying to make sure",
  "106:37": "that we know how to build stuff from scratch. This special \ufffdself.training\ufffd is set for",
  "106:45": "every module automatically by fastai to... Based on whether or not you're in the validation",
  "106:53": "part of your training loop, or the training part of your training loop. It's also part",
  "107:00": "of PyTorch and in PyTorch, if you're not using fastai, you have to call the \ufffdtrain()\ufffd",
  "107:04": "method on a module to set training to true and the \ufffdeval()\ufffd method to set it to false",
  "107:09": "for every module inside some other module. So that's one great approach to regularization.",
  "107:17": "Another approach, which I've only seen used in recurrent neural nets, is a activation",
  "107:26": "regularization and temporal activation regularization, which is very very similar to the question",
  "107:31": "that we were just asked. What happens with activation regularization is it looks very",
  "107:40": "similar to weight decay, but rather than adding some multiplier times the sum of squares of",
  "107:51": "the weights, we add some multiplier by the sum of squares of the activations. So in other",
  "107:58": "words we're basically saying, we're not just trying to decrease the weights, but decrease",
  "108:04": "the total activations, and then similarly we can also see what's the difference between",
  "108:15": "the activations from the previous time step to this time step, so take the difference",
  "108:22": "and then again, squared times some value. So the\ufffd These are two hyper parameters,",
  "108:30": "alpha and beta. The higher they are the more regularized your model, and so with TAR it's",
  "108:37": "going to say, no layer of the LSTM should too dramatically change the activations from",
  "108:46": "one time step to the next, and then for alpha it's saying, no layer of the LSTM should create",
  "108:53": "too large activations, and so they wouldn't actually create these large activations, or",
  "108:59": "large changes and unless the loss improved by enough to make it worth it. Okay, so this",
  "109:13": "then... I think just one more thing we need to know about, which is called weight tying,",
  "109:19": "and weight tying is a very minor change, and let's have a look at it here. So this is the",
  "109:24": "embedding we had before, this is the LSTM we had before, this is where we're going to",
  "109:28": "introduce dropout, this is the hidden to output linear layer we had before, but we're going",
  "109:38": "to add one more line of code, which is the hidden to output weights are actually equal",
  "109:46": "to the input to hidden weights. Now, this is not just setting them once this is actually",
  "109:53": "setting them so that they are a reference to the exact same object in memory, the exact",
  "109:57": "same tensor in memory. So the weights of the hidden to output layer, will always be identical",
  "110:03": "to the weights of the input to hidden layer, and this is called weight tying, and the reason",
  "110:10": "we do this is because conceptually in a language model predicting the next word is about kind",
  "110:16": "of converting activations into English words, whereas an embedding is about converting English",
  "110:24": "words to activations, and there's a reasonable hypothesis,",
  "110:27": "which would be that: \ufffdWhile those are basically exactly the same computation or at least the,",
  "110:33": "the reverse of it, so why shouldn't they use the same weights.\ufffd And it turns out lo and",
  "110:37": "behold, yes, if you use the same weights then actually it does work a little bit better.",
  "110:44": "So then here's our forward, which is to do the input to hidden, do the RNN, apply the",
  "110:49": "dropout, do the detach, and then apply the hidden to output, which is using exactly the",
  "110:56": "same weights as the input to hidden, and reset\ufffds the same. We haven't created the RNN regularizer",
  "111:04": "from scratch here, but you can add it as a callback passing in your alpha and your beta.",
  "111:15": "If you call TextLearner(), instead of Learner(), it will add the ModelReseter and the RNNRegularizer()",
  "111:23": "for you. So that's what one of the things TextLearner() does. So this code is the same",
  "111:28": "as this code, and so we can then train the model again, and let\ufffds also add weight decay.",
  "111:35": "And look at this! We're getting up close to 90% accuracy. So, we've covered a lot in this",
  "111:47": "lesson, but the amazing thing is that we've just replicated all of the pieces in an AWD-LSTM,",
  "111:57": "all of the pieces in this state-of-the-art recurrent neural net, which we've showed we",
  "112:03": "could use in the previous notebook to get, what was until very recently, state-of-the-art",
  "112:10": "results for text classification, and far more quickly, and with far less compute, and memory",
  "112:18": "than more modern, than the approaches in the last year or so, which have beaten that benchmark.",
  "112:26": "So this is a really efficient, really accurate approach, and it's still the, the state-of-the-art",
  "112:34": "in many, many academic situations, and it's still very widely used in industry, and so",
  "112:42": "it's pretty cool that we've actually seen how to, to write it from scratch. So the main",
  "112:50": "thing to mention in the further research is to have a look at the source code for AWD-LSTM",
  "112:55": "in fastai, and see if you can see how the things in AWD-LSTM map to, you know, what",
  "113:03": "those lines of code how they map to the concepts that we've seen in this chapter. Rachel, do",
  "113:09": "we have any questions? So, here we have come to the conclusion of our, what was originally",
  "113:17": "going to be seven lessons, and turned into eight lessons. I hope that you've got a lot",
  "113:27": "out of this. Thank you for staying with us. What a lot of folks people, people now do",
  "113:33": "when they finish, they're at least people who finish previous courses, is they go back",
  "113:36": "to lesson one, and try and repeat it, but doing a lot less looking at the notebooks,",
  "113:42": "a lot more doing stuff from scratch yourself, and going deeper into the assignments. So",
  "113:51": "that's one thing you could do next. Another thing you could do next would be to pick out",
  "113:55": "a Kaggle competition to enter, or pick a book that you want to read about deep learning,",
  "114:03": "or a paper, and team up with some friends to do, like a, paper reading group, or a book",
  "114:12": "reading group. You know, one of the most important things to keep the learning going is to get",
  "114:16": "together with, with other people on the learning journey. Another great way to do that, of",
  "114:22": "course, is through the forums. So if you haven't been using the forums much so far no problem,",
  "114:26": "but now might be a great time to get involved and find some projects that are going on,",
  "114:31": "that look interesting, and it's fine if you, you know, you don't have to be an expert.",
  "114:37": "Right? Obviously any of those projects, the people that are already doing it, are going",
  "114:40": "to know more about it than you do at this point, because they're already doing it, but",
  "114:45": "if you drop into a thread and say, \ufffdHey I would love to learn more about this how",
  "114:48": "do I get started?\ufffd, or have a look at the wiki posts to find out, and try things out.",
  "114:54": "You can start getting involved in other people's projects, and help them out. So, yeah... And",
  "115:05": "of course don't forget about writing. So if you haven't tried writing a blog post yet,",
  "115:09": "maybe now's a great do that. Pick something that's interesting to you, especially if it's",
  "115:15": "something in your area of expertise at work, or a hobby, or something like that, or specific",
  "115:20": "to where you live, maybe you could try and build some kind of text classifier, or text",
  "115:26": "generator for particular kinds of texts, that are, that you know about. You know, that would",
  "115:33": "be that would be a super interesting thing to try out, and be sure to share it with the",
  "115:36": "folks on the forum. So there's a few ideas. So don't let this be the end of your learning",
  "115:42": "journey, you know, keep, keep going and then come back, and try part two. If it's not out",
  "115:50": "yet, obviously you have to wait until it is out, if it, but if it is out, you might want",
  "115:54": "to kind of spend a couple of months, you know, really experimenting with this, before you",
  "115:59": "move on to part two, to make sure that everything in part one feels pretty, pretty solid to",
  "116:06": "you. Well, thank you very much everybody for, for your time. We've really enjoyed doing",
  "116:14": "this course. It's been a tough course for us to teach, because with all this COVID-19",
  "116:19": "stuff going on at the same time, I'm really glad we've got through it. I'm particularly,",
  "116:23": "particularly grateful to Sylvain, who has been extraordinary in, in really making so",
  "116:31": "much of this happen, and particularly since I've been so busy with COVID-19 stuff, around",
  "116:37": "masks in particular, it's really... A lot thanks to Sylvain, that everything has come",
  "116:42": "together, and of course to Rachel, who's been here with me on, on every one of these lessons.",
  "116:50": "Thank you so much. And I'm looking forward to seeing you again in a future course. Thanks",
  "116:56": "everybody."
}